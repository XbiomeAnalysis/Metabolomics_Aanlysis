# Chemometrics Analysis

The functions for Chemometrics Analysis in **POMA** [@castellano2021pomashiny] implemented from **mixOmics** [@rohart2017mixomics].

## Loading packages
```{r}
knitr::opts_chunk$set(warning = F, message = F)

library(dplyr)
library(tibble)
library(POMA)
library(ggplot2)
library(ggraph)
library(plotly)
library(SummarizedExperiment)

# rm(list = ls())
options(stringsAsFactors = F)
options(future.globals.maxSize = 1000 * 1024^2)
```

## Importing data

The input data sets are from the previous chapter.
```{r}
se_processed <- readRDS("./dataset/POMA/se_processed.RDS")
```


## Principal Component Analysis (PCA)

> The aim of PCA (Jolliffe 2005) is to reduce the dimensionality of the data whilst retaining as much information as possible. ‘Information’ is referred here as variance. The idea is to create uncorrelated artificial variables called principal components (PCs) that combine in a linear manner the original (possibly correlated) variables.

```{r, fig.width=8, fig.height=6}
poma_pca <- PomaMultivariate(se_processed, method = "pca")
poma_pca$scoresplot +
  ggtitle("Scores Plot (pca)")
```


## Partial Least Squares-Discriminant Analysis (PLS-DA)

> Partial Least Squares (PLS) regression is a multivariate methodology which relates two data matrices X (e.g. transcriptomics) and Y (e.g. lipids). PLS goes beyond traditional multiple regression by modelling the structure of both matrices. Unlike traditional multiple regression models, it is not limited to uncorrelated variables. One of the many advantages of PLS is that it can handle many noisy, collinear (correlated) and missing variables and can also simultaneously model several response variables in Y.

* Calculation

```R
poma_plsda <- PomaMultivariate(se_processed, method = "plsda")
```

```{r, include=FALSE}
poma_plsda <- PomaMultivariate(se_processed, method = "plsda")
```

* scatter plot
```{r, fig.width=8, fig.height=6}
poma_plsda$scoresplot +
  ggtitle("Scores Plot (plsda)")
```

* errors plot
```{r, fig.width=8, fig.height=5}
poma_plsda$errors_plsda_plot +
  ggtitle("Error Plot (plsda)")
```


## Sparse Partial Least Squares-Discriminant Analysis (sPLS-DA)

> Even though PLS is highly efficient in a high dimensional context, the interpretability of PLS needed to be improved. sPLS has been recently developed by our team to perform simultaneous variable selection in both data sets X and Y data sets, by including LASSO penalizations in PLS on each pair of loading vectors

* Calculation

```R
poma_splsda <- PomaMultivariate(se_processed, method = "splsda")
```

```{r, include=FALSE}
poma_splsda <- PomaMultivariate(se_processed, method = "splsda")
```

* scatter plot
```{r, fig.width=8, fig.height=6}
poma_splsda$scoresplot +
  ggtitle("Scores Plot (splsda)")
```

## Orthogonal Partial Least Squares-Discriminant Analysis (orthoPLS-DA)


## Systematic Information
```{r}
devtools::session_info()
```