[["index.html", "Data Analysis in Metabolomics Chapter 1 Introduction 1.1 What is metabolomics? 1.2 Workflow of metabolomics data analysis 1.3 Software 1.4 Reference", " Data Analysis in Metabolomics Hua Zou and Bangzhuo Tong 2023-11-27 Chapter 1 Introduction 1.1 What is metabolomics? Metabolomics is the large-scale study of small molecules, commonly known as metabolites, within cells, biofluids, tissues or organisms. Collectively, these small molecules and their interactions within a biological system are known as the metabolome. Figure 1.1: Overview of the four major omics fields, from genomics to metabolomics Just as genomics is the study of DNA and genetic information within a cell, and transcriptomics is the study of RNA and differences in mRNA expression; metabolomics is the study of substrates and products of metabolism, which are influenced by both genetic and environmental factors. Metabolomics is a powerful approach because metabolites and their concentrations, unlike other “omics” measures, directly reflect the underlying biochemical activity and state of cells / tissues. Thus metabolomics best represents the molecular phenotype. 1.2 Workflow of metabolomics data analysis In this tutorial, two modules would be introduced: Statistical Analysis Functional Analysis In Statistical Analysis module, you will learn to preprocess metabolomics data and use different statistical tests to find potential metabolomics biomarkers. After that, you could explore the possible functions of the identified metabolomics biomarkers through Functional analysis (including Enrichment Analysis and Pathway Analysis). Below we showed the details of the workflow: Figure 1.2: Workflow in Data Analysis on metabolomics 1.2.1 Statistical Analysis Due to terrible experience on Statistical Analysis in Metabolomics via MetaboAnalystR R package, we try to provide a reproducible and easy-to-use template for visualization, pre-processing, exploration, and statistical analysis on metabolomic data by other packages and scripts. Here, the template comprises the following procedures: Data Processing Data Checking Data Filtering Missing Value Imputation Data Normalization Cluster Analysis Hierarchical Clustering Partitional Clustering Chemometrics Analysis Principal Component Analysis (PCA) Partial Least Squares-Discriminant Analysis (PLS-DA) Sparse Partial Least Squares-Discriminant Analysis (sPLS-DA) Univariate Analysis Fold Change Analysis T Tests Wilcoxon Test Limma Test Wilcoxon Test Volcano plot Correlation Heatmaps glasso Feature selection Lasso Ridge Elasticnet Classification Random Forest Network Analysis SPRING Spearman SparCC Network comparison 1.2.2 Functional Analysis Following two chapters would focus on the Enrichment Analysis and Pathway Analysis of metabolomic data. Enrichment Analysis includes three sections (i.e., ORA, SSP and QEA) and Pathway Analysis only includes ORA and QEA. The main difference between Enrichment Analysis and Pathway Analysis are the data set that input metabolites are enriched to. In Enrichment Analysis, input metabolites are enriched to pre-defined metabolite sets while in Pathway Analysis, metabolites are enriched to pathways in KEGG. Workflow of Enrichment analysis and Pathway analysis is attached below. Users can choose analysis module according to their data type or interest. Enrichment Analysis Single Sample Profiling Over representation analysis Quantitative Enrichment Analysis Pathway Analysis Over representation analysis Quantitative Enrichment Analysis 1.3 Software R 4.1.2 or later release Download link. Rstudio Desktop Download link. 1.4 Reference Metabolomics on EBI "],["data-processing.html", "Chapter 2 Data Processing 2.1 Loading packages 2.2 Importing data 2.3 Data Checking 2.4 Missing value imputation 2.5 Data Filtering 2.6 Data Normalization 2.7 Removing outliers 2.8 Data distribution 2.9 Saving datasets into RDS files 2.10 Systematic Information", " Chapter 2 Data Processing Although the horrible experience of data analysis by using MetaboAnalystR R package (Pang et al. 2020), its thought of data processing are very useful. Therefore, this template is based on the workflow from MetaboAnalystR. We integrated R packages and our own scripts to build the data analysis template on metabolomic data. Particularly, we thanks very much for POMA R package (Castellano-Escuder et al. 2021). POMA is a flexible data cleaning and statistical analysis processes in one comprehensible and user-friendly R package. 2.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(Biobase) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(readxl) library(SummarizedExperiment) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 2.2 Importing data The dataset is from the Zeybel-2022 published paper (Zeybel et al. 2022). features table profile &lt;- readxl::read_xlsx(&quot;./dataset/OmicsDataSet-Zeybel-2022.xlsx&quot;, sheet = 6) head(profile) ## # A tibble: 6 × 67 ## BIOCHEMICAL `SUPER PATHWAY` `SUB PATHWAY` `COMP ID` PLATFORM `CHEMICAL ID` RI MASS PUBCHEM CAS KEGG `SampleID HMDBID` P101001 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 (14 or 15)-meth… Lipid Fatty Acid, … 38768 LC/MS N… 100002945 5695 269. 8181;1… &lt;NA&gt; C169… HMDB0061859 5.11e7 ## 2 (16 or 17)-meth… Lipid Fatty Acid, … 38296 LC/MS N… 100002356 5993 297. 3083779 2724… &lt;NA&gt; HMDB0037397 5.11e6 ## 3 (2 or 3)-deceno… Lipid Medium Chain… 63436 LC/MS N… 100021502 4990 169. &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 7.57e5 ## 4 (2,4 or 2,5)-di… Xenobiotics Food Compone… 62533 LC/MS N… 100020519 3474 201. &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 5 (N(1) + N(8))-a… Amino Acid Polyamine Me… 57814 LC/MS P… 100016038 3080 188. 123689… &lt;NA&gt; C006… HMDB0001276,HMDB… 2.82e5 ## 6 (R)-3-hydroxybu… Lipid Fatty Acid M… 43264 LC/MS P… 100003926 2400 248. 534816… &lt;NA&gt; &lt;NA&gt; HMDB0013127 NA ## # ℹ 54 more variables: P101012 &lt;dbl&gt;, P101030 &lt;dbl&gt;, P101031 &lt;dbl&gt;, P101050 &lt;dbl&gt;, P101059 &lt;dbl&gt;, P101071 &lt;dbl&gt;, P101072 &lt;dbl&gt;, ## # P101084 &lt;dbl&gt;, P101003 &lt;dbl&gt;, P101004 &lt;dbl&gt;, P101013 &lt;dbl&gt;, P101016 &lt;dbl&gt;, P101017 &lt;dbl&gt;, P101038 &lt;dbl&gt;, P101051 &lt;dbl&gt;, P101061 &lt;dbl&gt;, ## # P101062 &lt;dbl&gt;, P101074 &lt;dbl&gt;, P101075 &lt;dbl&gt;, P101076 &lt;dbl&gt;, P101085 &lt;dbl&gt;, P101088 &lt;dbl&gt;, P101007 &lt;dbl&gt;, P101018 &lt;dbl&gt;, P101019 &lt;dbl&gt;, ## # P101041 &lt;dbl&gt;, P101052 &lt;dbl&gt;, P101064 &lt;dbl&gt;, P101065 &lt;dbl&gt;, P101077 &lt;dbl&gt;, P101090 &lt;dbl&gt;, P101094 &lt;dbl&gt;, P101009 &lt;dbl&gt;, P101010 &lt;dbl&gt;, ## # P101021 &lt;dbl&gt;, P101022 &lt;dbl&gt;, P101042 &lt;dbl&gt;, P101054 &lt;dbl&gt;, P101056 &lt;dbl&gt;, P101067 &lt;dbl&gt;, P101068 &lt;dbl&gt;, P101079 &lt;dbl&gt;, P101095 &lt;dbl&gt;, ## # P101096 &lt;dbl&gt;, P101011 &lt;dbl&gt;, P101024 &lt;dbl&gt;, P101025 &lt;dbl&gt;, P101027 &lt;dbl&gt;, P101047 &lt;dbl&gt;, P101057 &lt;dbl&gt;, P101069 &lt;dbl&gt;, P101080 &lt;dbl&gt;, ## # P101081 &lt;dbl&gt;, P101082 &lt;dbl&gt; metadata table metadata &lt;- readxl::read_xlsx(&quot;./dataset/OmicsDataSet-Zeybel-2022.xlsx&quot;, sheet = 2) head(metadata) ## # A tibble: 6 × 11 ## PatientID Stage Metabolomics Proteomics GutMetagenomics OralMetagenomics LiverFatClass Gender AlcoholConsumption Smoker Age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 P101001 Before Send Send Send Send Severe Male No No 52 ## 2 P101003 Before Send Send Send Send None Female No No 31 ## 3 P101004 Before Send Send Send Send Moderate Male Yes No 43 ## 4 P101007 Before Send Send Send Send Severe Female No No 61 ## 5 P101009 Before Send Send Send Send Moderate Male No Yes 51 ## 6 P101010 Before Send Send Send Send Mild Male Yes No 27 Data Preparation: ExpressionSet object get_ExpressionSet &lt;- function( x, y) { # x = metadata # y = profile phen &lt;- x %&gt;% dplyr::mutate(Metabolomics == &quot;Send&quot;) %&gt;% dplyr::select(PatientID, LiverFatClass, Gender, Smoker, Age, AlcoholConsumption) sid &lt;- intersect(phen$PatientID, colnames(y)) prof &lt;- y %&gt;% dplyr::select(all_of(sid)) %&gt;% data.frame() rownames(prof) &lt;- paste0(&quot;M_&quot;, y$`COMP ID`) phen &lt;- phen[pmatch(sid, phen$PatientID), , F] %&gt;% tibble::column_to_rownames(&quot;PatientID&quot;) feat &lt;- y %&gt;% dplyr::select(1:12) %&gt;% as.data.frame() rownames(feat) &lt;- paste0(&quot;M_&quot;, y$`COMP ID`) # expressionSet phen_ADF &lt;- new(&quot;AnnotatedDataFrame&quot;, data=phen) feature_ADF &lt;- new(&quot;AnnotatedDataFrame&quot;, data=feat) experimentData &lt;- new( &quot;MIAME&quot;, name=&quot;Hua&quot;, lab=&quot;Xbiome Company&quot;, contact=&quot;Hua@xbiome.com&quot;, title=&quot;Metabolomics&quot;, abstract=&quot;The Mass Spectrometry ExpressionSet without imputation value&quot;, url=&quot;www.xbiome.cn&quot;, other=list(notes=&quot;Metabolomics&quot;)) expressionSet &lt;- new( &quot;ExpressionSet&quot;, exprs=prof, phenoData=phen_ADF, featureData=feature_ADF, experimentData=experimentData) return(expressionSet) } ExprSet &lt;- get_ExpressionSet(x = metadata, y = profile) ExprSet ## ExpressionSet (storageMode: lockedEnvironment) ## assayData: 1032 features, 55 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: P101001 P101003 ... P101096 (55 total) ## varLabels: LiverFatClass Gender ... AlcoholConsumption (5 total) ## varMetadata: labelDescription ## featureData ## featureNames: M_38768 M_38296 ... M_15581 (1032 total) ## fvarLabels: BIOCHEMICAL SUPER PATHWAY ... SampleID HMDBID (12 total) ## fvarMetadata: labelDescription ## experimentData: use &#39;experimentData(object)&#39; ## Annotation: Data Preparation: SummarizedExperiment object getSEobject &lt;- function(x, y) { target &lt;- x %&gt;% dplyr::mutate(Metabolomics == &quot;Send&quot;) %&gt;% dplyr::select(PatientID, LiverFatClass, Gender, Smoker, Age, AlcoholConsumption) sid &lt;- intersect(target$PatientID, colnames(y)) features &lt;- y %&gt;% dplyr::select(all_of(sid)) %&gt;% data.frame() %&gt;% t() colnames(features) &lt;- paste0(&quot;M_&quot;, y$`COMP ID`) target &lt;- target[pmatch(sid, target$PatientID), , F] res &lt;- PomaSummarizedExperiment(target = target, features = features) return(res) } se &lt;- getSEobject(metadata, profile) se ## class: SummarizedExperiment ## dim: 1032 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(1032): M_38768 M_38296 ... M_57517 M_15581 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption Extract data for test dataset get_testData &lt;- function(object, num = 200) { features_tab &lt;- SummarizedExperiment::assay(object) %&gt;% t() metadata_tab &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;ID&quot;) res &lt;- PomaSummarizedExperiment(target = metadata_tab, features = features_tab[, 1:num]) return(res) } se_raw &lt;- get_testData(object = se) se_raw ## class: SummarizedExperiment ## dim: 200 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(200): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.3 Data Checking Features in PomaSummarizedExperiment object must have the following criterion: All data values are numeric. A total of 0 (0%) missing values were detected. CheckData &lt;- function(object) { features_tab &lt;- SummarizedExperiment::assay(object) # numeric &amp; missing values int_mat &lt;- features_tab rowNms &lt;- rownames(int_mat) colNms &lt;- colnames(int_mat) naNms &lt;- sum(is.na(int_mat)) for (i in 1:ncol(int_mat)) { if (class(int_mat[, i]) == &quot;integer64&quot;) { int_mat[, i] &lt;- as.double(int_mat[, i]) } } num_mat &lt;- apply(int_mat, 2, as.numeric) if (sum(is.na(num_mat)) &gt; naNms) { num_mat &lt;- apply(int_mat, 2, function(x) as.numeric(gsub(&quot;,&quot;, &quot;&quot;, x))) if (sum(is.na(num_mat)) &gt; naNms) { message(&quot;&lt;font color=\\&quot;red\\&quot;&gt;Non-numeric values were found and replaced by NA.&lt;/font&gt;&quot;) } else { message(&quot;All data values are numeric.&quot;) } } else { message(&quot;All data values are numeric.&quot;) } int_mat &lt;- num_mat rownames(int_mat) &lt;- rowNms colnames(int_mat) &lt;- colNms varCol &lt;- apply(int_mat, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;&lt;font color=\\&quot;red\\&quot;&gt;&quot;, constNum, &quot;features with a constant or single value across samples were found and deleted.&lt;/font&gt;&quot;)) int_mat &lt;- int_mat[, !constCol, drop = FALSE] } totalCount &lt;- nrow(int_mat) * ncol(int_mat) naCount &lt;- sum(is.na(int_mat)) naPercent &lt;- round(100 * naCount/totalCount, 1) message(paste(&quot;A total of &quot;, naCount, &quot; (&quot;, naPercent, &quot;%) missing values were detected.&quot;, sep = &quot;&quot;)) # save int_mat into se object target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = t(int_mat)) return(res) } se_check &lt;- CheckData(object = se_raw) ## All data values are numeric. ## A total of 1146 (10.4%) missing values were detected. se_check ## class: SummarizedExperiment ## dim: 200 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(200): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.4 Missing value imputation “none”: all missing values will be replaced by zero. “LOD”: specific Limit Of Detection which provides by user. “half_min”: half minimal values across samples except zero. “median”: median values across samples except zero. “mean”: mean values across samples except zero. “min”: minimal values across samples except zero. “knn”: k-nearest neighbors samples. “rf”: nonparametric missing value imputation using Random Forest. “QRILC”: missing values imputation based quantile regression. (default: “none”). impute_abundance &lt;- function( object, group, ZerosAsNA = FALSE, RemoveNA = TRUE, prevalence = 0.5, method = c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;), LOD = NULL) { # object = se_check # group = &quot;group&quot; # ZerosAsNA = TRUE # RemoveNA = TRUE # prevalence = 0.5 # method = &quot;knn&quot; if (base::missing(object)) { stop(&quot;object argument is empty!&quot;) } if (!methods::is(object, &quot;SummarizedExperiment&quot;)) { stop(&quot;object is not either a phyloseq or SummarizedExperiment object.&quot;) } method &lt;- match.arg( method, c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;) ) if (base::missing(method)) { message(&quot;method argument is empty! KNN will be used&quot;) } # profile: row-&gt;samples; col-&gt;features if (all(!is.null(object), inherits(object, &quot;SummarizedExperiment&quot;))) { # sample table &amp; profile table sam_tab &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;TempRowNames&quot;) prf_tab &lt;- SummarizedExperiment::assay(object) %&gt;% data.frame() %&gt;% t() } group_index &lt;- which(colnames(sam_tab) == group) samples_groups &lt;- sam_tab[, group_index] to_imp_data &lt;- prf_tab %&gt;% as.matrix() if (ZerosAsNA) { to_imp_data[to_imp_data == 0] &lt;- NA to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } else { to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } percent_na &lt;- sum(is.na(to_imp_data)) if (percent_na == 0) { message(&quot;No missing values detected in your data&quot;) if (method != &quot;none&quot;) { method &lt;- &quot;none&quot; } } if (isTRUE(RemoveNA)) { count_NA &lt;- stats::aggregate( . ~ Group, data = to_imp_data, function(x) {(sum(is.na(x)) / (sum(is.na(x)) + sum(!is.na(x))) ) }, na.action = NULL) count_NA &lt;- count_NA %&gt;% dplyr::select(-Group) correct_names &lt;- names(count_NA) supress &lt;- unlist(as.data.frame(lapply(count_NA, function(x) any(x &gt; prevalence)))) names(supress) &lt;- correct_names correct_names &lt;- names(supress[supress == &quot;FALSE&quot;]) depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)][!supress] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) } else { depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) correct_names &lt;- colnames(prf_tab) } # Row-&gt;feature;Col-&gt;sample if (method == &quot;none&quot;) { depurdata[is.na(depurdata)] &lt;- 0 } else if (method == &quot;LOD&quot;) { if (is.null(LOD)) { message(&quot;No LOD provided, regard one-tenth mininal value as LOD&quot;) depurdata_withoutNA &lt;- depurdata[!is.na(depurdata)] LOD &lt;- min(depurdata_withoutNA[depurdata_withoutNA != 0]) / 10 } depurdata[is.na(depurdata)] &lt;- LOD depurdata[depurdata == 0] &lt;- LOD } else if (method == &quot;half_min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE)/2, x) else x}) } else if (method == &quot;median&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), median(x, na.rm = TRUE), x) else x}) } else if (method == &quot;mean&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), mean(x, na.rm = TRUE), x) else x}) } else if (method == &quot;min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE), x) else x}) } else if (method == &quot;knn&quot;) { depurdata &lt;- t(depurdata) datai &lt;- impute::impute.knn(depurdata, k = 20) depurdata &lt;- t(datai$data) } else if (method == &quot;rf&quot;) { fit &lt;- missForest::missForest(t(depurdata)) depurdata &lt;- fit$ximp %&gt;% t() } else if (method == &quot;QRILC&quot;) { fit &lt;- log(t(depurdata)) %&gt;% imputeLCMD::impute.QRILC() depurdata &lt;- t(fit[[1]]) } colnames(depurdata) &lt;- correct_names rownames(depurdata) &lt;- rownames(prf_tab) if (methods::is(object, &quot;SummarizedExperiment&quot;)) { target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = depurdata) } return(res) } se_impute &lt;- impute_abundance( se_check, group = &quot;group&quot;, ZerosAsNA = TRUE, RemoveNA = TRUE, prevalence = 0.5, method = &quot;knn&quot;) se_impute ## class: SummarizedExperiment ## dim: 180 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(180): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption # profile head(SummarizedExperiment::assay(se_impute)) ## P101001 P101003 P101004 P101007 P101009 P101010 P101011 P101012 P101013 P101016 P101017 ## M_38768 51127588.0 42040432.0 34940596.00 58518636.0 51118832.00 83783688.0 29017984.0 51222064.00 77550128.0 30949554.0 26923596.00 ## M_38296 5105020.5 4006120.2 3885477.00 4285129.5 6665653.50 9057441.0 2802655.2 5996555.00 11367511.0 3874736.8 2817151.00 ## M_63436 756686.2 983889.2 851026.50 726593.9 232959.52 650261.1 541954.8 598491.00 438885.6 1625844.8 566466.94 ## M_57814 281502.0 175893.0 297304.38 319016.7 242172.20 200135.8 242804.9 248842.02 377212.6 183718.3 232514.53 ## M_52984 125465.8 154494.6 128320.37 176100.9 77345.62 122282.8 131924.3 80226.58 102010.7 129011.9 97377.79 ## M_48762 559069.1 596473.9 53293.76 627140.5 7016015.00 1914246.9 2762589.2 140576.45 723530.9 295995.2 3321584.25 ## P101018 P101019 P101021 P101022 P101024 P101025 P101027 P101030 P101031 P101038 P101041 ## M_38768 56720032.00 27956064.0 48723600.00 16282054.0 77028824.0 32022342.0 22589448.0 38449788.0 59134052.0 32038030.0 20833830.00 ## M_38296 8029728.00 3766663.8 5174967.00 1746182.9 5519105.5 2557365.0 1882902.6 2860324.2 4721201.0 4011627.5 2938779.00 ## M_63436 427850.62 519559.0 1301591.25 1474247.4 970475.8 628680.1 635516.6 367246.8 512037.9 852000.1 634488.56 ## M_57814 279062.56 195083.9 290545.53 514479.0 420295.6 181825.7 196115.8 231290.3 315392.4 248820.8 214474.08 ## M_52984 98456.04 361975.5 119374.53 169170.4 101209.9 105117.3 104063.2 153193.4 181312.4 235948.1 68496.68 ## M_48762 3489639.25 417727.6 16078.62 24787876.0 2287562.2 4724330.0 2960643.8 1503947.2 338791.1 1028211.6 16129281.00 ## P101042 P101047 P101050 P101051 P101052 P101054 P101056 P101057 P101059 P101061 P101062 ## M_38768 33809080.00 18637508.00 21978476.0 24265162.0 52203780.00 12836384.0 18546636.0 32301820.0 22645984.0 23683254.00 29027646.0 ## M_38296 3017260.50 1935144.12 2897211.0 2476279.5 5928454.00 1685760.6 1650011.0 3419157.8 2196044.2 3217499.25 4060367.8 ## M_63436 1680135.75 326005.62 316650.2 737202.9 459385.94 346176.6 585470.2 417958.5 734586.3 337035.72 982299.4 ## M_57814 295862.56 397441.94 253910.2 295948.6 246857.86 330762.7 209301.7 265086.1 181746.3 256601.55 187952.7 ## M_52984 112239.87 94186.81 112969.0 118040.4 115115.18 142644.3 103307.2 113114.2 89261.8 56381.96 186628.3 ## M_48762 87286.19 2211343.75 98800.9 1933066.2 54885.02 4003695.2 1786579.6 2497416.7 10217042.0 7272486.00 4477679.0 ## P101064 P101065 P101067 P101068 P101069 P101071 P101072 P101074 P101075 P101076 P101077 ## M_38768 32629048.0 22950806.00 33555116.00 44283972.0 52685972.0 32415040.0 34170948.0 22550616.0 22058076.00 24455466.0 25225170.0 ## M_38296 3031529.5 2467147.25 3567913.25 6525382.0 3984333.5 3001414.5 4679519.0 2529255.5 2583265.50 3515218.2 3272875.0 ## M_63436 1255148.0 637699.06 284516.12 664800.1 684813.6 596846.1 316855.0 646136.8 198381.73 255897.7 547243.4 ## M_57814 165441.1 203872.41 238433.59 220632.9 209510.0 412294.9 335871.3 229869.7 225894.31 201601.9 285970.2 ## M_52984 179940.6 82205.24 56987.89 144673.7 151451.9 131184.4 127776.5 102868.8 64535.59 105523.9 130333.8 ## M_48762 395835.7 460618.81 8156659.00 3966085.0 2887422.5 190455.1 46928844.0 3240584.5 91241.58 3088418.0 6992567.5 ## P101079 P101080 P101081 P101082 P101084 P101085 P101088 P101090 P101094 P101095 P101096 ## M_38768 15718590.0 29120336.0 65904836.0 22908578.0 29140440.0 20427124.0 29199012.00 24042020.00 36910084.00 35662068.0 66402192.00 ## M_38296 2449462.5 2695001.5 6474709.5 2110243.8 3648091.2 3253531.8 4154170.75 2396959.75 4759584.50 3452283.2 6374383.00 ## M_63436 508791.6 1256550.2 339909.3 596292.2 497300.8 309859.3 601515.12 794206.00 414972.84 3606340.5 1077637.50 ## M_57814 191453.5 264148.1 212220.1 335886.6 228471.4 345303.3 333549.22 321148.53 313197.78 500135.6 226660.25 ## M_52984 127343.7 153657.1 125355.2 107572.9 151915.6 106491.1 89181.83 147634.67 91856.74 340070.0 137341.48 ## M_48762 1325582.1 600080.8 3410091.7 1303324.6 684199.1 2319273.2 854781.06 92700.81 1132143.00 31216882.0 34001.17 2.5 Data Filtering The purpose of the data filtering is to identify and remove variables that are unlikely to be of use when modeling the data. No phenotype information are used in the filtering process, so the result can be used with any downstream analysis. This step is strongly recommended for untargeted metabolomics datasets (i.e. spectral binning data, peak lists) with large number of variables, many of them are from baseline noises. Filtering can usually improve the results. For details, please refer to the paper by Hackstadt, et al. Non-informative variables can be characterized in three groups: 1) variables of very small values (close to baseline or detection limit) - these variables can be detected using mean or median; 2) variables that are near-constant values throughout the experiment conditions (housekeeping or homeostasis) - these variables can be detected using standard deviation (SD); or the robust estimate such as interquantile range (IQR); and 3) variables that show low repeatability - this can be measured using QC samples using the relative standard deviation(RSD = SD/mean). Features with high percent RSD should be removed from the subsequent analysis (the suggested threshold is 20% for LC-MS and 30% for GC-MS). For data filtering based on the first two categories, the following empirical rules are applied during data filtering: Less than 250 variables: 5% will be filtered; Between 250 - 500 variables: 10% will be filtered; Between 500 - 1000 variables: 25% will be filtered; Over 1000 variables: 40% will be filtered; Filtering features if their RSDs are &gt; 25% in QC samples Interquantile range (IQR) Standard deviation (SD) Median absolute deviation (MAD) Relative standard deviation (RSD = SD/mean) Non-parametric relative standard deviation (MAD/median) Mean intensity value Median intensity value FilterFeature &lt;- function( object, qc_label, method = c(&quot;none&quot;, &quot;iqr&quot;, &quot;rsd&quot;, &quot;nrsd&quot;, &quot;mean&quot;, &quot;sd&quot;, &quot;mad&quot;, &quot;median&quot;), rsd_cutoff = 25) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) # QC samples qc_samples &lt;- metadata_tab %&gt;% data.frame() %&gt;% dplyr::filter(group == qc_label) if (dim(qc_samples)[1] == 0) { stop(&quot;No qc samples have been chosen, please check your input&quot;) } # QC samples&#39; feature table qc_feature &lt;- features_tab[, colnames(features_tab)%in%rownames(qc_samples)] %&gt;% t() # filter features by QC RSD rsd &lt;- rsd_cutoff / 100 sds &lt;- apply(qc_feature, 2, sd, na.rm = T) mns &lt;- apply(qc_feature, 2, mean, na.rm = T) rsd_vals &lt;- abs(sds/mns) %&gt;% na.omit() gd_inx &lt;- rsd_vals &lt; rsd int_mat &lt;- features_tab[gd_inx, ] message(&quot;Removed &quot;, (dim(qc_feature)[2] - dim(int_mat)[1]), &quot; features based on QC RSD values. QC samples are excluded from downstream functional analysis.&quot;) # whether to filter features by percentage according to the number PerformFeatureFilter &lt;- function(datMatrix, qc_method = method, remain_num = NULL) { dat &lt;- datMatrix feat_num &lt;- ncol(dat) feat_nms &lt;- colnames(dat) nm &lt;- NULL if (qc_method == &quot;none&quot; &amp;&amp; feat_num &lt; 5000) { # only allow for less than 4000 remain &lt;- rep(TRUE, feat_num) nm &lt;- &quot;No filtering was applied&quot; } else { if (qc_method == &quot;rsd&quot;){ sds &lt;- apply(dat, 2, sd, na.rm = T) mns &lt;- apply(dat, 2, mean, na.rm = T) filter_val &lt;- abs(sds/mns) nm &lt;- &quot;Relative standard deviation&quot; } else if (qc_method == &quot;nrsd&quot; ) { mads &lt;- apply(dat, 2, mad, na.rm = T) meds &lt;- apply(dat, 2, median, na.rm = T) filter_val &lt;- abs(mads/meds) nm &lt;- &quot;Non-paramatric relative standard deviation&quot; } else if (qc_method == &quot;mean&quot;) { filter_val &lt;- apply(dat, 2, mean, na.rm = T) nm &lt;- &quot;mean&quot; } else if (qc_method == &quot;sd&quot;) { filter_val &lt;- apply(dat, 2, sd, na.rm = T) nm &lt;- &quot;standard deviation&quot; } else if (qc_method == &quot;mad&quot;) { filter_val &lt;- apply(dat, 2, mad, na.rm = T) nm &lt;- &quot;Median absolute deviation&quot; } else if (qc_method == &quot;median&quot;) { filter_val &lt;- apply(dat, 2, median, na.rm = T) nm &lt;- &quot;median&quot; } else if (qc_method == &quot;iqr&quot;) { # iqr filter_val &lt;- apply(dat, 2, IQR, na.rm = T) nm &lt;- &quot;Interquantile Range&quot; } # get the rank of the filtered variables rk &lt;- rank(-filter_val, ties.method = &quot;random&quot;) if (is.null(remain_num)) { # apply empirical filtering based on data size if (feat_num &lt; 250) { # reduce 5% remain &lt;- rk &lt; feat_num * 0.95 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 500) { # reduce 10% remain &lt;- rk &lt; feat_num * 0.9 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 1000) { # reduce 25% remain &lt;- rk &lt; feat_num * 0.75 message(&quot;Further feature filtering based on &quot;, nm) } else { # reduce 40%, if still over 5000, then only use top 5000 remain &lt;- rk &lt; feat_num * 0.6 message(&quot;Further feature filtering based on &quot;, nm) } } else { remain &lt;- rk &lt; remain_num } } res &lt;- datMatrix[, remain] return(res) } feature_res &lt;- PerformFeatureFilter(t(int_mat)) # remove QC samples feature_final &lt;- feature_res[!rownames(feature_res) %in% rownames(qc_samples), ] # save int_mat into se object target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID %in% rownames(feature_final)) res &lt;- PomaSummarizedExperiment(target = target, features = feature_final) return(res) } se_filter &lt;- FilterFeature( object = se_impute, qc_label = &quot;None&quot;, method = &quot;iqr&quot;) ## Removed 133 features based on QC RSD values. QC samples are excluded from downstream functional analysis. ## Further feature filtering based on Interquantile Range se_filter ## class: SummarizedExperiment ## dim: 44 45 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(44): M_52603 M_19130 ... M_62952 M_32197 ## rowData names(0): ## colnames(45): P101001 P101004 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.6 Data Normalization The normalization procedures are grouped into three categories. You can use one or combine them to achieve better results. Sample normalization is for general-purpose adjustment for systematic differences among samples; Sample-specific normalization (i.e. weight, volume) Normalization by sum Normalization by median Normalization by a reference sample (PQN) Normalization by a pooled sample from group (group PQN) Normalization by reference feature Quantile normalization (suggested only for &gt; 1000 features) Data transformation applies a mathematical transformation on individual values themselves. A simple mathematical approach is used to deal with negative values in log and square root. Log transformation (base 10) Square root transformation (square root of data values) Cube root transformation (cube root of data values) Data scaling adjusts each variable/feature by a scaling factor computed based on the dispersion of the variable. Mean centering (mean-centered only) Auto scaling (mean-centered and divided by the standard deviation of each variable) Pareto scaling (mean-centered and divided by the square root of the standard deviation of each variable) Range scaling (mean-centered and divided by the range of each variable) 2.6.1 Normalization by NormalizeData function NormalizeData &lt;- function( object, rowNorm = c(&quot;Quantile&quot;, &quot;GroupPQN&quot;, &quot;SamplePQN&quot;, &quot;CompNorm&quot;, &quot;SumNorm&quot;, &quot;MedianNorm&quot;, &quot;SpecNorm&quot;, &quot;None&quot;), transNorm = c(&quot;LogNorm&quot;, &quot;SrNorm&quot;, &quot;CrNorm&quot;, &quot;None&quot;), scaleNorm = c(&quot;MeanCenter&quot;, &quot;AutoNorm&quot;, &quot;ParetoNorm&quot;, &quot;RangeNorm&quot;, &quot;None&quot;), ref = NULL, SpeWeight = 1) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) data &lt;- t(features_tab) colNames &lt;- colnames(data) rowNames &lt;- rownames(data) ############################################# # Sample normalization # perform quantile normalization on the raw data (can be log transformed later by user) QuantileNormalize &lt;- function(data) { return(t(preprocessCore::normalize.quantiles(t(data), copy=FALSE))); } # normalize by a reference sample (probability quotient normalization) # ref should be the name of the reference sample ProbNorm &lt;- function(x, ref_smpl) { return(x/median(as.numeric(x/ref_smpl), na.rm = T)) } # normalize by a reference reference (i.e. creatinine) # ref should be the name of the cmpd CompNorm &lt;- function(x, ref) { return(1000*x/x[ref]) } SumNorm &lt;- function(x) { return(1000*x/sum(x, na.rm = T)) } # normalize by median MedianNorm &lt;- function(x) { return(x/median(x, na.rm = T)) } # row-wise normalization if (rowNorm == &quot;Quantile&quot;) { data &lt;- QuantileNormalize(data) # this can introduce constant variables if a variable is # at the same rank across all samples (replaced by its average across all) varCol &lt;- apply(data, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;After quantile normalization&quot;, constNum, &quot;features with a constant value were found and deleted.&quot;)) data &lt;- data[, !constCol, drop = FALSE] colNames &lt;- colnames(data) rowNames &lt;- rownames(data) } rownm &lt;- &quot;Quantile Normalization&quot; } else if (rowNorm == &quot;GroupPQN&quot;) { grp_inx &lt;- metadata_tab$group == ref ref.smpl &lt;- apply(data[grp_inx, , drop = FALSE], 2, mean) data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference group&quot; } else if (rowNorm == &quot;SamplePQN&quot;) { ref.smpl &lt;- data[ref, , drop = FALSE] data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference sample&quot; } else if (rowNorm == &quot;CompNorm&quot;) { data &lt;- t(apply(t(data), 1, CompNorm, ref)) rownm &lt;- &quot;Normalization by a reference feature&quot;; } else if (rowNorm == &quot;SumNorm&quot;) { data &lt;- t(apply(data, 1, SumNorm)) rownm &lt;- &quot;Normalization to constant sum&quot; } else if (rowNorm == &quot;MedianNorm&quot;) { data &lt;- t(apply(data, 1, MedianNorm)) rownm &lt;- &quot;Normalization to sample median&quot; } else if(rowNorm == &quot;SpecNorm&quot;) { norm.vec &lt;- rep(SpeWeight, nrow(data)) # default all same weight vec to prevent error data &lt;- data / norm.vec message(&quot;No sample specific information were given, all set to 1.0&quot;) rownm &lt;- &quot;Normalization by sample-specific factor&quot; } else { # nothing to do rownm &lt;- &quot;N/A&quot; } ################################################ # use apply will lose dimension info (i.e. row names and colnames) rownames(data) &lt;- rowNames colnames(data) &lt;- colNames # if the reference by feature, the feature column should be removed, since it is all 1 if(rowNorm == &quot;CompNorm&quot; &amp;&amp; !is.null(ref)){ inx &lt;- match(ref, colnames(data)) data &lt;- data[, -inx, drop=FALSE] colNames &lt;- colNames[-inx] } ############################################# # Data transformation # generalize log, tolerant to 0 and negative values LogNorm &lt;- function(x, min.val) { return(log10((x + sqrt(x^2 + min.val^2))/2)) } # square root, tolerant to negative values SquareRootNorm &lt;- function(x, min.val) { return(((x + sqrt(x^2 + min.val^2))/2)^(1/2)) } if (transNorm == &quot;LogNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, LogNorm, min.val) transnm &lt;- &quot;Log10 Normalization&quot; } else if (transNorm == &quot;SrNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, SquareRootNorm, min.val) transnm &lt;- &quot;Square Root Transformation&quot; } else if (transNorm == &quot;CrNorm&quot;) { norm.data &lt;- abs(data)^(1/3) norm.data[data &lt; 0] &lt;- -norm.data[data &lt; 0] data &lt;- norm.data transnm &lt;- &quot;Cubic Root Transformation&quot; } else { transnm &lt;- &quot;N/A&quot; } ############################################# ############################################# # Data scaling # normalize to zero mean and unit variance AutoNorm &lt;- function(x) { return((x - mean(x))/sd(x, na.rm = T)) } # normalize to zero mean but variance/SE ParetoNorm &lt;- function(x) { return((x - mean(x))/sqrt(sd(x, na.rm = T))) } # normalize to zero mean but variance/SE MeanCenter &lt;- function(x) { return(x - mean(x)) } # normalize to zero mean but variance/SE RangeNorm &lt;- function(x) { if (max(x) == min(x)) { return(x) } else { return((x - mean(x))/(max(x) - min(x))) } } if (scaleNorm == &quot;MeanCenter&quot;) { data &lt;- apply(data, 2, MeanCenter) scalenm &lt;- &quot;Mean Centering&quot; } else if (scaleNorm == &quot;AutoNorm&quot;) { data &lt;- apply(data, 2, AutoNorm) scalenm &lt;- &quot;Autoscaling&quot; } else if (scaleNorm == &quot;ParetoNorm&quot;) { data &lt;- apply(data, 2, ParetoNorm) scalenm &lt;- &quot;Pareto Scaling&quot; } else if (scaleNorm == &quot;RangeNorm&quot;) { data &lt;- apply(data, 2, RangeNorm) scalenm &lt;- &quot;Range Scaling&quot; } else { scalenm &lt;- &quot;N/A&quot; } ############################################# message(&quot;Row norm: &quot;, rownm, &quot;\\n&quot;, &quot;Data Transformation norm: &quot;, transnm, &quot;\\n&quot;, &quot;Data Scaling norm: &quot;, scalenm, &quot;\\n&quot;) # note after using &quot;apply&quot; function, all the attribute lost, need to add back rownames(data) &lt;- rowNames colnames(data) &lt;- colNames target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID%in%rownames(data)) se &lt;- PomaSummarizedExperiment(target = target, features = data) # need to do some sanity check, for log there may be Inf values introduced res &lt;- CheckData(se) return(res) } se_normalize &lt;- NormalizeData( object = se_impute, rowNorm = &quot;None&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;) ## Row norm: N/A ## Data Transformation norm: Log10 Normalization ## Data Scaling norm: Pareto Scaling ## All data values are numeric. ## A total of 0 (0%) missing values were detected. se_normalize ## class: SummarizedExperiment ## dim: 180 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(180): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.6.2 Normalization by POMA R package none &lt;- PomaNorm(se_impute, method = &quot;none&quot;) auto_scaling &lt;- PomaNorm(se_impute, method = &quot;auto_scaling&quot;) evel_scaling &lt;- PomaNorm(se_impute, method = &quot;level_scaling&quot;) log_scaling &lt;- PomaNorm(se_impute, method = &quot;log_scaling&quot;) log_transformation &lt;- PomaNorm(se_impute, method = &quot;log_transformation&quot;) vast_scaling &lt;- PomaNorm(se_impute, method = &quot;vast_scaling&quot;) se_normalize_v2 &lt;- PomaNorm(se_impute, method = &quot;log_pareto&quot;) se_normalize_v2 ## class: SummarizedExperiment ## dim: 180 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(180): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.6.3 Comparison of unnormalized and normalized dataset boxplot pl_unnor &lt;- PomaBoxplots(se_impute, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaBoxplots(se_normalize, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) density pl_unnor &lt;- PomaDensity(se_impute, group = &quot;features&quot;) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaDensity(se_normalize, group = &quot;features&quot;) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) 2.7 Removing outliers Calculating the pairwise distance (distance measured by “euclidean”, “maximum”, “manhattan”, “canberra” or “minkowski”), and using 1.5 in Q3 + 1.5*IQR formula to detect outliers. More details to see ?POMA::PomaOutliers. Caution: this step will remove samples regarded as outliers, please pay attention to your own data. PomaOutliers(se_normalize, do = &quot;analyze&quot;)$polygon_plot # to explore se_processed &lt;- PomaOutliers(se_normalize, do = &quot;clean&quot;) # to remove outliers se_processed ## class: SummarizedExperiment ## dim: 180 53 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(180): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(53): P101001 P101003 ... P101094 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 2.8 Data distribution get_distribution &lt;- function( datset, Type = c(&quot;raw&quot;, &quot;check&quot;, &quot;filter&quot;, &quot;impute&quot;, &quot;norm_relative&quot;, &quot;norm_log10&quot;)){ # datset = se # Type = &quot;raw&quot; dat &lt;- SummarizedExperiment::assay(datset) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;name&quot;) %&gt;% tidyr::gather(key=&quot;sample&quot;, value=&quot;value&quot;, -name) if (Type == &quot;raw&quot;) { pl &lt;- ggplot(dat, aes(x=value)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;white&quot;)+ labs(title=&quot;Distribution of Raw \\n Metabolites Intensity&quot;, x=&quot;Raw Intensity&quot;, y=&quot;Frequency&quot;)+ theme_bw() } else if (Type == &quot;check&quot;) { pl &lt;- ggplot(dat, aes(x=value)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;white&quot;)+ labs(title=&quot;Distribution of check \\n Metabolites Intensity&quot;, x=&quot;checked Intensity&quot;, y=&quot;Frequency&quot;)+ theme_bw() } else if (Type == &quot;filter&quot;) { pl &lt;- ggplot(dat, aes(x=value)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;white&quot;)+ labs(title=&quot;Distribution of filter\\n Metabolites Intensity&quot;, x=&quot;filtered Intensity&quot;, y=&quot;Frequency&quot;)+ theme_bw() } else if (Type == &quot;impute&quot;) { pl &lt;- ggplot(dat, aes(x=value)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;white&quot;)+ labs(title=&quot;Distribution of impute\\n Metabolites Intensity&quot;, x=&quot;imputed Intensity&quot;, y=&quot;Frequency&quot;)+ theme_bw() } else if (Type == &quot;norm&quot;) { pl &lt;- ggplot(dat, aes(x=value)) + geom_histogram(colour=&quot;black&quot;, fill=&quot;white&quot;)+ labs(title=&quot;Distribution of norm\\n Metabolites Intensity&quot;, x=&quot;norm&quot;, y=&quot;Frequency&quot;)+ theme_bw() } return(pl) } raw_pl &lt;- get_distribution(datset=se_raw, Type=&quot;raw&quot;) check_pl &lt;- get_distribution(datset=se_check, Type=&quot;check&quot;) filter_pl &lt;- get_distribution(datset=se_filter, Type=&quot;filter&quot;) impute_pl &lt;- get_distribution(datset=se_impute, Type=&quot;impute&quot;) norm_pl &lt;- get_distribution(datset=se_normalize_v2, Type=&quot;norm&quot;) cowplot::plot_grid(raw_pl, check_pl, filter_pl, impute_pl, norm_pl, align = &quot;hv&quot;, nrow = 2) 2.9 Saving datasets into RDS files if (!dir.exists(&quot;./dataset/POMA/&quot;)) { dir.create(&quot;./dataset/POMA/&quot;) } saveRDS(ExprSet, &quot;./dataset/POMA/ExprSet_raw.RDS&quot;, compress = TRUE) saveRDS(se_raw, &quot;./dataset/POMA/se_raw.RDS&quot;, compress = TRUE) saveRDS(se_check, &quot;./dataset/POMA/se_check.RDS&quot;, compress = TRUE) saveRDS(se_filter, &quot;./dataset/POMA/se_filter.RDS&quot;, compress = TRUE) saveRDS(se_impute, &quot;./dataset/POMA/se_impute.RDS&quot;, compress = TRUE) saveRDS(se_normalize, &quot;./dataset/POMA/se_normalize.RDS&quot;, compress = TRUE) saveRDS(se_processed, &quot;./dataset/POMA/se_processed.RDS&quot;, compress = TRUE) 2.10 Systematic Information devtools::session_info() ## ─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os macOS Monterey 12.2.1 ## system x86_64, darwin17.0 ## ui RStudio ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Asia/Shanghai ## date 2023-11-27 ## rstudio 2023.09.0+463 Desert Sunflower (desktop) ## pandoc 3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [2] CRAN (R 4.1.0) ## ade4 1.7-22 2023-02-06 [2] CRAN (R 4.1.2) ## affy 1.72.0 2021-10-26 [2] Bioconductor ## affyio 1.64.0 2021-10-26 [2] Bioconductor ## annotate 1.72.0 2021-10-26 [2] Bioconductor ## AnnotationDbi * 1.60.2 2023-03-10 [2] Bioconductor ## ape 5.7-1 2023-03-13 [2] CRAN (R 4.1.2) ## aplot 0.1.10 2023-03-08 [2] CRAN (R 4.1.2) ## attempt 0.3.1 2020-05-03 [2] CRAN (R 4.1.0) ## backports 1.4.1 2021-12-13 [2] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [2] CRAN (R 4.1.0) ## Biobase * 2.54.0 2021-10-26 [2] Bioconductor ## BiocGenerics * 0.40.0 2021-10-26 [2] Bioconductor ## BiocManager 1.30.21 2023-06-10 [2] CRAN (R 4.1.3) ## BiocParallel 1.28.3 2021-12-09 [2] Bioconductor ## biomformat 1.22.0 2021-10-26 [2] Bioconductor ## Biostrings 2.62.0 2021-10-26 [2] Bioconductor ## bit 4.0.5 2022-11-15 [2] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [2] CRAN (R 4.1.0) ## bitops 1.0-7 2021-04-24 [2] CRAN (R 4.1.0) ## blob 1.2.4 2023-03-17 [2] CRAN (R 4.1.2) ## bookdown 0.34 2023-05-09 [2] CRAN (R 4.1.2) ## broom 1.0.5 2023-06-09 [2] CRAN (R 4.1.3) ## bslib 0.6.0 2023-11-21 [1] CRAN (R 4.1.3) ## cachem 1.0.8 2023-05-01 [2] CRAN (R 4.1.2) ## Cairo 1.6-0 2022-07-05 [2] CRAN (R 4.1.2) ## callr 3.7.3 2022-11-02 [2] CRAN (R 4.1.2) ## car 3.1-2 2023-03-30 [2] CRAN (R 4.1.2) ## carData 3.0-5 2022-01-06 [2] CRAN (R 4.1.2) ## caret 6.0-94 2023-03-21 [2] CRAN (R 4.1.2) ## caTools 1.18.2 2021-03-28 [2] CRAN (R 4.1.0) ## cellranger 1.1.0 2016-07-27 [2] CRAN (R 4.1.0) ## checkmate 2.2.0 2023-04-27 [2] CRAN (R 4.1.2) ## circlize 0.4.15 2022-05-10 [2] CRAN (R 4.1.2) ## class 7.3-22 2023-05-03 [2] CRAN (R 4.1.2) ## cli 3.6.1 2023-03-23 [2] CRAN (R 4.1.2) ## clue 0.3-64 2023-01-31 [2] CRAN (R 4.1.2) ## cluster * 2.1.4 2022-08-22 [2] CRAN (R 4.1.2) ## clusterProfiler * 4.2.2 2022-01-13 [2] Bioconductor ## codetools 0.2-19 2023-02-01 [2] CRAN (R 4.1.2) ## coin 1.4-2 2021-10-08 [2] CRAN (R 4.1.0) ## colorspace 2.1-0 2023-01-23 [2] CRAN (R 4.1.2) ## ComplexHeatmap 2.10.0 2021-10-26 [2] Bioconductor ## config 0.3.1 2020-12-17 [2] CRAN (R 4.1.0) ## corpcor 1.6.10 2021-09-16 [2] CRAN (R 4.1.0) ## cowplot 1.1.1 2020-12-30 [2] CRAN (R 4.1.0) ## crayon 1.5.2 2022-09-29 [2] CRAN (R 4.1.2) ## crmn 0.0.21 2020-02-10 [2] CRAN (R 4.1.0) ## curl 5.0.1 2023-06-07 [2] CRAN (R 4.1.3) ## data.table 1.14.8 2023-02-17 [2] CRAN (R 4.1.2) ## DBI 1.1.3 2022-06-18 [2] CRAN (R 4.1.2) ## DelayedArray 0.20.0 2021-10-26 [2] Bioconductor ## dendextend * 1.17.1 2023-03-25 [2] CRAN (R 4.1.2) ## DESeq2 1.34.0 2021-10-26 [2] Bioconductor ## devtools 2.4.5 2022-10-11 [2] CRAN (R 4.1.2) ## digest 0.6.33 2023-07-07 [1] CRAN (R 4.1.3) ## DO.db 2.9 2022-04-11 [2] Bioconductor ## doParallel 1.0.17 2022-02-07 [2] CRAN (R 4.1.2) ## doRNG 1.8.6 2023-01-16 [2] CRAN (R 4.1.2) ## DOSE 3.20.1 2021-11-18 [2] Bioconductor ## doSNOW 1.0.20 2022-02-04 [2] CRAN (R 4.1.2) ## downloader 0.4 2015-07-09 [2] CRAN (R 4.1.0) ## dplyr * 1.1.2 2023-04-20 [2] CRAN (R 4.1.2) ## DT 0.28 2023-05-18 [2] CRAN (R 4.1.3) ## dynamicTreeCut * 1.63-1 2016-03-11 [2] CRAN (R 4.1.0) ## e1071 1.7-13 2023-02-01 [2] CRAN (R 4.1.2) ## edgeR 3.36.0 2021-10-26 [2] Bioconductor ## ellipse 0.4.5 2023-04-05 [2] CRAN (R 4.1.2) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.1.0) ## enrichplot 1.14.2 2022-02-24 [2] Bioconductor ## evaluate 0.21 2023-05-05 [2] CRAN (R 4.1.2) ## factoextra * 1.0.7 2020-04-01 [2] CRAN (R 4.1.0) ## fansi 1.0.4 2023-01-22 [2] CRAN (R 4.1.2) ## farver 2.1.1 2022-07-06 [2] CRAN (R 4.1.2) ## fastcluster * 1.2.3 2021-05-24 [2] CRAN (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] CRAN (R 4.1.2) ## fastmatch 1.1-3 2021-07-23 [2] CRAN (R 4.1.0) ## fdrtool 1.2.17 2021-11-13 [2] CRAN (R 4.1.0) ## fgsea 1.20.0 2021-10-26 [2] Bioconductor ## filematrix 1.3 2018-02-27 [2] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [2] CRAN (R 4.1.2) ## foreign 0.8-84 2022-12-06 [2] CRAN (R 4.1.2) ## forestplot 3.1.1 2022-12-06 [2] CRAN (R 4.1.2) ## Formula 1.2-5 2023-02-24 [2] CRAN (R 4.1.2) ## fs 1.6.2 2023-04-25 [2] CRAN (R 4.1.2) ## furrr 0.3.1 2022-08-15 [2] CRAN (R 4.1.2) ## future 1.33.0 2023-07-01 [2] CRAN (R 4.1.3) ## future.apply 1.11.0 2023-05-21 [2] CRAN (R 4.1.3) ## genefilter 1.76.0 2021-10-26 [2] Bioconductor ## geneplotter 1.72.0 2021-10-26 [2] Bioconductor ## generics 0.1.3 2022-07-05 [2] CRAN (R 4.1.2) ## GenomeInfoDb * 1.30.1 2022-01-30 [2] Bioconductor ## GenomeInfoDbData 1.2.7 2022-03-09 [2] Bioconductor ## GenomicRanges * 1.46.1 2021-11-18 [2] Bioconductor ## GetoptLong 1.0.5 2020-12-15 [2] CRAN (R 4.1.0) ## ggforce 0.4.1 2022-10-04 [2] CRAN (R 4.1.2) ## ggfun 0.1.1 2023-06-24 [2] CRAN (R 4.1.3) ## ggplot2 * 3.4.2 2023-04-03 [2] CRAN (R 4.1.2) ## ggplotify 0.1.1 2023-06-27 [2] CRAN (R 4.1.3) ## ggpubr 0.6.0 2023-02-10 [2] CRAN (R 4.1.2) ## ggraph * 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71) ## ggrepel 0.9.3 2023-02-03 [2] CRAN (R 4.1.2) ## ggsignif 0.6.4 2022-10-13 [2] CRAN (R 4.1.2) ## ggtree 3.2.1 2021-11-16 [2] Bioconductor ## glasso 1.11 2019-10-01 [2] CRAN (R 4.1.0) ## glmnet * 4.1-7 2023-03-23 [2] CRAN (R 4.1.2) ## GlobalOptions 0.1.2 2020-06-10 [2] CRAN (R 4.1.0) ## globals 0.16.2 2022-11-21 [2] CRAN (R 4.1.2) ## globaltest 5.48.0 2021-10-26 [2] Bioconductor ## glue * 1.6.2 2022-02-24 [2] CRAN (R 4.1.2) ## Gmisc * 3.0.2 2023-03-13 [2] CRAN (R 4.1.2) ## gmm 1.8 2023-06-06 [2] CRAN (R 4.1.3) ## gmp 0.7-1 2023-02-07 [2] CRAN (R 4.1.2) ## GO.db 3.14.0 2022-04-11 [2] Bioconductor ## golem 0.4.1 2023-06-05 [2] CRAN (R 4.1.3) ## GOSemSim 2.20.0 2021-10-26 [2] Bioconductor ## gower 1.0.1 2022-12-22 [2] CRAN (R 4.1.2) ## gplots 3.1.3 2022-04-25 [2] CRAN (R 4.1.2) ## graphlayouts 1.0.0 2023-05-01 [2] CRAN (R 4.1.2) ## gridExtra 2.3 2017-09-09 [2] CRAN (R 4.1.0) ## gridGraphics 0.5-1 2020-12-13 [2] CRAN (R 4.1.0) ## gtable 0.3.3 2023-03-21 [2] CRAN (R 4.1.2) ## gtools 3.9.4 2022-11-27 [2] CRAN (R 4.1.2) ## hardhat 1.3.0 2023-03-30 [2] CRAN (R 4.1.2) ## highr 0.10 2022-12-22 [2] CRAN (R 4.1.2) ## Hmisc 5.1-0 2023-05-08 [2] CRAN (R 4.1.2) ## hms 1.1.3 2023-03-21 [2] CRAN (R 4.1.2) ## htmlTable * 2.4.1 2022-07-07 [2] CRAN (R 4.1.2) ## htmltools 0.5.7 2023-11-03 [1] CRAN (R 4.1.3) ## htmlwidgets 1.6.2 2023-03-17 [2] CRAN (R 4.1.2) ## httpuv 1.6.11 2023-05-11 [2] CRAN (R 4.1.3) ## httr * 1.4.6 2023-05-08 [2] CRAN (R 4.1.2) ## huge 1.3.5 2021-06-30 [2] CRAN (R 4.1.0) ## igraph * 1.5.0 2023-06-16 [1] CRAN (R 4.1.3) ## impute 1.68.0 2021-10-26 [2] Bioconductor ## imputeLCMD 2.1 2022-06-10 [2] CRAN (R 4.1.2) ## ipred 0.9-14 2023-03-09 [2] CRAN (R 4.1.2) ## IRanges * 2.28.0 2021-10-26 [2] Bioconductor ## irlba 2.3.5.1 2022-10-03 [2] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [2] CRAN (R 4.1.2) ## itertools 0.1-3 2014-03-12 [2] CRAN (R 4.1.0) ## jpeg 0.1-10 2022-11-29 [2] CRAN (R 4.1.2) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.0) ## jsonlite 1.8.7 2023-06-29 [2] CRAN (R 4.1.3) ## KEGGREST 1.34.0 2021-10-26 [2] Bioconductor ## KernSmooth 2.23-22 2023-07-10 [2] CRAN (R 4.1.3) ## knitr 1.43 2023-05-25 [2] CRAN (R 4.1.3) ## labeling 0.4.2 2020-10-20 [2] CRAN (R 4.1.0) ## later 1.3.1 2023-05-02 [2] CRAN (R 4.1.2) ## lattice 0.21-8 2023-04-05 [2] CRAN (R 4.1.2) ## lava 1.7.2.1 2023-02-27 [2] CRAN (R 4.1.2) ## lavaan 0.6-15 2023-03-14 [2] CRAN (R 4.1.2) ## lazyeval 0.2.2 2019-03-15 [2] CRAN (R 4.1.0) ## libcoin 1.0-9 2021-09-27 [2] CRAN (R 4.1.0) ## lifecycle 1.0.3 2022-10-07 [2] CRAN (R 4.1.2) ## limma 3.50.3 2022-04-07 [2] Bioconductor ## listenv 0.9.0 2022-12-16 [2] CRAN (R 4.1.2) ## locfit 1.5-9.8 2023-06-11 [2] CRAN (R 4.1.3) ## lubridate 1.9.2 2023-02-10 [2] CRAN (R 4.1.2) ## magrittr * 2.0.3 2022-03-30 [2] CRAN (R 4.1.2) ## MALDIquant 1.22.1 2023-03-20 [2] CRAN (R 4.1.2) ## MASS 7.3-60 2023-05-04 [2] CRAN (R 4.1.2) ## massdatabase * 1.0.7 2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93) ## massdataset * 1.0.24 2023-05-30 [2] gitlab (jaspershen/massdataset@b397116) ## masstools * 1.0.10 2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc) ## Matrix * 1.6-0 2023-07-08 [2] CRAN (R 4.1.3) ## MatrixGenerics * 1.6.0 2021-10-26 [2] Bioconductor ## matrixStats * 1.0.0 2023-06-02 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.1.0) ## MetaboAnalystR * 3.2.0 2022-06-28 [2] Github (xia-lab/MetaboAnalystR@892a31b) ## metagenomeSeq 1.36.0 2021-10-26 [2] Bioconductor ## metid * 1.2.26 2023-05-30 [2] gitlab (jaspershen/metid@6bde121) ## metpath * 1.0.5 2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f) ## mgcv 1.8-42 2023-03-02 [2] CRAN (R 4.1.2) ## MicrobiomeProfiler * 1.0.0 2021-10-26 [2] Bioconductor ## mime 0.12 2021-09-28 [2] CRAN (R 4.1.0) ## miniUI 0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0) ## missForest 1.5 2022-04-14 [2] CRAN (R 4.1.2) ## mixedCCA 1.6.2 2022-09-09 [2] CRAN (R 4.1.2) ## mixOmics 6.18.1 2021-11-18 [2] Bioconductor (R 4.1.2) ## mnormt 2.1.1 2022-09-26 [2] CRAN (R 4.1.2) ## ModelMetrics 1.2.2.2 2020-03-17 [2] CRAN (R 4.1.0) ## modeltools 0.2-23 2020-03-05 [2] CRAN (R 4.1.0) ## MsCoreUtils 1.6.2 2022-02-24 [2] Bioconductor ## MSnbase * 2.20.4 2022-01-16 [2] Bioconductor ## multcomp 1.4-25 2023-06-20 [2] CRAN (R 4.1.3) ## multtest 2.50.0 2021-10-26 [2] Bioconductor ## munsell 0.5.0 2018-06-12 [2] CRAN (R 4.1.0) ## mvtnorm 1.2-2 2023-06-08 [2] CRAN (R 4.1.3) ## mzID 1.32.0 2021-10-26 [2] Bioconductor ## mzR * 2.28.0 2021-10-27 [2] Bioconductor ## ncdf4 1.21 2023-01-07 [2] CRAN (R 4.1.2) ## NetCoMi * 1.0.3 2022-07-14 [2] Github (stefpeschel/NetCoMi@d4d80d3) ## nlme 3.1-162 2023-01-31 [2] CRAN (R 4.1.2) ## nnet 7.3-19 2023-05-03 [2] CRAN (R 4.1.2) ## norm 1.0-11.1 2023-06-18 [2] CRAN (R 4.1.3) ## openxlsx 4.2.5.2 2023-02-06 [2] CRAN (R 4.1.2) ## org.Mm.eg.db * 3.14.0 2022-11-23 [2] Bioconductor ## parallelly 1.36.0 2023-05-26 [2] CRAN (R 4.1.3) ## patchwork 1.1.2 2022-08-19 [2] CRAN (R 4.1.2) ## pbapply 1.7-2 2023-06-27 [2] CRAN (R 4.1.3) ## pbivnorm 0.6.0 2015-01-23 [2] CRAN (R 4.1.0) ## pcaMethods 1.86.0 2021-10-26 [2] Bioconductor ## pcaPP 2.0-3 2022-10-24 [2] CRAN (R 4.1.2) ## permute 0.9-7 2022-01-27 [2] CRAN (R 4.1.2) ## pheatmap 1.0.12 2019-01-04 [2] CRAN (R 4.1.0) ## phyloseq 1.38.0 2021-10-26 [2] Bioconductor ## pillar 1.9.0 2023-03-22 [2] CRAN (R 4.1.2) ## pkgbuild 1.4.2 2023-06-26 [2] CRAN (R 4.1.3) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.1.0) ## pkgload 1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3) ## plotly * 4.10.2 2023-06-03 [2] CRAN (R 4.1.3) ## plyr 1.8.8 2022-11-11 [2] CRAN (R 4.1.2) ## png 0.1-8 2022-11-29 [2] CRAN (R 4.1.2) ## polyclip 1.10-4 2022-10-20 [2] CRAN (R 4.1.2) ## POMA * 1.7.2 2022-07-26 [2] Github (pcastellanoescuder/POMA@bc8a972) ## preprocessCore 1.56.0 2021-10-26 [2] Bioconductor ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.1.0) ## pROC 1.18.4 2023-07-06 [2] CRAN (R 4.1.3) ## processx 3.8.2 2023-06-30 [2] CRAN (R 4.1.3) ## prodlim 2023.03.31 2023-04-02 [2] CRAN (R 4.1.2) ## profvis 0.3.8 2023-05-02 [2] CRAN (R 4.1.2) ## progress 1.2.2 2019-05-16 [2] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0) ## ProtGenerics * 1.26.0 2021-10-26 [2] Bioconductor ## proxy 0.4-27 2022-06-09 [2] CRAN (R 4.1.2) ## ps 1.7.5 2023-04-18 [2] CRAN (R 4.1.2) ## psych 2.3.6 2023-06-21 [2] CRAN (R 4.1.3) ## pulsar 0.3.10 2023-01-26 [2] CRAN (R 4.1.2) ## purrr 1.0.1 2023-01-10 [2] CRAN (R 4.1.2) ## qgraph 1.9.5 2023-05-16 [2] CRAN (R 4.1.3) ## qs 0.25.5 2023-02-22 [2] CRAN (R 4.1.2) ## quadprog 1.5-8 2019-11-20 [2] CRAN (R 4.1.0) ## qvalue 2.26.0 2021-10-26 [2] Bioconductor ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.1.0) ## ragg 1.2.5 2023-01-12 [2] CRAN (R 4.1.2) ## randomForest 4.7-1.1 2022-05-23 [2] CRAN (R 4.1.2) ## RankProd 3.20.0 2021-10-26 [2] Bioconductor ## RApiSerialize 0.1.2 2022-08-25 [2] CRAN (R 4.1.2) ## rARPACK 0.11-0 2016-03-10 [2] CRAN (R 4.1.0) ## rbibutils 2.2.13 2023-01-13 [2] CRAN (R 4.1.2) ## RColorBrewer 1.1-3 2022-04-03 [2] CRAN (R 4.1.2) ## Rcpp * 1.0.11 2023-07-06 [1] CRAN (R 4.1.3) ## RcppParallel 5.1.7 2023-02-27 [2] CRAN (R 4.1.2) ## RCurl 1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2) ## Rdisop 1.54.0 2021-10-26 [2] Bioconductor ## Rdpack 2.4 2022-07-20 [2] CRAN (R 4.1.2) ## readr 2.1.4 2023-02-10 [2] CRAN (R 4.1.2) ## readxl * 1.4.3 2023-07-06 [2] CRAN (R 4.1.3) ## recipes 1.0.6 2023-04-25 [2] CRAN (R 4.1.2) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.1.0) ## reshape2 1.4.4 2020-04-09 [2] CRAN (R 4.1.0) ## rhdf5 2.38.1 2022-03-10 [2] Bioconductor ## rhdf5filters 1.6.0 2021-10-26 [2] Bioconductor ## Rhdf5lib 1.16.0 2021-10-26 [2] Bioconductor ## rjson 0.2.21 2022-01-09 [2] CRAN (R 4.1.2) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.1.2) ## rmarkdown 2.23 2023-07-01 [2] CRAN (R 4.1.3) ## Rmpfr 0.9-2 2023-04-22 [2] CRAN (R 4.1.2) ## rngtools 1.5.2 2021-09-20 [2] CRAN (R 4.1.0) ## rootSolve 1.8.2.3 2021-09-29 [2] CRAN (R 4.1.0) ## ropls * 1.26.4 2022-01-11 [2] Bioconductor ## rpart 4.1.19 2022-10-21 [2] CRAN (R 4.1.2) ## Rserve * 1.8-11 2022-11-28 [2] CRAN (R 4.1.2) ## RSpectra 0.16-1 2022-04-24 [2] CRAN (R 4.1.2) ## RSQLite 2.3.1 2023-04-03 [2] CRAN (R 4.1.2) ## rstatix 0.7.2 2023-02-01 [2] CRAN (R 4.1.2) ## rstudioapi 0.15.0 2023-07-07 [2] CRAN (R 4.1.3) ## rvest 1.0.3 2022-08-19 [2] CRAN (R 4.1.2) ## S4Vectors * 0.32.4 2022-03-29 [2] Bioconductor ## sandwich 3.0-2 2022-06-15 [2] CRAN (R 4.1.2) ## sass 0.4.6 2023-05-03 [2] CRAN (R 4.1.2) ## scales 1.2.1 2022-08-20 [2] CRAN (R 4.1.2) ## scatterpie 0.2.1 2023-06-07 [2] CRAN (R 4.1.3) ## scrime 1.3.5 2018-12-01 [2] CRAN (R 4.1.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.1.0) ## shadowtext 0.1.2 2022-04-22 [2] CRAN (R 4.1.2) ## shape 1.4.6 2021-05-19 [2] CRAN (R 4.1.0) ## shiny 1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3) ## shinycustomloader 0.9.0 2018-03-27 [2] CRAN (R 4.1.0) ## shinyWidgets 0.7.6 2023-01-08 [2] CRAN (R 4.1.2) ## siggenes 1.68.0 2021-10-26 [2] Bioconductor ## snow 0.4-4 2021-10-27 [2] CRAN (R 4.1.0) ## SpiecEasi * 1.1.2 2022-07-14 [2] Github (zdk123/SpiecEasi@c463727) ## SPRING * 1.0.4 2022-08-03 [2] Github (GraceYoon/SPRING@3d641a4) ## stringdist 0.9.10 2022-11-07 [2] CRAN (R 4.1.2) ## stringfish 0.15.8 2023-05-30 [2] CRAN (R 4.1.3) ## stringi 1.7.12 2023-01-11 [2] CRAN (R 4.1.2) ## stringr 1.5.0 2022-12-02 [2] CRAN (R 4.1.2) ## SummarizedExperiment * 1.24.0 2021-10-26 [2] Bioconductor ## survival 3.5-5 2023-03-12 [2] CRAN (R 4.1.2) ## systemfonts 1.0.4 2022-02-11 [2] CRAN (R 4.1.2) ## textshaping 0.3.6 2021-10-13 [2] CRAN (R 4.1.0) ## TH.data 1.1-2 2023-04-17 [2] CRAN (R 4.1.2) ## tibble * 3.2.1 2023-03-20 [2] CRAN (R 4.1.2) ## tidygraph 1.2.3 2023-02-01 [2] CRAN (R 4.1.2) ## tidyr 1.3.0 2023-01-24 [2] CRAN (R 4.1.2) ## tidyselect 1.2.0 2022-10-10 [2] CRAN (R 4.1.2) ## tidytree 0.4.2 2022-12-18 [2] CRAN (R 4.1.2) ## timechange 0.2.0 2023-01-11 [2] CRAN (R 4.1.2) ## timeDate 4022.108 2023-01-07 [2] CRAN (R 4.1.2) ## tmvtnorm 1.5 2022-03-22 [2] CRAN (R 4.1.2) ## treeio 1.18.1 2021-11-14 [2] Bioconductor ## tweenr 2.0.2 2022-09-06 [2] CRAN (R 4.1.2) ## tzdb 0.4.0 2023-05-12 [2] CRAN (R 4.1.3) ## urlchecker 1.0.1 2021-11-30 [2] CRAN (R 4.1.0) ## usethis 2.2.2 2023-07-06 [2] CRAN (R 4.1.3) ## utf8 1.2.3 2023-01-31 [2] CRAN (R 4.1.2) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.1.3) ## vegan 2.6-4 2022-10-11 [2] CRAN (R 4.1.2) ## VGAM 1.1-8 2023-03-09 [2] CRAN (R 4.1.2) ## viridis 0.6.3 2023-05-03 [2] CRAN (R 4.1.2) ## viridisLite 0.4.2 2023-05-02 [2] CRAN (R 4.1.2) ## vsn 3.62.0 2021-10-26 [2] Bioconductor ## WGCNA * 1.72-1 2023-01-18 [2] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.1.2) ## Wrench 1.12.0 2021-10-26 [2] Bioconductor ## xfun 0.40 2023-08-09 [1] CRAN (R 4.1.3) ## XMAS2 * 2.2.0 2023-10-27 [1] local ## XML 3.99-0.14 2023-03-19 [2] CRAN (R 4.1.2) ## xml2 1.3.5 2023-07-06 [2] CRAN (R 4.1.3) ## xtable 1.8-4 2019-04-21 [2] CRAN (R 4.1.0) ## XVector 0.34.0 2021-10-26 [2] Bioconductor ## yaml 2.3.7 2023-01-23 [2] CRAN (R 4.1.2) ## yulab.utils 0.0.6 2022-12-20 [2] CRAN (R 4.1.2) ## zip 2.3.0 2023-04-17 [2] CRAN (R 4.1.2) ## zlibbioc 1.40.0 2021-10-26 [2] Bioconductor ## zoo 1.8-12 2023-04-13 [2] CRAN (R 4.1.2) ## ## [1] /Users/zouhua/Library/R/x86_64/4.1/library ## [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library ## ## ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── References "],["statistical-analysis-1.html", "Chapter 3 Statistical Analysis 3.1 Data Preprocessing 3.2 Cluster Analysis 3.3 Chemometrics Analysis 3.4 Univariate Analysis 3.5 Multivariate analysis 3.6 Network Analysis 3.7 Systematic Information", " Chapter 3 Statistical Analysis Although the horrible experience of data analysis by using MetaboAnalystR R package (Pang et al. 2020), its thought of data processing are very useful. Therefore, this template is based on the workflow from MetaboAnalystR. In this chapter, very detailed explaination of the available methods in each step in Statistical Analysis would be introduced. Users can nevertheless go through the whole analysis from with example data in Chapter 4. 3.1 Data Preprocessing We integrated R packages and our own scripts to build the data analysis template for metabolomics data. Particularly, we thanks very much for POMA R package (Castellano-Escuder et al. 2021). POMA is a flexible data cleaning and statistical analysis processes in one comprehensible and user-friendly R package. Note: Please remember to preprocess your data before Cluster Analysis and other steps below. 3.1.1 Environment setup knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(Biobase) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(readxl) library(SummarizedExperiment) library(ropls) library(XMAS2) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.1.2 Loading data The dataset is from the Zeybel-2022 published paper (Zeybel et al. 2022). features table profile &lt;- readxl::read_xlsx(&quot;./dataset/OmicsDataSet-Zeybel-2022.xlsx&quot;, sheet = 6) head(profile) ## # A tibble: 6 × 67 ## BIOCHEMICAL `SUPER PATHWAY` `SUB PATHWAY` `COMP ID` PLATFORM `CHEMICAL ID` RI MASS PUBCHEM CAS KEGG `SampleID HMDBID` P101001 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 (14 or 15)-meth… Lipid Fatty Acid, … 38768 LC/MS N… 100002945 5695 269. 8181;1… &lt;NA&gt; C169… HMDB0061859 5.11e7 ## 2 (16 or 17)-meth… Lipid Fatty Acid, … 38296 LC/MS N… 100002356 5993 297. 3083779 2724… &lt;NA&gt; HMDB0037397 5.11e6 ## 3 (2 or 3)-deceno… Lipid Medium Chain… 63436 LC/MS N… 100021502 4990 169. &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 7.57e5 ## 4 (2,4 or 2,5)-di… Xenobiotics Food Compone… 62533 LC/MS N… 100020519 3474 201. &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA ## 5 (N(1) + N(8))-a… Amino Acid Polyamine Me… 57814 LC/MS P… 100016038 3080 188. 123689… &lt;NA&gt; C006… HMDB0001276,HMDB… 2.82e5 ## 6 (R)-3-hydroxybu… Lipid Fatty Acid M… 43264 LC/MS P… 100003926 2400 248. 534816… &lt;NA&gt; &lt;NA&gt; HMDB0013127 NA ## # ℹ 54 more variables: P101012 &lt;dbl&gt;, P101030 &lt;dbl&gt;, P101031 &lt;dbl&gt;, P101050 &lt;dbl&gt;, P101059 &lt;dbl&gt;, P101071 &lt;dbl&gt;, P101072 &lt;dbl&gt;, ## # P101084 &lt;dbl&gt;, P101003 &lt;dbl&gt;, P101004 &lt;dbl&gt;, P101013 &lt;dbl&gt;, P101016 &lt;dbl&gt;, P101017 &lt;dbl&gt;, P101038 &lt;dbl&gt;, P101051 &lt;dbl&gt;, P101061 &lt;dbl&gt;, ## # P101062 &lt;dbl&gt;, P101074 &lt;dbl&gt;, P101075 &lt;dbl&gt;, P101076 &lt;dbl&gt;, P101085 &lt;dbl&gt;, P101088 &lt;dbl&gt;, P101007 &lt;dbl&gt;, P101018 &lt;dbl&gt;, P101019 &lt;dbl&gt;, ## # P101041 &lt;dbl&gt;, P101052 &lt;dbl&gt;, P101064 &lt;dbl&gt;, P101065 &lt;dbl&gt;, P101077 &lt;dbl&gt;, P101090 &lt;dbl&gt;, P101094 &lt;dbl&gt;, P101009 &lt;dbl&gt;, P101010 &lt;dbl&gt;, ## # P101021 &lt;dbl&gt;, P101022 &lt;dbl&gt;, P101042 &lt;dbl&gt;, P101054 &lt;dbl&gt;, P101056 &lt;dbl&gt;, P101067 &lt;dbl&gt;, P101068 &lt;dbl&gt;, P101079 &lt;dbl&gt;, P101095 &lt;dbl&gt;, ## # P101096 &lt;dbl&gt;, P101011 &lt;dbl&gt;, P101024 &lt;dbl&gt;, P101025 &lt;dbl&gt;, P101027 &lt;dbl&gt;, P101047 &lt;dbl&gt;, P101057 &lt;dbl&gt;, P101069 &lt;dbl&gt;, P101080 &lt;dbl&gt;, ## # P101081 &lt;dbl&gt;, P101082 &lt;dbl&gt; metadata table metadata &lt;- readxl::read_xlsx(&quot;./dataset/OmicsDataSet-Zeybel-2022.xlsx&quot;, sheet = 2) head(metadata) ## # A tibble: 6 × 11 ## PatientID Stage Metabolomics Proteomics GutMetagenomics OralMetagenomics LiverFatClass Gender AlcoholConsumption Smoker Age ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 P101001 Before Send Send Send Send Severe Male No No 52 ## 2 P101003 Before Send Send Send Send None Female No No 31 ## 3 P101004 Before Send Send Send Send Moderate Male Yes No 43 ## 4 P101007 Before Send Send Send Send Severe Female No No 61 ## 5 P101009 Before Send Send Send Send Moderate Male No Yes 51 ## 6 P101010 Before Send Send Send Send Mild Male Yes No 27 3.1.3 Object Preparation Data Preparation: ExpressionSet object get_ExpressionSet &lt;- function( x, y) { # x = metadata # y = profile phen &lt;- x %&gt;% dplyr::mutate(Metabolomics == &quot;Send&quot;) %&gt;% dplyr::select(PatientID, LiverFatClass, Gender, Smoker, Age, AlcoholConsumption) sid &lt;- intersect(phen$PatientID, colnames(y)) prof &lt;- y %&gt;% dplyr::select(all_of(sid)) %&gt;% data.frame() rownames(prof) &lt;- paste0(&quot;M_&quot;, y$`COMP ID`) phen &lt;- phen[pmatch(sid, phen$PatientID), , F] %&gt;% tibble::column_to_rownames(&quot;PatientID&quot;) feat &lt;- y %&gt;% dplyr::select(1:12) %&gt;% as.data.frame() rownames(feat) &lt;- paste0(&quot;M_&quot;, y$`COMP ID`) # expressionSet phen_ADF &lt;- new(&quot;AnnotatedDataFrame&quot;, data=phen) feature_ADF &lt;- new(&quot;AnnotatedDataFrame&quot;, data=feat) experimentData &lt;- new( &quot;MIAME&quot;, name=&quot;Hua&quot;, lab=&quot;Xbiome Company&quot;, contact=&quot;Hua@xbiome.com&quot;, title=&quot;Metabolomics&quot;, abstract=&quot;The Mass Spectrometry ExpressionSet without imputation value&quot;, url=&quot;www.xbiome.cn&quot;, other=list(notes=&quot;Metabolomics&quot;)) expressionSet &lt;- new( &quot;ExpressionSet&quot;, exprs=prof, phenoData=phen_ADF, featureData=feature_ADF, experimentData=experimentData) return(expressionSet) } ExprSet &lt;- get_ExpressionSet(x = metadata, y = profile) ExprSet ## ExpressionSet (storageMode: lockedEnvironment) ## assayData: 1032 features, 55 samples ## element names: exprs ## protocolData: none ## phenoData ## sampleNames: P101001 P101003 ... P101096 (55 total) ## varLabels: LiverFatClass Gender ... AlcoholConsumption (5 total) ## varMetadata: labelDescription ## featureData ## featureNames: M_38768 M_38296 ... M_15581 (1032 total) ## fvarLabels: BIOCHEMICAL SUPER PATHWAY ... SampleID HMDBID (12 total) ## fvarMetadata: labelDescription ## experimentData: use &#39;experimentData(object)&#39; ## Annotation: Data Preparation: SummarizedExperiment object getSEobject &lt;- function(x, y) { target &lt;- x %&gt;% dplyr::mutate(Metabolomics == &quot;Send&quot;) %&gt;% dplyr::select(PatientID, LiverFatClass, Gender, Smoker, Age, AlcoholConsumption) sid &lt;- intersect(target$PatientID, colnames(profile)) features &lt;- y %&gt;% dplyr::select(all_of(sid)) %&gt;% data.frame() %&gt;% t() colnames(features) &lt;- paste0(&quot;M_&quot;, profile$`COMP ID`) target &lt;- target[pmatch(sid, target$PatientID), , F] res &lt;- PomaSummarizedExperiment(target = target, features = features) return(res) } se_raw &lt;- getSEobject(metadata, profile) se_raw ## class: SummarizedExperiment ## dim: 1032 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(1032): M_38768 M_38296 ... M_57517 M_15581 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption Extract data for test dataset get_testData &lt;- function(object, num = 200) { features_tab &lt;- SummarizedExperiment::assay(object) %&gt;% t() metadata_tab &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;ID&quot;) res &lt;- PomaSummarizedExperiment(target = metadata_tab, features = features_tab[, 1:num]) return(res) } se_raw &lt;- get_testData(object = se_raw) se_raw ## class: SummarizedExperiment ## dim: 200 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(200): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.4 Data Checking Features in PomaSummarizedExperiment object must have the following criterion: All data values are numeric. A total of 0 (0%) missing values were detected. CheckData &lt;- function(object) { features_tab &lt;- SummarizedExperiment::assay(object) # numeric &amp; missing values int_mat &lt;- features_tab rowNms &lt;- rownames(int_mat) colNms &lt;- colnames(int_mat) naNms &lt;- sum(is.na(int_mat)) for (i in 1:ncol(int_mat)) { if (class(int_mat[, i]) == &quot;integer64&quot;) { int_mat[, i] &lt;- as.double(int_mat[, i]) } } num_mat &lt;- apply(int_mat, 2, as.numeric) if (sum(is.na(num_mat)) &gt; naNms) { num_mat &lt;- apply(int_mat, 2, function(x) as.numeric(gsub(&quot;,&quot;, &quot;&quot;, x))) if (sum(is.na(num_mat)) &gt; naNms) { message(&quot;&lt;font color=\\&quot;red\\&quot;&gt;Non-numeric values were found and replaced by NA.&lt;/font&gt;&quot;) } else { message(&quot;All data values are numeric.&quot;) } } else { message(&quot;All data values are numeric.&quot;) } int_mat &lt;- num_mat rownames(int_mat) &lt;- rowNms colnames(int_mat) &lt;- colNms varCol &lt;- apply(int_mat, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;&lt;font color=\\&quot;red\\&quot;&gt;&quot;, constNum, &quot;features with a constant or single value across samples were found and deleted.&lt;/font&gt;&quot;)) int_mat &lt;- int_mat[, !constCol, drop = FALSE] } totalCount &lt;- nrow(int_mat) * ncol(int_mat) naCount &lt;- sum(is.na(int_mat)) naPercent &lt;- round(100 * naCount/totalCount, 1) message(paste(&quot;A total of &quot;, naCount, &quot; (&quot;, naPercent, &quot;%) missing values were detected.&quot;, sep = &quot;&quot;)) # save int_mat into se object target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = t(int_mat)) return(res) } se_check &lt;- CheckData(object = se_raw) ## All data values are numeric. ## A total of 1146 (10.4%) missing values were detected. se_check ## class: SummarizedExperiment ## dim: 200 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(200): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.5 Missing value imputation “none”: all missing values will be replaced by zero. “LOD”: specific Limit Of Detection which provides by user. “half_min”: half minimal values across samples except zero. “median”: median values across samples except zero. “mean”: mean values across samples except zero. “min”: minimal values across samples except zero. “knn”: k-nearest neighbors samples. “rf”: nonparametric missing value imputation using Random Forest. “QRILC”: missing values imputation based quantile regression. (default: “none”). impute_abundance &lt;- function( object, group, ZerosAsNA = FALSE, RemoveNA = TRUE, prevalence = 0.5, method = c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;), LOD = NULL) { # object = se_check # group = &quot;group&quot; # ZerosAsNA = TRUE # RemoveNA = TRUE # prevalence = 0.5 # method = &quot;knn&quot; if (base::missing(object)) { stop(&quot;object argument is empty!&quot;) } if (!methods::is(object, &quot;SummarizedExperiment&quot;)) { stop(&quot;object is not either a phyloseq or SummarizedExperiment object.&quot;) } method &lt;- match.arg( method, c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;) ) if (base::missing(method)) { message(&quot;method argument is empty! KNN will be used&quot;) } # profile: row-&gt;samples; col-&gt;features if (all(!is.null(object), inherits(object, &quot;SummarizedExperiment&quot;))) { # sample table &amp; profile table sam_tab &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;TempRowNames&quot;) prf_tab &lt;- SummarizedExperiment::assay(object) %&gt;% data.frame() %&gt;% t() } group_index &lt;- which(colnames(sam_tab) == group) samples_groups &lt;- sam_tab[, group_index] to_imp_data &lt;- prf_tab %&gt;% as.matrix() if (ZerosAsNA) { to_imp_data[to_imp_data == 0] &lt;- NA to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } else { to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } percent_na &lt;- sum(is.na(to_imp_data)) if (percent_na == 0) { message(&quot;No missing values detected in your data&quot;) if (method != &quot;none&quot;) { method &lt;- &quot;none&quot; } } if (isTRUE(RemoveNA)) { count_NA &lt;- stats::aggregate( . ~ Group, data = to_imp_data, function(x) {(sum(is.na(x)) / (sum(is.na(x)) + sum(!is.na(x))) ) }, na.action = NULL) count_NA &lt;- count_NA %&gt;% dplyr::select(-Group) correct_names &lt;- names(count_NA) supress &lt;- unlist(as.data.frame(lapply(count_NA, function(x) any(x &gt; prevalence)))) names(supress) &lt;- correct_names correct_names &lt;- names(supress[supress == &quot;FALSE&quot;]) depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)][!supress] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) } else { depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) correct_names &lt;- colnames(prf_tab) } # Row-&gt;feature;Col-&gt;sample if (method == &quot;none&quot;) { depurdata[is.na(depurdata)] &lt;- 0 } else if (method == &quot;LOD&quot;) { if (is.null(LOD)) { message(&quot;No LOD provided, regard one-tenth mininal value as LOD&quot;) depurdata_withoutNA &lt;- depurdata[!is.na(depurdata)] LOD &lt;- min(depurdata_withoutNA[depurdata_withoutNA != 0]) / 10 } depurdata[is.na(depurdata)] &lt;- LOD depurdata[depurdata == 0] &lt;- LOD } else if (method == &quot;half_min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE)/2, x) else x}) } else if (method == &quot;median&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), median(x, na.rm = TRUE), x) else x}) } else if (method == &quot;mean&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), mean(x, na.rm = TRUE), x) else x}) } else if (method == &quot;min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE), x) else x}) } else if (method == &quot;knn&quot;) { depurdata &lt;- t(depurdata) datai &lt;- impute::impute.knn(depurdata, k = 20) depurdata &lt;- t(datai$data) } else if (method == &quot;rf&quot;) { fit &lt;- missForest::missForest(t(depurdata)) depurdata &lt;- fit$ximp %&gt;% t() } else if (method == &quot;QRILC&quot;) { fit &lt;- log(t(depurdata)) %&gt;% imputeLCMD::impute.QRILC() depurdata &lt;- t(fit[[1]]) } colnames(depurdata) &lt;- correct_names rownames(depurdata) &lt;- rownames(prf_tab) if (methods::is(object, &quot;SummarizedExperiment&quot;)) { target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = depurdata) } return(res) } se_impute &lt;- impute_abundance( se_check, group = &quot;group&quot;, ZerosAsNA = TRUE, RemoveNA = TRUE, prevalence = 0.5, method = &quot;knn&quot;) se_impute ## class: SummarizedExperiment ## dim: 180 55 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(180): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(55): P101001 P101003 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption # profile head(SummarizedExperiment::assay(se_impute)) ## P101001 P101003 P101004 P101007 P101009 P101010 P101011 P101012 P101013 P101016 P101017 ## M_38768 51127588.0 42040432.0 34940596.00 58518636.0 51118832.00 83783688.0 29017984.0 51222064.00 77550128.0 30949554.0 26923596.00 ## M_38296 5105020.5 4006120.2 3885477.00 4285129.5 6665653.50 9057441.0 2802655.2 5996555.00 11367511.0 3874736.8 2817151.00 ## M_63436 756686.2 983889.2 851026.50 726593.9 232959.52 650261.1 541954.8 598491.00 438885.6 1625844.8 566466.94 ## M_57814 281502.0 175893.0 297304.38 319016.7 242172.20 200135.8 242804.9 248842.02 377212.6 183718.3 232514.53 ## M_52984 125465.8 154494.6 128320.37 176100.9 77345.62 122282.8 131924.3 80226.58 102010.7 129011.9 97377.79 ## M_48762 559069.1 596473.9 53293.76 627140.5 7016015.00 1914246.9 2762589.2 140576.45 723530.9 295995.2 3321584.25 ## P101018 P101019 P101021 P101022 P101024 P101025 P101027 P101030 P101031 P101038 P101041 ## M_38768 56720032.00 27956064.0 48723600.00 16282054.0 77028824.0 32022342.0 22589448.0 38449788.0 59134052.0 32038030.0 20833830.00 ## M_38296 8029728.00 3766663.8 5174967.00 1746182.9 5519105.5 2557365.0 1882902.6 2860324.2 4721201.0 4011627.5 2938779.00 ## M_63436 427850.62 519559.0 1301591.25 1474247.4 970475.8 628680.1 635516.6 367246.8 512037.9 852000.1 634488.56 ## M_57814 279062.56 195083.9 290545.53 514479.0 420295.6 181825.7 196115.8 231290.3 315392.4 248820.8 214474.08 ## M_52984 98456.04 361975.5 119374.53 169170.4 101209.9 105117.3 104063.2 153193.4 181312.4 235948.1 68496.68 ## M_48762 3489639.25 417727.6 16078.62 24787876.0 2287562.2 4724330.0 2960643.8 1503947.2 338791.1 1028211.6 16129281.00 ## P101042 P101047 P101050 P101051 P101052 P101054 P101056 P101057 P101059 P101061 P101062 ## M_38768 33809080.00 18637508.00 21978476.0 24265162.0 52203780.00 12836384.0 18546636.0 32301820.0 22645984.0 23683254.00 29027646.0 ## M_38296 3017260.50 1935144.12 2897211.0 2476279.5 5928454.00 1685760.6 1650011.0 3419157.8 2196044.2 3217499.25 4060367.8 ## M_63436 1680135.75 326005.62 316650.2 737202.9 459385.94 346176.6 585470.2 417958.5 734586.3 337035.72 982299.4 ## M_57814 295862.56 397441.94 253910.2 295948.6 246857.86 330762.7 209301.7 265086.1 181746.3 256601.55 187952.7 ## M_52984 112239.87 94186.81 112969.0 118040.4 115115.18 142644.3 103307.2 113114.2 89261.8 56381.96 186628.3 ## M_48762 87286.19 2211343.75 98800.9 1933066.2 54885.02 4003695.2 1786579.6 2497416.7 10217042.0 7272486.00 4477679.0 ## P101064 P101065 P101067 P101068 P101069 P101071 P101072 P101074 P101075 P101076 P101077 ## M_38768 32629048.0 22950806.00 33555116.00 44283972.0 52685972.0 32415040.0 34170948.0 22550616.0 22058076.00 24455466.0 25225170.0 ## M_38296 3031529.5 2467147.25 3567913.25 6525382.0 3984333.5 3001414.5 4679519.0 2529255.5 2583265.50 3515218.2 3272875.0 ## M_63436 1255148.0 637699.06 284516.12 664800.1 684813.6 596846.1 316855.0 646136.8 198381.73 255897.7 547243.4 ## M_57814 165441.1 203872.41 238433.59 220632.9 209510.0 412294.9 335871.3 229869.7 225894.31 201601.9 285970.2 ## M_52984 179940.6 82205.24 56987.89 144673.7 151451.9 131184.4 127776.5 102868.8 64535.59 105523.9 130333.8 ## M_48762 395835.7 460618.81 8156659.00 3966085.0 2887422.5 190455.1 46928844.0 3240584.5 91241.58 3088418.0 6992567.5 ## P101079 P101080 P101081 P101082 P101084 P101085 P101088 P101090 P101094 P101095 P101096 ## M_38768 15718590.0 29120336.0 65904836.0 22908578.0 29140440.0 20427124.0 29199012.00 24042020.00 36910084.00 35662068.0 66402192.00 ## M_38296 2449462.5 2695001.5 6474709.5 2110243.8 3648091.2 3253531.8 4154170.75 2396959.75 4759584.50 3452283.2 6374383.00 ## M_63436 508791.6 1256550.2 339909.3 596292.2 497300.8 309859.3 601515.12 794206.00 414972.84 3606340.5 1077637.50 ## M_57814 191453.5 264148.1 212220.1 335886.6 228471.4 345303.3 333549.22 321148.53 313197.78 500135.6 226660.25 ## M_52984 127343.7 153657.1 125355.2 107572.9 151915.6 106491.1 89181.83 147634.67 91856.74 340070.0 137341.48 ## M_48762 1325582.1 600080.8 3410091.7 1303324.6 684199.1 2319273.2 854781.06 92700.81 1132143.00 31216882.0 34001.17 3.1.6 Data Filtering The purpose of the data filtering is to identify and remove variables that are unlikely to be of use when modeling the data. No phenotype information are used in the filtering process, so the result can be used with any downstream analysis. This step is strongly recommended for untargeted metabolomics datasets (i.e. spectral binning data, peak lists) with large number of variables, many of them are from baseline noises. Filtering can usually improve the results. For details, please refer to the paper by Hackstadt, et al. Non-informative variables can be characterized in three groups: 1) variables of very small values (close to baseline or detection limit) - these variables can be detected using mean or median; 2) variables that are near-constant values throughout the experiment conditions (housekeeping or homeostasis) - these variables can be detected using standard deviation (SD); or the robust estimate such as interquantile range (IQR); and 3) variables that show low repeatability - this can be measured using QC samples using the relative standard deviation(RSD = SD/mean). Features with high percent RSD should be removed from the subsequent analysis (the suggested threshold is 20% for LC-MS and 30% for GC-MS). For data filtering based on the first two categories, the following empirical rules are applied during data filtering: Less than 250 variables: 5% will be filtered; Between 250 - 500 variables: 10% will be filtered; Between 500 - 1000 variables: 25% will be filtered; Over 1000 variables: 40% will be filtered; Filtering features if their RSDs are &gt; 25% in QC samples Interquantile range (IQR) Standard deviation (SD) Median absolute deviation (MAD) Relative standard deviation (RSD = SD/mean) Non-parametric relative standard deviation (MAD/median) Mean intensity value Median intensity value FilterFeature &lt;- function( object, qc_label, method = c(&quot;none&quot;, &quot;iqr&quot;, &quot;rsd&quot;, &quot;nrsd&quot;, &quot;mean&quot;, &quot;sd&quot;, &quot;mad&quot;, &quot;median&quot;), rsd_cutoff = 25) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) # QC samples qc_samples &lt;- metadata_tab %&gt;% data.frame() %&gt;% dplyr::filter(group == qc_label) if (dim(qc_samples)[1] == 0) { stop(&quot;No qc samples have been chosen, please check your input&quot;) } # QC samples&#39; feature table qc_feature &lt;- features_tab[, colnames(features_tab)%in%rownames(qc_samples)] %&gt;% t() # filter features by QC RSD rsd &lt;- rsd_cutoff / 100 sds &lt;- apply(qc_feature, 2, sd, na.rm = T) mns &lt;- apply(qc_feature, 2, mean, na.rm = T) rsd_vals &lt;- abs(sds/mns) %&gt;% na.omit() gd_inx &lt;- rsd_vals &lt; rsd int_mat &lt;- features_tab[gd_inx, ] message(&quot;Removed &quot;, (dim(qc_feature)[2] - dim(int_mat)[1]), &quot; features based on QC RSD values. QC samples are excluded from downstream functional analysis.&quot;) # whether to filter features by percentage according to the number PerformFeatureFilter &lt;- function(datMatrix, qc_method = method, remain_num = NULL) { dat &lt;- datMatrix feat_num &lt;- ncol(dat) feat_nms &lt;- colnames(dat) nm &lt;- NULL if (qc_method == &quot;none&quot; &amp;&amp; feat_num &lt; 5000) { # only allow for less than 4000 remain &lt;- rep(TRUE, feat_num) nm &lt;- &quot;No filtering was applied&quot; } else { if (qc_method == &quot;rsd&quot;){ sds &lt;- apply(dat, 2, sd, na.rm = T) mns &lt;- apply(dat, 2, mean, na.rm = T) filter_val &lt;- abs(sds/mns) nm &lt;- &quot;Relative standard deviation&quot; } else if (qc_method == &quot;nrsd&quot; ) { mads &lt;- apply(dat, 2, mad, na.rm = T) meds &lt;- apply(dat, 2, median, na.rm = T) filter_val &lt;- abs(mads/meds) nm &lt;- &quot;Non-paramatric relative standard deviation&quot; } else if (qc_method == &quot;mean&quot;) { filter_val &lt;- apply(dat, 2, mean, na.rm = T) nm &lt;- &quot;mean&quot; } else if (qc_method == &quot;sd&quot;) { filter_val &lt;- apply(dat, 2, sd, na.rm = T) nm &lt;- &quot;standard deviation&quot; } else if (qc_method == &quot;mad&quot;) { filter_val &lt;- apply(dat, 2, mad, na.rm = T) nm &lt;- &quot;Median absolute deviation&quot; } else if (qc_method == &quot;median&quot;) { filter_val &lt;- apply(dat, 2, median, na.rm = T) nm &lt;- &quot;median&quot; } else if (qc_method == &quot;iqr&quot;) { # iqr filter_val &lt;- apply(dat, 2, IQR, na.rm = T) nm &lt;- &quot;Interquantile Range&quot; } # get the rank of the filtered variables rk &lt;- rank(-filter_val, ties.method = &quot;random&quot;) if (is.null(remain_num)) { # apply empirical filtering based on data size if (feat_num &lt; 250) { # reduce 5% remain &lt;- rk &lt; feat_num * 0.95 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 500) { # reduce 10% remain &lt;- rk &lt; feat_num * 0.9 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 1000) { # reduce 25% remain &lt;- rk &lt; feat_num * 0.75 message(&quot;Further feature filtering based on &quot;, nm) } else { # reduce 40%, if still over 5000, then only use top 5000 remain &lt;- rk &lt; feat_num * 0.6 message(&quot;Further feature filtering based on &quot;, nm) } } else { remain &lt;- rk &lt; remain_num } } res &lt;- datMatrix[, remain] return(res) } feature_res &lt;- PerformFeatureFilter(t(int_mat)) # remove QC samples feature_final &lt;- feature_res[!rownames(feature_res) %in% rownames(qc_samples), ] # save int_mat into se object target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID %in% rownames(feature_final)) res &lt;- PomaSummarizedExperiment(target = target, features = feature_final) return(res) } se_filter &lt;- FilterFeature( object = se_impute, qc_label = &quot;None&quot;, method = &quot;iqr&quot;, rsd_cutoff = 100) # default values: rsd_cutoff = 25 ## Removed 4 features based on QC RSD values. QC samples are excluded from downstream functional analysis. ## Further feature filtering based on Interquantile Range se_filter ## class: SummarizedExperiment ## dim: 167 45 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(167): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(45): P101001 P101004 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.7 Data Normalization The normalization procedures are grouped into three categories. You can use one or combine them to achieve better results. Sample normalization is for general-purpose adjustment for systematic differences among samples; Sample-specific normalization (i.e. weight, volume) Normalization by sum Normalization by median Normalization by a reference sample (PQN) Normalization by a pooled sample from group (group PQN) Normalization by reference feature Quantile normalization (suggested only for &gt; 1000 features) Data transformation applies a mathematical transformation on individual values themselves. A simple mathematical approach is used to deal with negative values in log and square root. Log transformation (base 10) Square root transformation (square root of data values) Cube root transformation (cube root of data values) Data scaling adjusts each variable/feature by a scaling factor computed based on the dispersion of the variable. Mean centering (mean-centered only) Auto scaling (mean-centered and divided by the standard deviation of each variable) Pareto scaling (mean-centered and divided by the square root of the standard deviation of each variable) Range scaling (mean-centered and divided by the range of each variable) 3.1.7.1 Normalization by NormalizeData function NormalizeData &lt;- function( object, rowNorm = c(&quot;Quantile&quot;, &quot;GroupPQN&quot;, &quot;SamplePQN&quot;, &quot;CompNorm&quot;, &quot;SumNorm&quot;, &quot;MedianNorm&quot;, &quot;SpecNorm&quot;, &quot;None&quot;), transNorm = c(&quot;LogNorm&quot;, &quot;SrNorm&quot;, &quot;CrNorm&quot;, &quot;None&quot;), scaleNorm = c(&quot;MeanCenter&quot;, &quot;AutoNorm&quot;, &quot;ParetoNorm&quot;, &quot;RangeNorm&quot;, &quot;None&quot;), ref = NULL, SpeWeight = 1) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) data &lt;- t(features_tab) colNames &lt;- colnames(data) rowNames &lt;- rownames(data) ############################################# # Sample normalization # perform quantile normalization on the raw data (can be log transformed later by user) QuantileNormalize &lt;- function(data) { return(t(preprocessCore::normalize.quantiles(t(data), copy=FALSE))); } # normalize by a reference sample (probability quotient normalization) # ref should be the name of the reference sample ProbNorm &lt;- function(x, ref_smpl) { return(x/median(as.numeric(x/ref_smpl), na.rm = T)) } # normalize by a reference reference (i.e. creatinine) # ref should be the name of the cmpd CompNorm &lt;- function(x, ref) { return(1000*x/x[ref]) } SumNorm &lt;- function(x) { return(1000*x/sum(x, na.rm = T)) } # normalize by median MedianNorm &lt;- function(x) { return(x/median(x, na.rm = T)) } # row-wise normalization if (rowNorm == &quot;Quantile&quot;) { data &lt;- QuantileNormalize(data) # this can introduce constant variables if a variable is # at the same rank across all samples (replaced by its average across all) varCol &lt;- apply(data, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;After quantile normalization&quot;, constNum, &quot;features with a constant value were found and deleted.&quot;)) data &lt;- data[, !constCol, drop = FALSE] colNames &lt;- colnames(data) rowNames &lt;- rownames(data) } rownm &lt;- &quot;Quantile Normalization&quot; } else if (rowNorm == &quot;GroupPQN&quot;) { grp_inx &lt;- metadata_tab$group == ref ref.smpl &lt;- apply(data[grp_inx, , drop = FALSE], 2, mean) data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference group&quot; } else if (rowNorm == &quot;SamplePQN&quot;) { ref.smpl &lt;- data[ref, , drop = FALSE] data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference sample&quot; } else if (rowNorm == &quot;CompNorm&quot;) { data &lt;- t(apply(t(data), 1, CompNorm, ref)) rownm &lt;- &quot;Normalization by a reference feature&quot;; } else if (rowNorm == &quot;SumNorm&quot;) { data &lt;- t(apply(data, 1, SumNorm)) rownm &lt;- &quot;Normalization to constant sum&quot; } else if (rowNorm == &quot;MedianNorm&quot;) { data &lt;- t(apply(data, 1, MedianNorm)) rownm &lt;- &quot;Normalization to sample median&quot; } else if(rowNorm == &quot;SpecNorm&quot;) { norm.vec &lt;- rep(SpeWeight, nrow(data)) # default all same weight vec to prevent error data &lt;- data / norm.vec message(&quot;No sample specific information were given, all set to 1.0&quot;) rownm &lt;- &quot;Normalization by sample-specific factor&quot; } else { # nothing to do rownm &lt;- &quot;N/A&quot; } ################################################ # use apply will lose dimension info (i.e. row names and colnames) rownames(data) &lt;- rowNames colnames(data) &lt;- colNames # if the reference by feature, the feature column should be removed, since it is all 1 if(rowNorm == &quot;CompNorm&quot; &amp;&amp; !is.null(ref)){ inx &lt;- match(ref, colnames(data)) data &lt;- data[, -inx, drop=FALSE] colNames &lt;- colNames[-inx] } ############################################# # Data transformation # generalize log, tolerant to 0 and negative values LogNorm &lt;- function(x, min.val) { return(log10((x + sqrt(x^2 + min.val^2))/2)) } # square root, tolerant to negative values SquareRootNorm &lt;- function(x, min.val) { return(((x + sqrt(x^2 + min.val^2))/2)^(1/2)) } if (transNorm == &quot;LogNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, LogNorm, min.val) transnm &lt;- &quot;Log10 Normalization&quot; } else if (transNorm == &quot;SrNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, SquareRootNorm, min.val) transnm &lt;- &quot;Square Root Transformation&quot; } else if (transNorm == &quot;CrNorm&quot;) { norm.data &lt;- abs(data)^(1/3) norm.data[data &lt; 0] &lt;- -norm.data[data &lt; 0] data &lt;- norm.data transnm &lt;- &quot;Cubic Root Transformation&quot; } else { transnm &lt;- &quot;N/A&quot; } ############################################# ############################################# # Data scaling # normalize to zero mean and unit variance AutoNorm &lt;- function(x) { return((x - mean(x))/sd(x, na.rm = T)) } # normalize to zero mean but variance/SE ParetoNorm &lt;- function(x) { return((x - mean(x))/sqrt(sd(x, na.rm = T))) } # normalize to zero mean but variance/SE MeanCenter &lt;- function(x) { return(x - mean(x)) } # normalize to zero mean but variance/SE RangeNorm &lt;- function(x) { if (max(x) == min(x)) { return(x) } else { return((x - mean(x))/(max(x) - min(x))) } } if (scaleNorm == &quot;MeanCenter&quot;) { data &lt;- apply(data, 2, MeanCenter) scalenm &lt;- &quot;Mean Centering&quot; } else if (scaleNorm == &quot;AutoNorm&quot;) { data &lt;- apply(data, 2, AutoNorm) scalenm &lt;- &quot;Autoscaling&quot; } else if (scaleNorm == &quot;ParetoNorm&quot;) { data &lt;- apply(data, 2, ParetoNorm) scalenm &lt;- &quot;Pareto Scaling&quot; } else if (scaleNorm == &quot;RangeNorm&quot;) { data &lt;- apply(data, 2, RangeNorm) scalenm &lt;- &quot;Range Scaling&quot; } else { scalenm &lt;- &quot;N/A&quot; } ############################################# message(&quot;Row norm: &quot;, rownm, &quot;\\n&quot;, &quot;Data Transformation norm: &quot;, transnm, &quot;\\n&quot;, &quot;Data Scaling norm: &quot;, scalenm, &quot;\\n&quot;) # note after using &quot;apply&quot; function, all the attribute lost, need to add back rownames(data) &lt;- rowNames colnames(data) &lt;- colNames target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID%in%rownames(data)) se &lt;- PomaSummarizedExperiment(target = target, features = data) # need to do some sanity check, for log there may be Inf values introduced res &lt;- CheckData(se) return(res) } se_normalize &lt;- NormalizeData( object = se_filter, rowNorm = &quot;None&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;) ## Row norm: N/A ## Data Transformation norm: Log10 Normalization ## Data Scaling norm: Pareto Scaling ## All data values are numeric. ## A total of 0 (0%) missing values were detected. se_normalize ## class: SummarizedExperiment ## dim: 167 45 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(167): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(45): P101001 P101004 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.7.2 Normalization by POMA R package none &lt;- PomaNorm(se_filter, method = &quot;none&quot;) auto_scaling &lt;- PomaNorm(se_filter, method = &quot;auto_scaling&quot;) evel_scaling &lt;- PomaNorm(se_filter, method = &quot;level_scaling&quot;) log_scaling &lt;- PomaNorm(se_filter, method = &quot;log_scaling&quot;) log_transformation &lt;- PomaNorm(se_filter, method = &quot;log_transformation&quot;) vast_scaling &lt;- PomaNorm(se_filter, method = &quot;vast_scaling&quot;) se_normalize_v2 &lt;- PomaNorm(se_filter, method = &quot;log_pareto&quot;) se_normalize_v2 ## class: SummarizedExperiment ## dim: 167 45 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(167): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(45): P101001 P101004 ... P101095 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.7.3 Comparison of unnormalized and normalized dataset boxplot pl_unnor &lt;- PomaBoxplots(se_filter, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaBoxplots(se_normalize, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) density pl_unnor &lt;- PomaDensity(se_filter, group = &quot;features&quot;) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaDensity(se_normalize, group = &quot;features&quot;) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) 3.1.8 Removing outliers PomaOutliers(se_normalize, do = &quot;analyze&quot;)$polygon_plot # to explore se_processed &lt;- PomaOutliers(se_normalize, do = &quot;clean&quot;) # to remove outliers se_processed ## class: SummarizedExperiment ## dim: 167 42 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(167): M_38768 M_38296 ... M_31787 M_63361 ## rowData names(0): ## colnames(42): P101001 P101004 ... P101094 P101096 ## colData names(5): group Gender Smoker Age AlcoholConsumption 3.1.9 Saving datasets into RDS files if (!dir.exists(&quot;./dataset/POMA/&quot;)) { dir.create(&quot;./dataset/POMA/&quot;) } saveRDS(ExprSet, &quot;./dataset/POMA/ExprSet_raw.RDS&quot;, compress = TRUE) saveRDS(se_raw, &quot;./dataset/POMA/se_raw.RDS&quot;, compress = TRUE) saveRDS(se_check, &quot;./dataset/POMA/se_check.RDS&quot;, compress = TRUE) saveRDS(se_filter, &quot;./dataset/POMA/se_filter.RDS&quot;, compress = TRUE) saveRDS(se_impute, &quot;./dataset/POMA/se_impute.RDS&quot;, compress = TRUE) saveRDS(se_normalize, &quot;./dataset/POMA/se_normalize.RDS&quot;, compress = TRUE) saveRDS(se_processed, &quot;./dataset/POMA/se_processed.RDS&quot;, compress = TRUE) 3.2 Cluster Analysis Hierarchical clustering is an alternative approach to k-means clustering for identifying groups in the dataset. It does not require us to pre-specify the number of clusters to be generated as is required by the k-means approach. Furthermore, hierarchical clustering has an added advantage over K-means clustering in that it results in an attractive tree-based representation of the observations, called a dendrogram. Note: Please remember to preprocess your data before clustering 3.2.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(POMA) library(ggplot2) library(SummarizedExperiment) library(cluster) # clustering algorithms library(factoextra) # clustering visualization library(dendextend) # for comparing two dendrograms # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.2.2 Importing data The input data sets are from the previous chapter. se_normalize &lt;- readRDS(&quot;./dataset/POMA/se_normalize.RDS&quot;) 3.2.3 Hierarchical Clustering Hierarchical clustering can be divided into two main types: agglomerative and divisive. Calculate dissimilarity However, a bigger question is: How do we measure the dissimilarity between two clusters of observations? A number of different cluster agglomeration methods (i.e, linkage methods) have been developed to answer to this question. The most common types methods are: Maximum or complete linkage clustering: It computes all pairwise dissimilarities between the elements in cluster 1 and the elements in cluster 2, and considers the largest value (i.e., maximum value) of these dissimilarities as the distance between the two clusters. It tends to produce more compact clusters. Minimum or single linkage clustering: It computes all pairwise dissimilarities between the elements in cluster 1 and the elements in cluster 2, and considers the smallest of these dissimilarities as a linkage criterion. It tends to produce long, “loose” clusters. Mean or average linkage clustering: It computes all pairwise dissimilarities between the elements in cluster 1 and the elements in cluster 2, and considers the average of these dissimilarities as the distance between the two clusters. Centroid linkage clustering: It computes the dissimilarity between the centroid for cluster 1 (a mean vector of length p variables) and the centroid for cluster 2. Ward’s minimum variance method: It minimizes the total within-cluster variance. At each step the pair of clusters with minimum between-cluster distance are merged. Data Processing: Rows are observations (individuals) and columns are variables. Any missing value in the data must be removed or estimated. The data must be standardized (i.e., scaled) to make variables comparable. Recall that, standardization consists of transforming the variables such that they have mean zero and standard deviation one. Functions to computing hierarchical clustering: hclust [in stats package] and agnes [in cluster package] for agglomerative hierarchical clustering. diana [in cluster package] for divisive hierarchical clustering. HieraCluster &lt;- function(object, method_dis = c(&quot;euclidean&quot;, &quot;bray&quot;), method_cluster = c(&quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;, &quot;ward.D2&quot;), cluster_type = c(&quot;Agglomerative&quot;, &quot;Divisive&quot;), tree_num = 4) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) df &lt;- t(features_tab) if (cluster_type == &quot;Agglomerative&quot;) { # Agglomerative Hierarchical Clustering # Dissimilarity matrix d &lt;- dist(df, method = method_dis) # Hierarchical clustering using Linkage method hc &lt;- hclust(d, method = method_cluster) # hc &lt;- agnes(df, method = method_cluster) ####### identifying the strongest clustering structure ################ # # methods to assess # m &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;) # names(m) &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;) # # # function to compute coefficient # ac &lt;- function(x) { # agnes(df, method = x)$ac # } # # map_dbl(m, ac) } else if (cluster_type == &quot;Divisive&quot;) { # Divisive Hierarchical Clustering hc &lt;- diana(df, metric = method_dis) } hc_res &lt;- as.hclust(hc) sub_grp &lt;- cutree(hc_res, k = tree_num) plot(hc_res, cex = 0.6) rect.hclust(hc_res, k = tree_num, border = 2:(tree_num+1)) res &lt;- list(data=df, cluster=sub_grp, hc=hc_res) return(res) } 3.2.3.1 Agglomerative Hierarchical Clustering Agglomerative clustering: It’s also known as AGNES (Agglomerative Nesting). It works in a bottom-up manner. That is, each object is initially considered as a single-element cluster (leaf). At each step of the algorithm, the two clusters that are the most similar are combined into a new bigger cluster (nodes). This procedure is iterated until all points are member of just one single big cluster (root). The result is a tree which can be plotted as a dendrogram. Calculation Agg_hc_res &lt;- HieraCluster( object = se_normalize, method_dis = &quot;euclidean&quot;, method_cluster = &quot;ward.D2&quot;, cluster_type = &quot;Agglomerative&quot;) Visualization: visualize the result in a scatter plot fviz_cluster(list(data = Agg_hc_res$data, cluster = Agg_hc_res$cluster)) 3.2.3.2 Divisive Hierarchical Clustering Divisive hierarchical clustering: It’s also known as DIANA (Divise Analysis) and it works in a top-down manner. The algorithm is an inverse order of AGNES. It begins with the root, in which all objects are included in a single cluster. At each step of iteration, the most heterogeneous cluster is divided into two. The process is iterated until all objects are in their own cluster. Calculation Div_hc_res &lt;- HieraCluster( object = se_normalize, method_dis = &quot;euclidean&quot;, method_cluster = &quot;ward&quot;, cluster_type = &quot;Divisive&quot;) Visualization: visualize the result in a scatter plot fviz_cluster(list(data = Div_hc_res$data, cluster = Div_hc_res$cluster)) 3.2.3.3 Comparison dendrograms: In the dendrogram displayed above, each leaf corresponds to one observation. Agg_hc_dend &lt;- as.dendrogram(Agg_hc_res$hc) Div_hc_dend &lt;- as.dendrogram(Div_hc_res$hc) tanglegram(Agg_hc_dend, Div_hc_dend) tanglegrams dend_list &lt;- dendlist(Agg_hc_dend, Div_hc_dend) tanglegram(Agg_hc_dend, Div_hc_dend, highlight_distinct_edges = FALSE, # Turn-off dashed lines common_subtrees_color_lines = FALSE, # Turn-off line colors common_subtrees_color_branches = TRUE, # Color common branches main = paste(&quot;entanglement =&quot;, round(entanglement(dend_list), 2))) 3.2.3.4 Determining Optimal Clusters Elbow plot fviz_nbclust(Agg_hc_res$data, FUN = hcut, method = &quot;wss&quot;) Average Silhouette Method fviz_nbclust(Agg_hc_res$data, FUN = hcut, method = &quot;silhouette&quot;) Gap Statistic Method gap_stat &lt;- clusGap(Agg_hc_res$data, FUN = hcut, nstart = 25, K.max = 10, B = 50) ## Clustering k = 1,2,..., K.max (= 10): .. done ## Bootstrapping, b = 1,2,..., B (= 50) [one &quot;.&quot; per sample]: ## .................................................. 50 fviz_gap_stat(gap_stat) 3.2.4 Partitional Clustering K-means clustering is the most commonly used unsupervised machine learning algorithm for partitioning a given data set into a set of k groups (i.e. k clusters), where k represents the number of groups pre-specified by the analyst. PartCluster &lt;- function(object, cluster_num = 4) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) df &lt;- t(features_tab) res &lt;- kmeans(df, centers = cluster_num) # show clusters print(fviz_cluster(list(data = df, cluster = res$cluster))) return(res) } Kcluster_res &lt;- PartCluster( object = se_normalize, cluster_num = 4) 3.3 Chemometrics Analysis The functions for Chemometrics Analysis in POMA (Castellano-Escuder et al. 2021) implemented from mixOmics (Rohart et al. 2017). Note: Please also remember to preprocess your data before running this sub-chapter. 3.3.1 Loading packages knitr::opts_chunk$set(warning = F, message = F) library(dplyr) library(tibble) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(SummarizedExperiment) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.3.2 Importing data The input data sets are from the previous chapter. se_processed &lt;- readRDS(&quot;./dataset/POMA/se_processed.RDS&quot;) 3.3.3 Principal Component Analysis (PCA) The aim of PCA (Jolliffe 2005) is to reduce the dimensionality of the data whilst retaining as much information as possible. ‘Information’ is referred here as variance. The idea is to create uncorrelated artificial variables called principal components (PCs) that combine in a linear manner the original (possibly correlated) variables. poma_pca &lt;- PomaMultivariate(se_processed, method = &quot;pca&quot;) poma_pca$scoresplot + ggtitle(&quot;Scores Plot (pca)&quot;) 3.3.4 Partial Least Squares-Discriminant Analysis (PLS-DA) Partial Least Squares (PLS) regression is a multivariate methodology which relates two data matrices X (e.g. transcriptomics) and Y (e.g. lipids). PLS goes beyond traditional multiple regression by modelling the structure of both matrices. Unlike traditional multiple regression models, it is not limited to uncorrelated variables. One of the many advantages of PLS is that it can handle many noisy, collinear (correlated) and missing variables and can also simultaneously model several response variables in Y. Calculation poma_plsda &lt;- PomaMultivariate(se_processed, method = &quot;plsda&quot;) scatter plot poma_plsda$scoresplot + ggtitle(&quot;Scores Plot (plsda)&quot;) errors plot poma_plsda$errors_plsda_plot + ggtitle(&quot;Error Plot (plsda)&quot;) 3.3.5 Sparse Partial Least Squares-Discriminant Analysis (sPLS-DA) Even though PLS is highly efficient in a high dimensional context, the interpretability of PLS needed to be improved. sPLS has been recently developed by our team to perform simultaneous variable selection in both data sets X and Y data sets, by including LASSO penalizations in PLS on each pair of loading vectors Calculation poma_splsda &lt;- PomaMultivariate(se_processed, method = &quot;splsda&quot;) scatter plot poma_splsda$scoresplot + ggtitle(&quot;Scores Plot (splsda)&quot;) 3.3.6 Orthogonal Partial Least Squares-Discriminant Analysis (orthoPLS-DA) Still in development… 3.3.7 Chemometrics Analysis by own scripts DR_fun &lt;- function( x, group, group_names, DRtype = c(&quot;PCA&quot;, &quot;PLS&quot;, &quot;OPLS&quot;)) { # x = se_processed # group = &quot;group&quot; # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # DRtype = &quot;PCA&quot; # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) match_order_index &lt;- sort(pmatch(unique(phenotype$CompVar), group_names), decreasing = F) group_names_new &lt;- group_names[match_order_index] phenotype$CompVar &lt;- factor(as.character(phenotype$CompVar), levels = group_names_new) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } prof_cln &lt;- prof dataMatrix &lt;- prof_cln %&gt;% t() # row-&gt;sampleID; col-&gt;features sampleMetadata &lt;- phen %&gt;% # row-&gt;sampleID; col-&gt;features dplyr::mutate(CompVar = factor(as.character(CompVar), levels = group_names_new)) %&gt;% dplyr::mutate(Color = factor(as.character(CompVar), levels = group_names_new), Color = as.character(Color)) if (DRtype == &quot;PCA&quot;) { fit &lt;- ropls::opls(dataMatrix) plot(fit, typeVc = &quot;x-score&quot;, parAsColFcVn = sampleMetadata$CompVar, ) } else if (DRtype == &quot;PLS&quot;) { fit &lt;- ropls::opls(dataMatrix, sampleMetadata$CompVar) plot(fit, typeVc = &quot;x-score&quot;, parAsColFcVn = sampleMetadata$CompVar, ) # return(fit) } else if (DRtype == &quot;OPLS&quot;) { # only for binary classification fit &lt;- ropls::opls(dataMatrix, sampleMetadata$CompVar, predI = 1, orthoI = NA) plot(fit, typeVc = &quot;x-score&quot;, parAsColFcVn = sampleMetadata$CompVar, ) # return(fit) } return(fit) } Principal Component Analysis (PCA) fit &lt;- DR_fun( x = se_processed, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), DRtype = &quot;PCA&quot;) ## PCA ## 26 samples x 167 variables ## standard scaling of predictors ## R2X(cum) pre ort ## Total 0.528 5 0 Partial Least Squares-Discriminant Analysis (PLS-DA) fit &lt;- DR_fun( x = se_processed, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), DRtype = &quot;PLS&quot;) ## PLS-DA ## 26 samples x 167 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.296 0.857 0.537 0.2 2 0 0.25 0.05 Orthogonal Partial Least Squares-Discriminant Analysis (orthoPLS-DA) fit &lt;- DR_fun( x = se_processed, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), DRtype = &quot;OPLS&quot;) ## OPLS-DA ## 26 samples x 167 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.402 0.99 0.521 0.0566 1 3 0.05 0.05 3.4 Univariate Analysis Univariate analysis explores each variable in a data set, separately and it uses traditional statistical methods on single variable to calculate the statistics, such as fold change, p-value, etc. Note: Please also remember to preprocess your data before running this sub-chapter. 3.4.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(SummarizedExperiment) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.4.2 Importing data The input data sets are from the previous chapter. se_impute &lt;- readRDS(&quot;./dataset/POMA/se_impute.RDS&quot;) se_normalize &lt;- readRDS(&quot;./dataset/POMA/se_normalize.RDS&quot;) se_processed &lt;- readRDS(&quot;./dataset/POMA/se_processed.RDS&quot;) 3.4.3 Fold Change Analysis RawData (inputed data) FoldChange &lt;- function( x, group, group_names) { # x = se_impute # group = &quot;group&quot; # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } fc_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) mn &lt;- tapply(dat$value, dat$group, function(x){ mean(x, na.rm = TRUE) }) %&gt;% as.data.frame() %&gt;% stats::setNames(&quot;value&quot;) %&gt;% tibble::rownames_to_column(&quot;Group&quot;) mn1 &lt;- with(mn, mn[Group %in% group_names[1], &quot;value&quot;]) mn2 &lt;- with(mn, mn[Group %in% group_names[2], &quot;value&quot;]) mnall &lt;- mean(dat$value, na.rm = TRUE) if (all(mn1 != 0, mn2 != 0)) { fc &lt;- mn1 / mn2 } else { fc &lt;- NA } logfc &lt;- log2(fc) res &lt;- c(fc, logfc, mnall, mn1, mn2) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(fc_res) &lt;- c(&quot;FeatureID&quot;, &quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;Mean Abundance\\n(All)&quot;, paste0(&quot;Mean Abundance\\n&quot;, c(&quot;former&quot;, &quot;latter&quot;))) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) fc_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- fc_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } fc_res &lt;- FoldChange( x = se_impute, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Moderate&quot;)) head(fc_res) ## FeatureID Block FoldChange Log2FoldChange Mean Abundance\\n(All) Mean Abundance\\nformer Mean Abundance\\nlatter ## 1 M_38768 14_Mild vs 19_Moderate 0.8977727 -0.15557781 37464768.7 35159693.7 39163245.1 ## 2 M_38296 14_Mild vs 19_Moderate 0.7827914 -0.35330013 4140693.4 3570299.1 4560983.9 ## 3 M_63436 14_Mild vs 19_Moderate 0.7982418 -0.32510221 734958.7 641591.4 803755.6 ## 4 M_57814 14_Mild vs 19_Moderate 0.9414267 -0.08707934 267247.3 258005.0 274057.4 ## 5 M_52984 14_Mild vs 19_Moderate 0.8476930 -0.23838621 136374.4 123589.4 145795.0 ## 6 M_48762 14_Mild vs 19_Moderate 0.3214408 -1.63737503 4371547.5 1973236.4 6138724.2 3.4.4 T Test group_names &lt;- c(&quot;Mild&quot;, &quot;Severe&quot;) se_processed_subset &lt;- se_processed[, se_processed$group %in% group_names] se_processed_subset$group &lt;- factor(as.character(se_processed_subset$group)) ttest_res &lt;- PomaUnivariate(se_processed_subset, method = &quot;ttest&quot;) head(ttest_res) ## # A tibble: 6 × 9 ## feature FC diff_means pvalue pvalueAdj mean_Mild mean_Severe sd_Mild sd_Severe ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_38768 0.116 0.087 0.621 0.893 -0.0990 -0.0115 0.528 0.354 ## 2 M_38296 -0.028 0.168 0.309 0.730 -0.163 0.00462 0.504 0.307 ## 3 M_63436 -0.395 0.082 0.594 0.878 -0.0584 0.0231 0.402 0.368 ## 4 M_57814 2.24 -0.024 0.827 0.952 -0.0192 -0.0431 0.327 0.223 ## 5 M_52603 2.46 0.034 0.771 0.952 0.0236 0.0580 0.238 0.339 ## 6 M_53174 0.178 0.103 0.546 0.878 -0.126 -0.0224 0.375 0.470 3.4.5 Wilcoxon Test wilcox_res &lt;- PomaUnivariate(se_processed_subset, method = &quot;mann&quot;) head(wilcox_res) ## # A tibble: 6 × 9 ## feature FC diff_means pvalue pvalueAdj mean_Mild mean_Severe sd_Mild sd_Severe ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_38768 0.116 0.087 0.560 0.867 -0.0990 -0.0115 0.528 0.354 ## 2 M_38296 -0.028 0.168 0.145 0.576 -0.163 0.00462 0.504 0.307 ## 3 M_63436 -0.395 0.082 0.560 0.867 -0.0584 0.0231 0.402 0.368 ## 4 M_57814 2.24 -0.024 0.940 0.981 -0.0192 -0.0431 0.327 0.223 ## 5 M_52603 2.46 0.034 0.940 0.981 0.0236 0.0580 0.238 0.339 ## 6 M_53174 0.178 0.103 0.705 0.912 -0.126 -0.0224 0.375 0.470 3.4.6 Limma Test Limma_res &lt;- PomaLimma(se_processed_subset, contrast = paste(group_names, collapse = &quot;-&quot;), adjust = &quot;fdr&quot;) head(Limma_res) ## # A tibble: 6 × 7 ## feature logFC AveExpr t P.Value adj.P.Val B ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_42449 -0.455 -0.0649 -3.24 0.00253 0.217 -2.34 ## 2 M_37482 0.535 0.0923 2.99 0.00499 0.217 -2.69 ## 3 M_62566 -0.389 0.0428 -2.95 0.00550 0.217 -2.74 ## 4 M_19263 -0.420 -0.0546 -2.87 0.00679 0.217 -2.85 ## 5 M_1566 -0.397 -0.0456 -2.83 0.00761 0.217 -2.91 ## 6 M_43761 -0.440 0.0168 -2.82 0.00780 0.217 -2.92 3.4.7 Volcano plot se_impute_subset &lt;- se_impute[, se_impute$group %in% group_names] se_impute_subset$group &lt;- factor(as.character(se_impute_subset$group)) PomaVolcano(se_impute_subset, pval = &quot;raw&quot;, pval_cutoff = 0.1, log2FC = 0.2, xlim = 1, labels = TRUE, plot_title = TRUE) 3.4.8 VIP (Variable influence on projection &amp; coefficient) Variable influence on projection (VIP) for orthogonal projections to latent structures (OPLS) Variable influence on projection (VIP) for projections to latent structures (PLS) VIP_fun &lt;- function( x, group, group_names, VIPtype = c(&quot;OPLS&quot;, &quot;PLS&quot;), vip_cutoff = 1) { # x = se_normalize # group = &quot;group&quot; # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # VIPtype = &quot;PLS&quot; # vip_cutoff = 1 metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } dataMatrix &lt;- prof %&gt;% base::t() # row-&gt;sampleID; col-&gt;features sampleMetadata &lt;- phen # row-&gt;sampleID; col-&gt;features comparsionVn &lt;- sampleMetadata[, &quot;CompVar&quot;] # corrlation between group and features pvaVn &lt;- apply(dataMatrix, 2, function(feaVn) cor.test(as.numeric(comparsionVn), feaVn)[[&quot;p.value&quot;]]) library(ropls) if (VIPtype == &quot;OPLS&quot;) { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, orthoI = NA, fig.pdfC = &quot;none&quot;)) } else { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, fig.pdfC = &quot;none&quot;)) } quantVn &lt;- qnorm(1 - pvaVn / 2) rmsQuantN &lt;- sqrt(mean(quantVn^2)) opar &lt;- par(font = 2, font.axis = 2, font.lab = 2, las = 1, mar = c(5.1, 4.6, 4.1, 2.1), lwd = 2, pch = 16) plot(pvaVn, vipVn, col = &quot;red&quot;, pch = 16, xlab = &quot;p-value&quot;, ylab = &quot;VIP&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;) box(lwd = 2) curve(qnorm(1 - x / 2) / rmsQuantN, 0, 1, add = TRUE, col = &quot;red&quot;, lwd = 3) abline(h = 1, col = &quot;blue&quot;) abline(v = 0.05, col = &quot;blue&quot;) res_temp &lt;- data.frame( FeatureID = names(vipVn), VIP = vipVn, CorPvalue = pvaVn) %&gt;% dplyr::arrange(desc(VIP)) vip_select &lt;- res_temp %&gt;% dplyr::filter(VIP &gt; vip_cutoff) pl &lt;- ggplot(vip_select, aes(FeatureID, VIP)) + geom_segment(aes(x = FeatureID, xend = FeatureID, y = 0, yend = VIP)) + geom_point(shape = 21, size = 5, color = &#39;#008000&#39; ,fill = &#39;#008000&#39;) + geom_point(aes(1,2.5), color = &#39;white&#39;) + geom_hline(yintercept = 1, linetype = &#39;dashed&#39;) + scale_y_continuous(expand = c(0, 0)) + labs(x = &#39;&#39;, y = &#39;VIP value&#39;) + theme_bw() + theme(legend.position = &#39;none&#39;, legend.text = element_text(color = &#39;black&#39;,size = 12, family = &#39;Arial&#39;, face = &#39;plain&#39;), panel.background = element_blank(), panel.grid = element_blank(), axis.text = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.text.x = element_text(angle = 90), axis.title = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.ticks = element_line(color = &#39;black&#39;), axis.ticks.x = element_blank()) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) res_temp$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res_df &lt;- res_temp %&gt;% dplyr::select(FeatureID, Block, everything()) res &lt;- list(vip = res_df, plot = pl) return(res) } vip_res &lt;- VIP_fun( x = se_normalize, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), VIPtype = &quot;PLS&quot;, vip_cutoff = 1) ## PLS-DA ## 26 samples x 167 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.12 0.692 0.33 0.288 1 0 0.1 0.05 head(vip_res$vip) ## FeatureID Block VIP CorPvalue ## M_42449 M_42449 14_Mild vs 12_Severe 2.362694 0.002247897 ## M_62566 M_62566 14_Mild vs 12_Severe 2.288128 0.003300438 ## M_1566 M_1566 14_Mild vs 12_Severe 2.143655 0.006556886 ## M_19263 M_19263 14_Mild vs 12_Severe 2.128317 0.007023483 ## M_52446 M_52446 14_Mild vs 12_Severe 2.059461 0.009476225 ## M_37482 M_37482 14_Mild vs 12_Severe 2.052135 0.009774742 vip_res$plot 3.4.9 T-test by local codes significant differences between two groups (p value) t_fun &lt;- function( x, group, group_names) { # x = se_normalize # group = &quot;group&quot; # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() # rename variables colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } t_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) rest &lt;- t.test(data = dat, value ~ group) res &lt;- c(rest$statistic, rest$p.value) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(t_res) &lt;- c(&quot;FeatureID&quot;, &quot;Statistic&quot;, &quot;Pvalue&quot;) t_res$AdjustedPvalue &lt;- p.adjust(as.numeric(t_res$Pvalue), method = &quot;BH&quot;) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) t_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- t_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } ttest_res &lt;- t_fun( x = se_normalize, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;)) head(ttest_res) ## FeatureID Block Statistic Pvalue AdjustedPvalue ## 1 M_38768 14_Mild vs 12_Severe -0.5018649 0.6205743 0.8928355 ## 2 M_38296 14_Mild vs 12_Severe -1.0405745 0.3094567 0.7300466 ## 3 M_63436 14_Mild vs 12_Severe -0.5398558 0.5942962 0.8782962 ## 4 M_57814 14_Mild vs 12_Severe 0.2204845 0.8274429 0.9515249 ## 5 M_52603 14_Mild vs 12_Severe -0.2952738 0.7709351 0.9515249 ## 6 M_53174 14_Mild vs 12_Severe -0.6134155 0.5461908 0.8782962 3.4.10 Merging result Foldchange by Raw Data VIP by Normalized Data test Pvalue by Normalized Data mergedResults &lt;- function( fc_result, vip_result, test_result, group_names, group_labels) { # fc_result = fc_res # vip_result = vip_res$vip # test_result = ttest_res # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;) if (is.null(vip_result)) { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } else { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(vip_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, VIP, CorPvalue, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } return(res) } m_results &lt;- mergedResults( fc_result = fc_res, vip_result = vip_res$vip, test_result = ttest_res, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;)) head(m_results) ## FeatureID Block2 Block FoldChange Log2FoldChange VIP CorPvalue Statistic Pvalue AdjustedPvalue ## 1 M_42449 Mild vs Severe 14_Mild vs 19_Moderate 0.6571801 -0.6056393 2.362694 0.002247897 -3.498896 0.001881585 0.2132448 ## 2 M_52446 Mild vs Severe 14_Mild vs 19_Moderate 0.7040861 -0.5061763 2.059461 0.009476225 -2.892892 0.008125613 0.2132448 ## 3 M_1566 Mild vs Severe 14_Mild vs 19_Moderate 0.7161609 -0.4816443 2.143655 0.006556886 -3.077688 0.005431005 0.2132448 ## 4 M_19263 Mild vs Severe 14_Mild vs 19_Moderate 0.7165011 -0.4809592 2.128317 0.007023483 -3.073546 0.005774977 0.2132448 ## 5 M_42448 Mild vs Severe 14_Mild vs 19_Moderate 0.7577644 -0.4001788 2.006246 0.011828403 -2.793941 0.010215320 0.2132448 ## 6 M_43761 Mild vs Severe 14_Mild vs 19_Moderate 0.8685495 -0.2033201 2.043515 0.010136007 -2.822338 0.009428795 0.2132448 3.4.11 Volcano of Merged Results get_volcano &lt;- function( inputdata, group_names, group_labels, group_colors, x_index, x_cutoff, y_index, y_cutoff, plot = TRUE) { # inputdata = m_results # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;) # group_colors = c(&quot;red&quot;, &quot;blue&quot;) # x_index = &quot;Log2FoldChange&quot; # x_cutoff = 0.5 # y_index = &quot;AdjustedPvalue&quot; # y_cutoff = 0.5 # plot = FALSE # selected_group &lt;- paste(group_names, collapse = &quot; vs &quot;) selected_group2 &lt;- paste(group_labels, collapse = &quot; vs &quot;) dat &lt;- inputdata %&gt;% dplyr::filter(Block2 %in% selected_group2) plotdata &lt;- dat %&gt;% dplyr::mutate(FeatureID = paste(FeatureID, sep = &quot;:&quot;)) %&gt;% dplyr::select(all_of(c(&quot;FeatureID&quot;, &quot;Block2&quot;, x_index, y_index))) if (!any(colnames(plotdata) %in% &quot;TaxaID&quot;)) { colnames(plotdata)[1] &lt;- &quot;TaxaID&quot; } if (y_index == &quot;CorPvalue&quot;) { colnames(plotdata)[which(colnames(plotdata) == y_index)] &lt;- &quot;Pvalue&quot; y_index &lt;- &quot;Pvalue&quot; } pl &lt;- plot_volcano( da_res = plotdata, group_names = group_labels, x_index = x_index, x_index_cutoff = x_cutoff, y_index = y_index, y_index_cutoff = y_cutoff, group_color = c(group_colors[1], &quot;grey&quot;, group_colors[2])) if (plot) { res &lt;- pl } else { colnames(plotdata)[which(colnames(plotdata) == x_index)] &lt;- &quot;Xindex&quot; colnames(plotdata)[which(colnames(plotdata) == y_index)] &lt;- &quot;Yindex&quot; datsignif &lt;- plotdata %&gt;% dplyr::filter(abs(Xindex) &gt; x_cutoff) %&gt;% dplyr::filter(Yindex &lt; y_cutoff) colnames(datsignif)[which(colnames(datsignif) == &quot;Xindex&quot;)] &lt;- x_index colnames(datsignif)[which(colnames(datsignif) == &quot;Yindex&quot;)] &lt;- y_index res &lt;- list(figure = pl, data = datsignif) } return(res) } lgfc_FDR_vol &lt;- get_volcano( inputdata = m_results, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;), group_colors = c(&quot;red&quot;, &quot;blue&quot;), x_index = &quot;Log2FoldChange&quot;, x_cutoff = 0.5, y_index = &quot;AdjustedPvalue&quot;, y_cutoff = 0.5, plot = FALSE) lgfc_FDR_vol$figure 3.4.12 Correlation Heatmaps poma_cor &lt;- PomaCorr(se_processed_subset, label_size = 8, coeff = 0.6) poma_cor$correlations ## # A tibble: 13,861 × 5 ## feature1 feature2 R pvalue FDR ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_52465 M_52466 0.955 3.19e-14 4.42e-10 ## 2 M_44621 M_39270 0.946 3.36e-13 2.33e- 9 ## 3 M_52610 M_52611 0.941 9.33e-13 4.31e- 9 ## 4 M_33971 M_33972 0.939 1.39e-12 4.83e- 9 ## 5 M_52464 M_52447 0.936 2.33e-12 6.10e- 9 ## 6 M_52687 M_42449 0.935 2.64e-12 6.10e- 9 ## 7 M_22036 M_63120 0.926 1.22e-11 2.41e- 8 ## 8 M_38768 M_33972 0.925 1.42e-11 2.46e- 8 ## 9 M_42449 M_52446 0.921 2.49e-11 3.83e- 8 ## 10 M_44621 M_39271 0.920 2.97e-11 4.12e- 8 ## # ℹ 13,851 more rows correlation plot poma_cor$corrplot Network poma_cor$graph 3.4.13 glasso: this function will compute a Gaussian Graphical Model using the glmnet package PomaCorr(se_processed_subset, corr_type = &quot;glasso&quot;, coeff = 0.6)$graph 3.5 Multivariate analysis Comparing to univariate analysis, multivariate analysis is defined as a process of involving multiple dependent variables resulting in one outcome for feature selection. Here, we use Regularized Generalized Linear Models and Random forest model to identify the biomarkers associated with Outcomes. Lasso, Ridge and Elasticnet Regularized Generalized Linear Models for Binary Outcomes Random forest model to select the important features Note: Please also remember to preprocess your data before running this sub-chapter. 3.5.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(SummarizedExperiment) library(glmnet) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.5.2 Importing data The input data sets are from the previous chapter. se_processed &lt;- readRDS(&quot;./dataset/POMA/se_processed.RDS&quot;) 3.5.3 Data curation group_names &lt;- c(&quot;Mild&quot;, &quot;Severe&quot;) se_processed_subset &lt;- se_processed[, se_processed$group %in% group_names] se_processed_subset$group &lt;- factor(as.character(se_processed_subset$group)) 3.5.4 Regularized Generalized Linear Models 3.5.4.1 Lasso: alpha = 1 lasso_res &lt;- PomaLasso(se_processed_subset, alpha = 1, labels = TRUE) cowplot::plot_grid(lasso_res$cvLassoPlot, lasso_res$coefficientPlot, ncol = 2, align = &quot;hv&quot;) lasso_res$coefficients ## # A tibble: 11 × 2 ## feature coefficient ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) 0.102 ## 2 M_52682 -1.55 ## 3 M_62566 0.336 ## 4 M_49617 -1.26 ## 5 M_52710 -0.0742 ## 6 M_42449 1.92 ## 7 M_45970 0.324 ## 8 M_42374 -0.117 ## 9 M_43761 0.319 ## 10 M_41220 0.249 ## 11 M_1566 1.44 3.5.4.2 Ridge: alpha = 0 ridge_res &lt;- PomaLasso(se_processed_subset, alpha = 0, labels = TRUE) cowplot::plot_grid(ridge_res$cvLassoPlot, ridge_res$coefficientPlot, ncol = 2, align = &quot;hv&quot;) ridge_res$coefficients ## # A tibble: 168 × 2 ## feature coefficient ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -0.118 ## 2 M_38768 0.0163 ## 3 M_38296 0.0426 ## 4 M_63436 0.0351 ## 5 M_57814 0.00998 ## 6 M_52603 -0.0159 ## 7 M_53174 -0.000721 ## 8 M_19130 -0.0635 ## 9 M_34404 -0.0326 ## 10 M_32391 -0.0262 ## # ℹ 158 more rows 3.5.4.3 Elasticnet: 0 &lt; alpha &lt; 1 elastic_res &lt;- PomaLasso(se_processed_subset, alpha = 0.4, labels = TRUE) cowplot::plot_grid(elastic_res$cvLassoPlot, elastic_res$coefficientPlot, ncol = 2, align = &quot;hv&quot;) elastic_res$coefficients ## # A tibble: 7 × 2 ## feature coefficient ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -0.141 ## 2 M_62566 0.224 ## 3 M_42449 0.237 ## 4 M_19263 0.0537 ## 5 M_37482 -0.0116 ## 6 M_43761 0.0507 ## 7 M_1566 0.125 3.5.5 Classification 3.5.5.1 Random Forest Calculation poma_rf &lt;- PomaRandForest(se_processed_subset, ntest = 10, nvar = 10) poma_rf$error_tree table poma_rf$confusionMatrix$table ## Reference ## Prediction 1 2 ## 1 0 0 ## 2 1 1 Important features poma_rf$MeanDecreaseGini_plot 3.5.5.2 Support Vector Machine (SVM) Still in development… 3.6 Network Analysis 3.6.1 Introduction Estimating microbial association networks from high-throughput sequencing data is a common exploratory data analysis approach aiming at understanding the complex interplay of microbial communities in their natural habitat. Statistical network estimation workflows comprise several analysis steps, including methods for zero handling, data normalization and computing microbial associations. Since microbial interactions are likely to change between conditions, e.g. between healthy individuals and patients, identifying network differences between groups is often an integral secondary analysis step. NetCoMi (Network Construction and Comparison for Microbiome Data) (Peschel et al. 2021) provides functionality for constructing, analyzing, and comparing networks suitable for the application on microbial compositional data. The following information is from NetCoMi github. Association measures: Pearson coefficient (cor() from stats package) Spearman coefficient (cor() from stats package) Biweight Midcorrelation bicor() from WGCNA package Methods for zero replacement: Adding a predefined pseudo count Multiplicative replacement (multRepl from zCompositions package) Modified EM alr-algorithm (lrEM from zCompositions package) Bayesian-multiplicative replacement (cmultRepl from zCompositions package) Normalization methods: Total Sum Scaling (TSS) (own implementation) Cumulative Sum Scaling (CSS) (cumNormMat from metagenomeSeq package) Common Sum Scaling (COM) (own implementation) Rarefying (rrarefy from vegan package) Variance Stabilizing Transformation (VST) (varianceStabilizingTransformation from DESeq2 package) Centered log-ratio (clr) transformation (clr() from SpiecEasi package)) TSS, CSS, COM, VST, and the clr transformation are described in [Badri et al., 2020]. 3.6.2 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(POMA) library(ggplot2) library(ggraph) library(plotly) library(SummarizedExperiment) library(NetCoMi) library(SPRING) library(SpiecEasi) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 3.6.3 Importing data The input data sets are from the previous chapter. se_filter &lt;- readRDS(&quot;./dataset/POMA/se_filter.RDS&quot;) 3.6.4 Data curation features_tab &lt;- SummarizedExperiment::assay(se_filter) %&gt;% t() features_tab[is.na(features_tab)] &lt;- 0 head(features_tab) ## M_38768 M_38296 M_63436 M_57814 M_52603 M_53174 M_19130 M_34404 M_32391 M_20675 M_34400 M_44621 M_52689 M_52673 ## P101001 51127588 5105020 756686.2 281502.0 94392176 144048.2 25632184 123026.38 321794.2 151752512 2205732.2 402949.6 23821584 11552554 ## P101004 34940596 3885477 851026.5 297304.4 115155104 217577.4 25106562 22810.19 210540.2 57703932 627949.3 288060.6 13722696 8489023 ## P101007 58518636 4285130 726593.9 319016.7 79582632 211262.5 31371314 375686.47 477073.6 198430704 2856552.5 746095.9 26451790 15090030 ## P101009 51118832 6665654 232959.5 242172.2 118408760 431295.3 27787270 118662.19 672746.8 105392656 1831869.2 347963.7 21134366 11239614 ## P101010 83783688 9057441 650261.1 200135.8 92508664 135226.5 26685844 130040.21 263299.9 103049880 1225102.6 550802.9 32726406 19644278 ## M_52682 M_52677 M_52478 M_52477 M_52713 M_52716 M_52474 M_39270 M_52475 M_52748 M_52614 M_39271 M_33228 M_35186 M_34214 ## P101001 28373504 2494246 9753736 2463866 594237.8 7622086 6879792 959249.2 40933908 14099088 3790466 1572987.8 96375552 8141286 8284910 ## P101004 24738246 2398333 8732374 1651473 528063.9 7439745 3780738 785895.0 23139750 12378493 1889665 1101383.0 49699956 4303854 7923489 ## P101007 27171710 2891707 9955330 3774870 780014.5 8345656 5111358 1903592.4 51188676 17399748 4683262 2026999.0 70649888 7129884 9211485 ## P101009 33480956 2989538 10679558 2826825 978802.8 10357009 4263671 863701.9 36418292 19482396 4177870 1169707.9 41290160 5394354 8559147 ## P101010 36381128 4624334 10877791 4131897 702736.2 7783024 5172609 1177860.8 68994568 29016166 6862688 1722600.4 57308316 6270727 7623603 ## M_34397 M_62559 M_62566 M_62562 M_48341 M_35153 M_49617 M_45951 M_52710 M_53189 M_53176 M_34419 M_36600 M_54885 ## P101001 712147.4 162056.6 265921.8 285496.1 292845.1 128661.8 381540.1 3736284 47739292 392911.0 3305130 306346432 9887348 298886.1 ## P101004 194718.0 178442.0 211541.5 265036.3 331437.5 276938.1 588488.2 1839252 43678784 300383.9 3552664 263333424 9703074 356274.3 ## P101007 505635.2 238782.9 456498.2 463207.5 514893.1 185715.0 464548.8 1545863 53975068 539361.5 2035337 191261648 6431966 393623.0 ## P101009 159987.3 152987.9 262397.8 322379.6 297725.7 320728.0 497342.0 3145905 47619564 487186.2 3802829 232171184 11914472 599783.6 ## P101010 446015.2 263668.8 356271.0 471981.4 594546.3 113578.3 457409.1 5152494 61906028 236719.5 3049962 183104336 9366287 280123.8 ## M_36594 M_27447 M_32350 M_62946 M_64596 M_30460 M_27665 M_34395 M_34389 M_53195 M_19258 M_35625 M_55041 M_52697 ## P101001 3238505 9004255 627613.7 395496.2 46295.48 270857.8 1335229.0 199466.6 2138968 13858347 9863770 574852.4 3655240 12883511 ## P101004 4642443 2944057 339586.8 1079166.8 1017875.06 204924.9 1279771.8 226695.4 2153556 6059094 5239331 236322.3 1637351 13617571 ## P101007 3509099 3230152 662555.6 484653.9 463587.81 320279.5 676678.7 208125.5 1348283 18901246 8920123 296148.1 7284474 19369632 ## P101009 5404004 2030452 492430.9 403058.4 370624.53 289090.7 1098703.2 583087.2 4572006 9496899 7639714 269586.8 3065707 14302725 ## P101010 3737352 2431808 373484.2 1065601.8 1228528.25 216454.2 520595.4 259017.0 3558800 19940270 12844156 585791.2 2493687 19721992 ## M_52687 M_48258 M_35628 M_36602 M_21184 M_53180 M_33230 M_52431 M_52462 M_52464 M_52467 M_52454 M_52610 M_52465 ## P101001 2398777 181136336 6548460 1749937 7613153 748319.2 19098412 824253.8 486910976 6794782 2280194 274026048 206279104 2204234 ## P101004 2017056 115752200 3455001 1409849 15023415 917020.4 10641834 328446.0 380887616 4090405 1003667 282066016 253920496 3084690 ## P101007 2768957 102036920 3640571 1495550 23832470 799016.0 14977371 469095.1 515795264 13183206 2950405 309709728 316142400 8800303 ## P101009 3650640 118663320 5087503 3099956 12286962 1118435.0 13575508 518623.8 390977568 7596680 3766843 325723168 232534688 4486037 ## P101010 1901558 154183360 5244878 3420659 14516694 1685150.8 19464998 795436.6 478479936 5395172 6117689 382690720 262177072 2910989 ## M_42446 M_42449 M_52450 M_52461 M_19263 M_52669 M_52470 M_52616 M_57388 M_33955 M_35631 M_45970 M_35305 M_21127 ## P101001 712253440 4006186 2641266 486655872 3874469 2759973 35859212 12365879 79676.23 448634784 4035864 409595.2 863723 4804332 ## P101004 807180352 4623029 2342063 439253152 2842332 1193472 23531182 10655923 37269.65 413690720 3446139 230301.7 1016275 6962388 ## P101007 715500800 5532970 3922614 448578400 5864154 2724709 44479796 14010174 103174.72 368849632 3764448 323317.6 1214598 10822974 ## P101009 742576768 7445768 6170018 473622240 4717213 4360214 41899896 14814230 65198.78 365712768 3444159 420762.3 1920743 9249804 ## P101010 642967424 3822049 6121756 647036736 4579096 5908542 64131204 12873290 41349.66 376101984 3276579 293613.2 2983894 17823292 ## M_61868 M_42450 M_52447 M_52449 M_52235 M_52611 M_52466 M_52452 M_52446 M_52468 M_52438 M_42448 M_52726 M_19265 ## P101001 504846.8 358896736 30252208 43173148 1118858.8 61304088 1859952 510461472 17331080 7814518 181406848 5754168 2246755 1156850 ## P101004 361061.4 282910752 19424238 30030992 3035421.1 78508544 2158371 573170816 17896104 8339710 122556968 3069182 863899 1564114 ## P101007 530824.9 404918560 57376512 50766284 7742330.5 133758544 6886556 588643712 27738444 11004061 181572112 6107326 1798405 6813304 ## P101009 507524.6 298822048 26429340 43420376 872709.2 80545136 2995264 631965888 28258140 15869048 208484000 6196910 3176317 1385724 ## P101010 309155.8 373251712 21732290 43622724 336274.6 104073768 2487264 590247424 18904148 11231769 306379392 6164263 4295183 2180185 ## M_33961 M_42398 M_19324 M_33971 M_33972 M_32497 M_63251 M_64418 M_37536 M_37752 M_38168 M_47403 M_37482 M_57547 ## P101001 191147264 6137137 3277043 34683340 21778388 7502807 702985.6 138656.33 213331.9 914067.1 5222754.0 209255.5 142595.88 169297.7 ## P101004 166379712 5143481 7207395 23345216 10599812 6293102 369620.4 143054.61 234348.0 1492370.2 156811.9 220424.3 152280.70 426227.5 ## P101007 189915296 7412535 7613864 68319096 22969486 7799882 514191.1 183824.64 580629.7 2570282.5 5744456.0 369675.0 38006.62 561078.5 ## P101009 186599152 5421984 6803468 37778060 13476085 3700375 811957.7 162973.59 119383.3 714076.2 1239502.1 172995.7 84628.77 457043.3 ## P101010 217632736 5767624 7363716 62689384 24592120 5778318 392289.5 121719.19 253655.1 1706573.6 914122.9 168503.4 101636.99 602024.4 ## M_62805 M_38276 M_64328 M_63042 M_48580 M_6146 M_42374 M_43761 M_43343 M_43266 M_19266 M_36746 M_63739 ## P101001 3250618 228644.9 110957136 12292479 91572.95 177446.7 42943284 1946942.6 242105.86 1163203.9 176944.80 479072.6 761146.2 ## P101004 2357354 281935.7 110705416 7593832 760372.12 352992.7 42325744 839404.1 133500.70 5113189.5 189413.64 1372193.2 549097.4 ## P101007 4624754 131296.8 137532672 31897926 356734.56 480009.0 44412548 2357434.8 165855.44 3111430.8 385203.22 642121.2 792883.2 ## P101009 2861962 149611.1 209583808 6453900 93497.58 354210.8 24181052 1745628.5 135844.00 890192.9 211997.21 778356.4 727360.0 ## P101010 2523801 246180.4 166666528 5296456 57886.30 650030.8 42762020 361423.8 45789.42 1139527.8 178331.05 2020790.5 913964.4 ## M_61700 M_57663 M_52281 M_42489 M_37253 M_18281 M_52916 M_61698 M_22036 M_35675 M_1432 M_17945 M_15667 M_48141 ## P101001 472302.3 719237.9 78466792 2865827 411578.0 179893.86 733452.4 2130324 774797.4 38006460 1354798.0 17661872 410808.2 5025640 ## P101004 265781.7 364556.1 81241496 1546570 425030.0 108887.77 683209.3 1221117 427803.9 49110836 927115.9 20479238 364068.7 2705928 ## P101007 403507.7 500680.8 95847768 1403190 742298.0 769990.44 767281.1 2035627 455143.1 38735820 2731939.8 16393367 236559.3 2406770 ## P101009 495207.8 523549.1 35564448 1653830 466825.0 267979.69 1044029.8 2243073 422308.4 38389060 933468.1 13751929 354344.8 1891979 ## P101010 318258.2 455201.1 108681912 1007203 232876.0 40788.35 716821.7 1380906 199201.0 41784488 652360.4 18558476 557050.1 1919326 ## M_63120 M_32506 M_64049 M_45095 M_53229 M_62520 M_63990 M_21232 M_55072 M_47118 M_35253 M_43400 M_41220 ## P101001 1647630.5 969193.1 1200940.00 751527.3 768160.4 63648.33 10428390 904260.1 488544.9 281162.7 27446600 3614323 3649905 ## P101004 715426.6 784027.9 259731.38 378033.7 953194.9 203543.30 6402490 2594437.2 653107.0 362380.0 28088842 1483176 1132894 ## P101007 918737.2 1068945.8 1829885.38 589506.3 1619436.8 115621.80 10938208 5687539.5 522721.5 482046.2 21613430 5746994 1522508 ## P101009 858821.5 400273.7 109314.27 503910.2 877530.2 1488895.25 7829000 1906269.8 873616.8 619943.9 28872470 5682455 1882729 ## P101010 441160.8 552550.0 62541.41 489013.9 993923.4 235431.48 9571510 2910665.2 864624.8 677774.7 25375946 6362144 1265978 ## M_46115 M_37174 M_63109 M_62952 M_63589 M_35635 M_45415 M_32197 M_62853 M_1566 M_63681 M_61871 M_31787 M_63361 ## P101001 1578011.4 70308.07 29603070 5104806 2036826 77650.82 148777.2 9709386 483999.6 2625320 434480.3 12926878 10650574 2540280.0 ## P101004 440408.7 156658.04 22345812 3084011 1527389 492895.75 30709.0 7547276 299234.0 2387450 373229.5 25459396 19791136 2165454.0 ## P101007 794592.2 31187.21 26736000 4728273 1855034 1017754.44 90723.0 12608340 440482.2 5896738 400386.6 15742145 52497536 2231037.2 ## P101009 671497.6 21561.75 31187900 4140767 1444713 118820.93 168136.0 10253790 491346.8 2785016 301840.8 23710054 48267136 992205.4 ## P101010 1133763.9 115934.38 17916018 2434359 3420016 1812900.50 163988.0 14821266 359500.1 1552196 548330.4 22917482 34226984 1125607.0 ## [ reached getOption(&quot;max.print&quot;) -- omitted 1 row ] 3.6.5 Associations Among Features 3.6.5.1 Single network with Pearson correlation as association measure Since Pearson correlations may lead to compositional effects when applied to sequencing data, we use the clr transformation as normalization method. Zero treatment is necessary in this case. InputData: numeric matrix. Can be a count matrix (rows are samples, columns are Features). Method to compute the associations between features (argument measure). Normalization method: normMethod: clr zeroMethod: multRepl sparsMethod: threshold A threshold of 0.3 is used as sparsification method, so that only OTUs with an absolute correlation greater than or equal to 0.3 are connected. 3.6.5.1.1 Building network model net_single &lt;- netConstruct(features_tab, measure = &quot;pearson&quot;, normMethod = &quot;clr&quot;, zeroMethod = &quot;multRepl&quot;, sparsMethod = &quot;threshold&quot;, thresh = 0.3, verbose = 3, seed = 123) 3.6.5.1.2 Visualizing the network primary plot props_single &lt;- netAnalyze(net_single, clustMethod = &quot;cluster_fast_greedy&quot;) plot(props_single, nodeColor = &quot;cluster&quot;, nodeSize = &quot;eigenvector&quot;, title1 = &quot;Network on metabolomics with Pearson correlations&quot;, showTitle = TRUE, cexTitle = 1.5) legend(0.7, 1.1, cex = 1, title = &quot;estimated correlation:&quot;, legend = c(&quot;+&quot;,&quot;-&quot;), lty = 1, lwd = 3, col = c(&quot;#009900&quot;,&quot;red&quot;), bty = &quot;n&quot;, horiz = TRUE) improve the visualization by changing the following arguments: repulsion = 0.8: Place the nodes further apart rmSingles = TRUE: Single nodes are removed labelScale = FALSE and cexLabels = 1.6: All labels have equal size and are enlarged to improve readability of small node’s labels nodeSizeSpread = 3 (default is 4): Node sizes are more similar if the value is decreased. This argument (in combination with cexNodes) is useful to enlarge small nodes while keeping the size of big nodes. plot(props_single, nodeColor = &quot;cluster&quot;, nodeSize = &quot;eigenvector&quot;, repulsion = 0.8, rmSingles = TRUE, labelScale = FALSE, cexLabels = 1.6, nodeSizeSpread = 3, cexNodes = 2, title1 = &quot;Network on metabolomics with Pearson correlations&quot;, showTitle = TRUE, cexTitle = 1.5) legend(0.7, 1.1, cex = 1.2, title = &quot;estimated correlation:&quot;, legend = c(&quot;+&quot;,&quot;-&quot;), lty = 1, lwd = 3, col = c(&quot;#009900&quot;,&quot;red&quot;), bty = &quot;n&quot;, horiz = TRUE) 3.6.5.2 Single network with spearman correlation as association measure 3.6.5.2.1 Building network model net_single2 &lt;- netConstruct(features_tab, measure = &quot;spearman&quot;, normMethod = &quot;clr&quot;, zeroMethod = &quot;multRepl&quot;, sparsMethod = &quot;threshold&quot;, thresh = 0.3, verbose = 3, seed = 123) 3.6.5.2.2 Visualizing the network props_single2 &lt;- netAnalyze(net_single2, clustMethod = &quot;cluster_fast_greedy&quot;) plot(props_single2, nodeColor = &quot;cluster&quot;, nodeSize = &quot;eigenvector&quot;, repulsion = 0.8, rmSingles = TRUE, labelScale = FALSE, cexLabels = 1.6, nodeSizeSpread = 3, cexNodes = 2, title1 = &quot;Network on metabolomics with Spearman correlations&quot;, showTitle = TRUE, cexTitle = 1.5) legend(0.7, 1.1, cex = 1.2, title = &quot;estimated correlation:&quot;, legend = c(&quot;+&quot;,&quot;-&quot;), lty = 1, lwd = 3, col = c(&quot;#009900&quot;,&quot;red&quot;), bty = &quot;n&quot;, horiz = TRUE) 3.6.5.3 Single network with WGCNA (bicor) as association measure Biweight Midcorrelation bicor() from WGCNA package. 3.6.5.3.1 Building network model net_single3 &lt;- netConstruct(features_tab, measure = &quot;bicor&quot;, measurePar = list(use = &quot;all.obs&quot;, maxPOutliers = 1, nThreads = 2), filtTax = &quot;highestVar&quot;, filtTaxPar = list(highestVar = 50), filtSamp = &quot;totalReads&quot;, filtSampPar = list(totalReads = 100), dissFunc = &quot;TOMdiss&quot;, verbose = 3) ## ..will use 2 parallel threads. ## Fraction of slow calculations: 0.000000 3.6.5.3.2 Visualizing the network props_single3 &lt;- netAnalyze(net_single3, clustMethod = &quot;cluster_fast_greedy&quot;) plot(props_single3, nodeColor = &quot;cluster&quot;, nodeSize = &quot;eigenvector&quot;, repulsion = 0.8, rmSingles = TRUE, labelScale = FALSE, cexLabels = 1.6, nodeSizeSpread = 3, cexNodes = 2, title1 = &quot;Network on metabolomics with WGCNA correlations&quot;, showTitle = TRUE, cexTitle = 1.5) legend(0.7, 1.1, cex = 1.2, title = &quot;estimated correlation:&quot;, legend = c(&quot;+&quot;,&quot;-&quot;), lty = 1, lwd = 3, col = c(&quot;#009900&quot;,&quot;red&quot;), bty = &quot;n&quot;, horiz = TRUE) 3.6.6 Network comparison Comparing two networks by NetCoMi. 3.6.6.1 Data preparing group_names &lt;- c(&quot;Mild&quot;, &quot;Severe&quot;) se_filter_subset &lt;- se_filter[, se_filter$group %in% group_names] se_filter_subset$group &lt;- factor(as.character(se_filter_subset$group)) features_tab &lt;- SummarizedExperiment::assay(se_filter_subset) %&gt;% t() features_tab[is.na(features_tab)] &lt;- 0 group_vector &lt;- se_filter_subset$group 3.6.6.2 Building network model net_group &lt;- netConstruct(features_tab, group = group_vector, measure = &quot;pearson&quot;, normMethod = &quot;clr&quot;, zeroMethod = &quot;multRepl&quot;, sparsMethod = &quot;threshold&quot;, thresh = 0.3, verbose = 3, seed = 123) 3.6.6.3 Network analysis props_group &lt;- netAnalyze(net_group, centrLCC = FALSE, avDissIgnoreInf = TRUE, sPathNorm = FALSE, clustMethod = &quot;cluster_fast_greedy&quot;, hubPar = c(&quot;degree&quot;, &quot;between&quot;, &quot;closeness&quot;), hubQuant = 0.9, lnormFit = TRUE, normDeg = FALSE, normBetw = FALSE, normClose = FALSE, normEigen = FALSE) summary(props_group) ## ## Component sizes ## ``````````````` ## Group 1: ## size: 167 ## #: 1 ## ## Group 2: ## size: 167 ## #: 1 ## ______________________________ ## Global network properties ## ````````````````````````` ## group &#39;1&#39; group &#39;2&#39; ## Number of components 1.00000 1.00000 ## Clustering coefficient 0.46890 0.45147 ## Modularity 0.06069 0.06436 ## Positive edge percentage 50.68785 52.11131 ## Edge density 0.37234 0.37075 ## Natural connectivity 0.10764 0.10844 ## Vertex connectivity 33.00000 35.00000 ## Edge connectivity 33.00000 35.00000 ## Average dissimilarity* 0.67686 0.67218 ## Average path length** 0.87528 0.86466 ## ## *Dissimilarity = 1 - edge weight ## **Path length: Sum of dissimilarities along the path ## ## ______________________________ ## Clusters ## - In the whole network ## - Algorithm: cluster_fast_greedy ## ```````````````````````````````` ## group &#39;1&#39;: ## name: 1 2 3 ## #: 81 33 53 ## ## group &#39;2&#39;: ## name: 1 2 3 ## #: 55 52 60 ## ## ______________________________ ## Hubs ## - In alphabetical/numerical order ## - Based on log-normal quantiles of centralities ## ``````````````````````````````````````````````` ## group &#39;1&#39; group &#39;2&#39; ## M_48258 M_33230 ## M_52447 M_35631 ## M_52467 M_42398 ## M_52452 ## M_52462 ## ## ______________________________ ## Centrality measures ## - In decreasing order ## - Computed for the complete network ## ```````````````````````````````````` ## Degree (unnormalized): ## group &#39;1&#39; group &#39;2&#39; ## M_53180 90 67 ## M_48258 89 63 ## M_52467 84 45 ## M_52447 83 56 ## M_46115 82 57 ## ______ ______ ## M_35631 57 83 ## M_33230 80 82 ## M_52474 77 81 ## M_52462 64 79 ## M_52452 61 79 ## ## Betweenness centrality (unnormalized): ## group &#39;1&#39; group &#39;2&#39; ## M_53180 127 70 ## M_52447 122 53 ## M_62805 117 45 ## M_52467 113 23 ## M_42449 107 76 ## ______ ______ ## M_42398 65 126 ## M_36600 63 104 ## M_52281 39 97 ## M_52462 70 96 ## M_52452 75 96 ## ## Closeness centrality (unnormalized): ## group &#39;1&#39; group &#39;2&#39; ## M_52464 234.21854 218.76093 ## M_52447 233.58239 219.26645 ## M_52669 233.55223 188.04641 ## M_33961 233.5356 237.105 ## M_19263 232.73107 211.31774 ## ______ ______ ## M_33230 228.08708 240.52716 ## M_52462 220.20663 240.09054 ## M_33955 231.77567 239.49465 ## M_35631 206.06295 239.35578 ## M_52474 228.59113 239.13909 ## ## Eigenvector centrality (unnormalized): ## group &#39;1&#39; group &#39;2&#39; ## M_52467 0.12638 0.05312 ## M_33230 0.12329 0.13395 ## M_48258 0.12211 0.11358 ## M_52447 0.12038 0.07532 ## M_35186 0.12025 0.13431 ## ______ ______ ## M_35631 0.07576 0.13915 ## M_52474 0.10472 0.13506 ## M_33955 0.12001 0.13501 ## M_35186 0.12025 0.13431 ## M_33230 0.12329 0.13395 3.6.6.4 Visualizing the network plot(props_group, sameLayout = TRUE, layoutGroup = 1, rmSingles = &quot;inboth&quot;, nodeSize = &quot;mclr&quot;, labelScale = FALSE, cexNodes = 1, cexLabels = 1.5, cexHubLabels = 2, cexTitle = 2, groupNames = group_names, hubBorderCol = &quot;gray40&quot;) legend(&quot;bottom&quot;, title = &quot;estimated association:&quot;, legend = c(&quot;+&quot;, &quot;-&quot;), col = c(&quot;#009900&quot;,&quot;red&quot;), inset = 0.04, cex = 3, lty = 1, lwd = 4, bty = &quot;n&quot;, horiz = TRUE) 3.6.6.5 Quantitative network comparison comp_group &lt;- netCompare(props_group, permTest = FALSE, verbose = FALSE) summary(comp_group, groupNames = group_names, showCentr = c(&quot;degree&quot;, &quot;between&quot;, &quot;closeness&quot;), numbNodes = 5) ## ## Comparison of Network Properties ## ---------------------------------- ## CALL: ## netCompare(x = props_group, permTest = FALSE, verbose = FALSE) ## ## ______________________________ ## Global network properties ## ````````````````````````` ## Mild Severe difference ## Number of components 1.000 1.000 0.000 ## Clustering coefficient 0.469 0.451 0.017 ## Moduarity 0.061 0.064 0.004 ## Positive edge percentage 50.688 52.111 1.423 ## Edge density 0.372 0.371 0.002 ## Natural connectivity 0.108 0.108 0.001 ## Vertex connectivity 33.000 35.000 2.000 ## Edge connectivity 33.000 35.000 2.000 ## Average dissimilarity* 0.677 0.672 0.005 ## Average path length** 0.875 0.865 0.011 ## ----- ## *: Dissimilarity = 1 - edge weight ## **Path length: Sum of dissimilarities along the path ## ## ______________________________ ## Jaccard index (similarity betw. sets of most central nodes) ## `````````````````````````````````````````````````````````` ## Jacc P(&lt;=Jacc) P(&gt;=Jacc) ## degree 0.171 0.001255 ** 0.999517 ## betweenness centr. 0.237 0.045289 * 0.974501 ## closeness centr. 0.348 0.656742 0.442460 ## eigenvec. centr. 0.382 0.838125 0.231086 ## hub taxa 0.000 0.039018 * 1.000000 ## ----- ## Jaccard index ranges from 0 (compl. different) to 1 (sets equal) ## ## ______________________________ ## Adjusted Rand index (similarity betw. clusterings) ## `````````````````````````````````````````````````` ## ARI p-value ## 0.048 0.001 ## ----- ## ARI in [-1,1] with ARI=1: perfect agreement betw. clusterings, ## ARI=0: expected for two random clusterings ## p-value: two-tailed test with null hypothesis ARI=0 ## ## ______________________________ ## Centrality measures ## - In decreasing order ## - Computed for the complete network ## ```````````````````````````````````` ## Degree (unnormalized): ## Mild Severe abs.diff. ## M_52610 35 75 40 ## M_52467 84 45 39 ## M_52669 77 38 39 ## M_62805 81 45 36 ## M_52478 36 68 32 ## ## Betweenness centrality (unnormalized): ## Mild Severe abs.diff. ## M_52467 113 23 90 ## M_57663 101 24 77 ## M_62805 117 45 72 ## M_52669 87 16 71 ## M_52447 122 53 69 ## ## Closeness centrality (unnormalized): ## Mild Severe abs.diff. ## M_52669 233.552 188.046 45.506 ## M_52467 232.354 194.418 37.936 ## M_35631 206.063 239.356 33.293 ## M_52610 187.991 219.596 31.605 ## M_35153 191.201 222.693 31.491 ## ## _________________________________________________________ ## Significance codes: ***: 0.001, **: 0.01, *: 0.05, .: 0.1 3.7 Systematic Information devtools::session_info() ## ─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os macOS Monterey 12.2.1 ## system x86_64, darwin17.0 ## ui RStudio ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Asia/Shanghai ## date 2023-11-27 ## rstudio 2023.09.0+463 Desert Sunflower (desktop) ## pandoc 3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [2] CRAN (R 4.1.0) ## ade4 1.7-22 2023-02-06 [2] CRAN (R 4.1.2) ## affy 1.72.0 2021-10-26 [2] Bioconductor ## affyio 1.64.0 2021-10-26 [2] Bioconductor ## annotate 1.72.0 2021-10-26 [2] Bioconductor ## AnnotationDbi * 1.60.2 2023-03-10 [2] Bioconductor ## ape 5.7-1 2023-03-13 [2] CRAN (R 4.1.2) ## aplot 0.1.10 2023-03-08 [2] CRAN (R 4.1.2) ## attempt 0.3.1 2020-05-03 [2] CRAN (R 4.1.0) ## backports 1.4.1 2021-12-13 [2] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [2] CRAN (R 4.1.0) ## Biobase * 2.54.0 2021-10-26 [2] Bioconductor ## BiocGenerics * 0.40.0 2021-10-26 [2] Bioconductor ## BiocManager 1.30.21 2023-06-10 [2] CRAN (R 4.1.3) ## BiocParallel 1.28.3 2021-12-09 [2] Bioconductor ## biomformat 1.22.0 2021-10-26 [2] Bioconductor ## Biostrings 2.62.0 2021-10-26 [2] Bioconductor ## bit 4.0.5 2022-11-15 [2] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [2] CRAN (R 4.1.0) ## bitops 1.0-7 2021-04-24 [2] CRAN (R 4.1.0) ## blob 1.2.4 2023-03-17 [2] CRAN (R 4.1.2) ## bookdown 0.34 2023-05-09 [2] CRAN (R 4.1.2) ## broom 1.0.5 2023-06-09 [2] CRAN (R 4.1.3) ## bslib 0.6.0 2023-11-21 [1] CRAN (R 4.1.3) ## cachem 1.0.8 2023-05-01 [2] CRAN (R 4.1.2) ## Cairo 1.6-0 2022-07-05 [2] CRAN (R 4.1.2) ## callr 3.7.3 2022-11-02 [2] CRAN (R 4.1.2) ## car 3.1-2 2023-03-30 [2] CRAN (R 4.1.2) ## carData 3.0-5 2022-01-06 [2] CRAN (R 4.1.2) ## caret 6.0-94 2023-03-21 [2] CRAN (R 4.1.2) ## caTools 1.18.2 2021-03-28 [2] CRAN (R 4.1.0) ## cellranger 1.1.0 2016-07-27 [2] CRAN (R 4.1.0) ## checkmate 2.2.0 2023-04-27 [2] CRAN (R 4.1.2) ## circlize 0.4.15 2022-05-10 [2] CRAN (R 4.1.2) ## class 7.3-22 2023-05-03 [2] CRAN (R 4.1.2) ## cli 3.6.1 2023-03-23 [2] CRAN (R 4.1.2) ## clue 0.3-64 2023-01-31 [2] CRAN (R 4.1.2) ## cluster * 2.1.4 2022-08-22 [2] CRAN (R 4.1.2) ## clusterProfiler * 4.2.2 2022-01-13 [2] Bioconductor ## codetools 0.2-19 2023-02-01 [2] CRAN (R 4.1.2) ## coin 1.4-2 2021-10-08 [2] CRAN (R 4.1.0) ## colorspace 2.1-0 2023-01-23 [2] CRAN (R 4.1.2) ## ComplexHeatmap 2.10.0 2021-10-26 [2] Bioconductor ## config 0.3.1 2020-12-17 [2] CRAN (R 4.1.0) ## corpcor 1.6.10 2021-09-16 [2] CRAN (R 4.1.0) ## cowplot 1.1.1 2020-12-30 [2] CRAN (R 4.1.0) ## crayon 1.5.2 2022-09-29 [2] CRAN (R 4.1.2) ## crmn 0.0.21 2020-02-10 [2] CRAN (R 4.1.0) ## curl 5.0.1 2023-06-07 [2] CRAN (R 4.1.3) ## data.table 1.14.8 2023-02-17 [2] CRAN (R 4.1.2) ## DBI 1.1.3 2022-06-18 [2] CRAN (R 4.1.2) ## DelayedArray 0.20.0 2021-10-26 [2] Bioconductor ## dendextend * 1.17.1 2023-03-25 [2] CRAN (R 4.1.2) ## DESeq2 1.34.0 2021-10-26 [2] Bioconductor ## devtools 2.4.5 2022-10-11 [2] CRAN (R 4.1.2) ## digest 0.6.33 2023-07-07 [1] CRAN (R 4.1.3) ## DO.db 2.9 2022-04-11 [2] Bioconductor ## doParallel 1.0.17 2022-02-07 [2] CRAN (R 4.1.2) ## doRNG 1.8.6 2023-01-16 [2] CRAN (R 4.1.2) ## DOSE 3.20.1 2021-11-18 [2] Bioconductor ## doSNOW 1.0.20 2022-02-04 [2] CRAN (R 4.1.2) ## downloader 0.4 2015-07-09 [2] CRAN (R 4.1.0) ## dplyr * 1.1.2 2023-04-20 [2] CRAN (R 4.1.2) ## DT 0.28 2023-05-18 [2] CRAN (R 4.1.3) ## dynamicTreeCut * 1.63-1 2016-03-11 [2] CRAN (R 4.1.0) ## e1071 1.7-13 2023-02-01 [2] CRAN (R 4.1.2) ## edgeR 3.36.0 2021-10-26 [2] Bioconductor ## ellipse 0.4.5 2023-04-05 [2] CRAN (R 4.1.2) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.1.0) ## enrichplot 1.14.2 2022-02-24 [2] Bioconductor ## evaluate 0.21 2023-05-05 [2] CRAN (R 4.1.2) ## factoextra * 1.0.7 2020-04-01 [2] CRAN (R 4.1.0) ## fansi 1.0.4 2023-01-22 [2] CRAN (R 4.1.2) ## farver 2.1.1 2022-07-06 [2] CRAN (R 4.1.2) ## fastcluster * 1.2.3 2021-05-24 [2] CRAN (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] CRAN (R 4.1.2) ## fastmatch 1.1-3 2021-07-23 [2] CRAN (R 4.1.0) ## fdrtool 1.2.17 2021-11-13 [2] CRAN (R 4.1.0) ## fgsea 1.20.0 2021-10-26 [2] Bioconductor ## filematrix 1.3 2018-02-27 [2] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [2] CRAN (R 4.1.2) ## foreign 0.8-84 2022-12-06 [2] CRAN (R 4.1.2) ## forestplot 3.1.1 2022-12-06 [2] CRAN (R 4.1.2) ## Formula 1.2-5 2023-02-24 [2] CRAN (R 4.1.2) ## fs 1.6.2 2023-04-25 [2] CRAN (R 4.1.2) ## furrr 0.3.1 2022-08-15 [2] CRAN (R 4.1.2) ## future 1.33.0 2023-07-01 [2] CRAN (R 4.1.3) ## future.apply 1.11.0 2023-05-21 [2] CRAN (R 4.1.3) ## genefilter 1.76.0 2021-10-26 [2] Bioconductor ## geneplotter 1.72.0 2021-10-26 [2] Bioconductor ## generics 0.1.3 2022-07-05 [2] CRAN (R 4.1.2) ## GenomeInfoDb * 1.30.1 2022-01-30 [2] Bioconductor ## GenomeInfoDbData 1.2.7 2022-03-09 [2] Bioconductor ## GenomicRanges * 1.46.1 2021-11-18 [2] Bioconductor ## GetoptLong 1.0.5 2020-12-15 [2] CRAN (R 4.1.0) ## ggforce 0.4.1 2022-10-04 [2] CRAN (R 4.1.2) ## ggfun 0.1.1 2023-06-24 [2] CRAN (R 4.1.3) ## ggplot2 * 3.4.2 2023-04-03 [2] CRAN (R 4.1.2) ## ggplotify 0.1.1 2023-06-27 [2] CRAN (R 4.1.3) ## ggpubr 0.6.0 2023-02-10 [2] CRAN (R 4.1.2) ## ggraph * 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71) ## ggrepel 0.9.3 2023-02-03 [2] CRAN (R 4.1.2) ## ggsignif 0.6.4 2022-10-13 [2] CRAN (R 4.1.2) ## ggtree 3.2.1 2021-11-16 [2] Bioconductor ## glasso 1.11 2019-10-01 [2] CRAN (R 4.1.0) ## glmnet * 4.1-7 2023-03-23 [2] CRAN (R 4.1.2) ## GlobalOptions 0.1.2 2020-06-10 [2] CRAN (R 4.1.0) ## globals 0.16.2 2022-11-21 [2] CRAN (R 4.1.2) ## globaltest 5.48.0 2021-10-26 [2] Bioconductor ## glue * 1.6.2 2022-02-24 [2] CRAN (R 4.1.2) ## Gmisc * 3.0.2 2023-03-13 [2] CRAN (R 4.1.2) ## gmm 1.8 2023-06-06 [2] CRAN (R 4.1.3) ## gmp 0.7-1 2023-02-07 [2] CRAN (R 4.1.2) ## GO.db 3.14.0 2022-04-11 [2] Bioconductor ## golem 0.4.1 2023-06-05 [2] CRAN (R 4.1.3) ## GOSemSim 2.20.0 2021-10-26 [2] Bioconductor ## gower 1.0.1 2022-12-22 [2] CRAN (R 4.1.2) ## gplots 3.1.3 2022-04-25 [2] CRAN (R 4.1.2) ## graphlayouts 1.0.0 2023-05-01 [2] CRAN (R 4.1.2) ## gridExtra 2.3 2017-09-09 [2] CRAN (R 4.1.0) ## gridGraphics 0.5-1 2020-12-13 [2] CRAN (R 4.1.0) ## gtable 0.3.3 2023-03-21 [2] CRAN (R 4.1.2) ## gtools 3.9.4 2022-11-27 [2] CRAN (R 4.1.2) ## hardhat 1.3.0 2023-03-30 [2] CRAN (R 4.1.2) ## highr 0.10 2022-12-22 [2] CRAN (R 4.1.2) ## Hmisc 5.1-0 2023-05-08 [2] CRAN (R 4.1.2) ## hms 1.1.3 2023-03-21 [2] CRAN (R 4.1.2) ## htmlTable * 2.4.1 2022-07-07 [2] CRAN (R 4.1.2) ## htmltools 0.5.7 2023-11-03 [1] CRAN (R 4.1.3) ## htmlwidgets 1.6.2 2023-03-17 [2] CRAN (R 4.1.2) ## httpuv 1.6.11 2023-05-11 [2] CRAN (R 4.1.3) ## httr * 1.4.6 2023-05-08 [2] CRAN (R 4.1.2) ## huge 1.3.5 2021-06-30 [2] CRAN (R 4.1.0) ## igraph * 1.5.0 2023-06-16 [1] CRAN (R 4.1.3) ## impute 1.68.0 2021-10-26 [2] Bioconductor ## imputeLCMD 2.1 2022-06-10 [2] CRAN (R 4.1.2) ## ipred 0.9-14 2023-03-09 [2] CRAN (R 4.1.2) ## IRanges * 2.28.0 2021-10-26 [2] Bioconductor ## irlba 2.3.5.1 2022-10-03 [2] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [2] CRAN (R 4.1.2) ## itertools 0.1-3 2014-03-12 [2] CRAN (R 4.1.0) ## jpeg 0.1-10 2022-11-29 [2] CRAN (R 4.1.2) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.0) ## jsonlite 1.8.7 2023-06-29 [2] CRAN (R 4.1.3) ## KEGGREST 1.34.0 2021-10-26 [2] Bioconductor ## KernSmooth 2.23-22 2023-07-10 [2] CRAN (R 4.1.3) ## knitr 1.43 2023-05-25 [2] CRAN (R 4.1.3) ## labeling 0.4.2 2020-10-20 [2] CRAN (R 4.1.0) ## later 1.3.1 2023-05-02 [2] CRAN (R 4.1.2) ## lattice 0.21-8 2023-04-05 [2] CRAN (R 4.1.2) ## lava 1.7.2.1 2023-02-27 [2] CRAN (R 4.1.2) ## lavaan 0.6-15 2023-03-14 [2] CRAN (R 4.1.2) ## lazyeval 0.2.2 2019-03-15 [2] CRAN (R 4.1.0) ## libcoin 1.0-9 2021-09-27 [2] CRAN (R 4.1.0) ## lifecycle 1.0.3 2022-10-07 [2] CRAN (R 4.1.2) ## limma 3.50.3 2022-04-07 [2] Bioconductor ## listenv 0.9.0 2022-12-16 [2] CRAN (R 4.1.2) ## locfit 1.5-9.8 2023-06-11 [2] CRAN (R 4.1.3) ## lubridate 1.9.2 2023-02-10 [2] CRAN (R 4.1.2) ## magrittr * 2.0.3 2022-03-30 [2] CRAN (R 4.1.2) ## MALDIquant 1.22.1 2023-03-20 [2] CRAN (R 4.1.2) ## MASS 7.3-60 2023-05-04 [2] CRAN (R 4.1.2) ## massdatabase * 1.0.7 2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93) ## massdataset * 1.0.24 2023-05-30 [2] gitlab (jaspershen/massdataset@b397116) ## masstools * 1.0.10 2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc) ## Matrix * 1.6-0 2023-07-08 [2] CRAN (R 4.1.3) ## MatrixGenerics * 1.6.0 2021-10-26 [2] Bioconductor ## matrixStats * 1.0.0 2023-06-02 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.1.0) ## MetaboAnalystR * 3.2.0 2022-06-28 [2] Github (xia-lab/MetaboAnalystR@892a31b) ## metagenomeSeq 1.36.0 2021-10-26 [2] Bioconductor ## metid * 1.2.26 2023-05-30 [2] gitlab (jaspershen/metid@6bde121) ## metpath * 1.0.5 2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f) ## mgcv 1.8-42 2023-03-02 [2] CRAN (R 4.1.2) ## MicrobiomeProfiler * 1.0.0 2021-10-26 [2] Bioconductor ## mime 0.12 2021-09-28 [2] CRAN (R 4.1.0) ## miniUI 0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0) ## missForest 1.5 2022-04-14 [2] CRAN (R 4.1.2) ## mixedCCA 1.6.2 2022-09-09 [2] CRAN (R 4.1.2) ## mixOmics 6.18.1 2021-11-18 [2] Bioconductor (R 4.1.2) ## mnormt 2.1.1 2022-09-26 [2] CRAN (R 4.1.2) ## ModelMetrics 1.2.2.2 2020-03-17 [2] CRAN (R 4.1.0) ## modeltools 0.2-23 2020-03-05 [2] CRAN (R 4.1.0) ## MsCoreUtils 1.6.2 2022-02-24 [2] Bioconductor ## MSnbase * 2.20.4 2022-01-16 [2] Bioconductor ## multcomp 1.4-25 2023-06-20 [2] CRAN (R 4.1.3) ## multtest 2.50.0 2021-10-26 [2] Bioconductor ## munsell 0.5.0 2018-06-12 [2] CRAN (R 4.1.0) ## mvtnorm 1.2-2 2023-06-08 [2] CRAN (R 4.1.3) ## mzID 1.32.0 2021-10-26 [2] Bioconductor ## mzR * 2.28.0 2021-10-27 [2] Bioconductor ## ncdf4 1.21 2023-01-07 [2] CRAN (R 4.1.2) ## NetCoMi * 1.0.3 2022-07-14 [2] Github (stefpeschel/NetCoMi@d4d80d3) ## nlme 3.1-162 2023-01-31 [2] CRAN (R 4.1.2) ## nnet 7.3-19 2023-05-03 [2] CRAN (R 4.1.2) ## norm 1.0-11.1 2023-06-18 [2] CRAN (R 4.1.3) ## openxlsx 4.2.5.2 2023-02-06 [2] CRAN (R 4.1.2) ## org.Mm.eg.db * 3.14.0 2022-11-23 [2] Bioconductor ## parallelly 1.36.0 2023-05-26 [2] CRAN (R 4.1.3) ## patchwork 1.1.2 2022-08-19 [2] CRAN (R 4.1.2) ## pbapply 1.7-2 2023-06-27 [2] CRAN (R 4.1.3) ## pbivnorm 0.6.0 2015-01-23 [2] CRAN (R 4.1.0) ## pcaMethods 1.86.0 2021-10-26 [2] Bioconductor ## pcaPP 2.0-3 2022-10-24 [2] CRAN (R 4.1.2) ## permute 0.9-7 2022-01-27 [2] CRAN (R 4.1.2) ## pheatmap 1.0.12 2019-01-04 [2] CRAN (R 4.1.0) ## phyloseq 1.38.0 2021-10-26 [2] Bioconductor ## pillar 1.9.0 2023-03-22 [2] CRAN (R 4.1.2) ## pkgbuild 1.4.2 2023-06-26 [2] CRAN (R 4.1.3) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.1.0) ## pkgload 1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3) ## plotly * 4.10.2 2023-06-03 [2] CRAN (R 4.1.3) ## plyr 1.8.8 2022-11-11 [2] CRAN (R 4.1.2) ## png 0.1-8 2022-11-29 [2] CRAN (R 4.1.2) ## polyclip 1.10-4 2022-10-20 [2] CRAN (R 4.1.2) ## POMA * 1.7.2 2022-07-26 [2] Github (pcastellanoescuder/POMA@bc8a972) ## preprocessCore 1.56.0 2021-10-26 [2] Bioconductor ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.1.0) ## pROC 1.18.4 2023-07-06 [2] CRAN (R 4.1.3) ## processx 3.8.2 2023-06-30 [2] CRAN (R 4.1.3) ## prodlim 2023.03.31 2023-04-02 [2] CRAN (R 4.1.2) ## profvis 0.3.8 2023-05-02 [2] CRAN (R 4.1.2) ## progress 1.2.2 2019-05-16 [2] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0) ## ProtGenerics * 1.26.0 2021-10-26 [2] Bioconductor ## proxy 0.4-27 2022-06-09 [2] CRAN (R 4.1.2) ## ps 1.7.5 2023-04-18 [2] CRAN (R 4.1.2) ## psych 2.3.6 2023-06-21 [2] CRAN (R 4.1.3) ## pulsar 0.3.10 2023-01-26 [2] CRAN (R 4.1.2) ## purrr 1.0.1 2023-01-10 [2] CRAN (R 4.1.2) ## qgraph 1.9.5 2023-05-16 [2] CRAN (R 4.1.3) ## qs 0.25.5 2023-02-22 [2] CRAN (R 4.1.2) ## quadprog 1.5-8 2019-11-20 [2] CRAN (R 4.1.0) ## qvalue 2.26.0 2021-10-26 [2] Bioconductor ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.1.0) ## ragg 1.2.5 2023-01-12 [2] CRAN (R 4.1.2) ## randomForest 4.7-1.1 2022-05-23 [2] CRAN (R 4.1.2) ## RankProd 3.20.0 2021-10-26 [2] Bioconductor ## RApiSerialize 0.1.2 2022-08-25 [2] CRAN (R 4.1.2) ## rARPACK 0.11-0 2016-03-10 [2] CRAN (R 4.1.0) ## rbibutils 2.2.13 2023-01-13 [2] CRAN (R 4.1.2) ## RColorBrewer 1.1-3 2022-04-03 [2] CRAN (R 4.1.2) ## Rcpp * 1.0.11 2023-07-06 [1] CRAN (R 4.1.3) ## RcppParallel 5.1.7 2023-02-27 [2] CRAN (R 4.1.2) ## RCurl 1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2) ## Rdisop 1.54.0 2021-10-26 [2] Bioconductor ## Rdpack 2.4 2022-07-20 [2] CRAN (R 4.1.2) ## readr 2.1.4 2023-02-10 [2] CRAN (R 4.1.2) ## readxl * 1.4.3 2023-07-06 [2] CRAN (R 4.1.3) ## recipes 1.0.6 2023-04-25 [2] CRAN (R 4.1.2) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.1.0) ## reshape2 1.4.4 2020-04-09 [2] CRAN (R 4.1.0) ## rhdf5 2.38.1 2022-03-10 [2] Bioconductor ## rhdf5filters 1.6.0 2021-10-26 [2] Bioconductor ## Rhdf5lib 1.16.0 2021-10-26 [2] Bioconductor ## rjson 0.2.21 2022-01-09 [2] CRAN (R 4.1.2) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.1.2) ## rmarkdown 2.23 2023-07-01 [2] CRAN (R 4.1.3) ## Rmpfr 0.9-2 2023-04-22 [2] CRAN (R 4.1.2) ## rngtools 1.5.2 2021-09-20 [2] CRAN (R 4.1.0) ## rootSolve 1.8.2.3 2021-09-29 [2] CRAN (R 4.1.0) ## ropls * 1.26.4 2022-01-11 [2] Bioconductor ## rpart 4.1.19 2022-10-21 [2] CRAN (R 4.1.2) ## Rserve * 1.8-11 2022-11-28 [2] CRAN (R 4.1.2) ## RSpectra 0.16-1 2022-04-24 [2] CRAN (R 4.1.2) ## RSQLite 2.3.1 2023-04-03 [2] CRAN (R 4.1.2) ## rstatix 0.7.2 2023-02-01 [2] CRAN (R 4.1.2) ## rstudioapi 0.15.0 2023-07-07 [2] CRAN (R 4.1.3) ## rvest 1.0.3 2022-08-19 [2] CRAN (R 4.1.2) ## S4Vectors * 0.32.4 2022-03-29 [2] Bioconductor ## sandwich 3.0-2 2022-06-15 [2] CRAN (R 4.1.2) ## sass 0.4.6 2023-05-03 [2] CRAN (R 4.1.2) ## scales 1.2.1 2022-08-20 [2] CRAN (R 4.1.2) ## scatterpie 0.2.1 2023-06-07 [2] CRAN (R 4.1.3) ## scrime 1.3.5 2018-12-01 [2] CRAN (R 4.1.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.1.0) ## shadowtext 0.1.2 2022-04-22 [2] CRAN (R 4.1.2) ## shape 1.4.6 2021-05-19 [2] CRAN (R 4.1.0) ## shiny 1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3) ## shinycustomloader 0.9.0 2018-03-27 [2] CRAN (R 4.1.0) ## shinyWidgets 0.7.6 2023-01-08 [2] CRAN (R 4.1.2) ## siggenes 1.68.0 2021-10-26 [2] Bioconductor ## snow 0.4-4 2021-10-27 [2] CRAN (R 4.1.0) ## SpiecEasi * 1.1.2 2022-07-14 [2] Github (zdk123/SpiecEasi@c463727) ## SPRING * 1.0.4 2022-08-03 [2] Github (GraceYoon/SPRING@3d641a4) ## stringdist 0.9.10 2022-11-07 [2] CRAN (R 4.1.2) ## stringfish 0.15.8 2023-05-30 [2] CRAN (R 4.1.3) ## stringi 1.7.12 2023-01-11 [2] CRAN (R 4.1.2) ## stringr 1.5.0 2022-12-02 [2] CRAN (R 4.1.2) ## SummarizedExperiment * 1.24.0 2021-10-26 [2] Bioconductor ## survival 3.5-5 2023-03-12 [2] CRAN (R 4.1.2) ## systemfonts 1.0.4 2022-02-11 [2] CRAN (R 4.1.2) ## textshaping 0.3.6 2021-10-13 [2] CRAN (R 4.1.0) ## TH.data 1.1-2 2023-04-17 [2] CRAN (R 4.1.2) ## tibble * 3.2.1 2023-03-20 [2] CRAN (R 4.1.2) ## tidygraph 1.2.3 2023-02-01 [2] CRAN (R 4.1.2) ## tidyr 1.3.0 2023-01-24 [2] CRAN (R 4.1.2) ## tidyselect 1.2.0 2022-10-10 [2] CRAN (R 4.1.2) ## tidytree 0.4.2 2022-12-18 [2] CRAN (R 4.1.2) ## timechange 0.2.0 2023-01-11 [2] CRAN (R 4.1.2) ## timeDate 4022.108 2023-01-07 [2] CRAN (R 4.1.2) ## tmvtnorm 1.5 2022-03-22 [2] CRAN (R 4.1.2) ## treeio 1.18.1 2021-11-14 [2] Bioconductor ## tweenr 2.0.2 2022-09-06 [2] CRAN (R 4.1.2) ## tzdb 0.4.0 2023-05-12 [2] CRAN (R 4.1.3) ## urlchecker 1.0.1 2021-11-30 [2] CRAN (R 4.1.0) ## usethis 2.2.2 2023-07-06 [2] CRAN (R 4.1.3) ## utf8 1.2.3 2023-01-31 [2] CRAN (R 4.1.2) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.1.3) ## vegan 2.6-4 2022-10-11 [2] CRAN (R 4.1.2) ## VGAM 1.1-8 2023-03-09 [2] CRAN (R 4.1.2) ## viridis 0.6.3 2023-05-03 [2] CRAN (R 4.1.2) ## viridisLite 0.4.2 2023-05-02 [2] CRAN (R 4.1.2) ## vsn 3.62.0 2021-10-26 [2] Bioconductor ## WGCNA * 1.72-1 2023-01-18 [2] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.1.2) ## Wrench 1.12.0 2021-10-26 [2] Bioconductor ## xfun 0.40 2023-08-09 [1] CRAN (R 4.1.3) ## XMAS2 * 2.2.0 2023-10-27 [1] local ## XML 3.99-0.14 2023-03-19 [2] CRAN (R 4.1.2) ## xml2 1.3.5 2023-07-06 [2] CRAN (R 4.1.3) ## xtable 1.8-4 2019-04-21 [2] CRAN (R 4.1.0) ## XVector 0.34.0 2021-10-26 [2] Bioconductor ## yaml 2.3.7 2023-01-23 [2] CRAN (R 4.1.2) ## yulab.utils 0.0.6 2022-12-20 [2] CRAN (R 4.1.2) ## zip 2.3.0 2023-04-17 [2] CRAN (R 4.1.2) ## zlibbioc 1.40.0 2021-10-26 [2] Bioconductor ## zoo 1.8-12 2023-04-13 [2] CRAN (R 4.1.2) ## ## [1] /Users/zouhua/Library/R/x86_64/4.1/library ## [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library ## ## ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── References "],["functional-analysis-1.html", "Chapter 4 Functional Analysis 4.1 Enrichment Analysis 4.2 Pathway Analysis 4.3 Functional Analysis by R package 4.4 Session info", " Chapter 4 Functional Analysis Following two chapters would focus on the Enrichment Analysis and Pathway Analysis of metabolomic data. Enrichment Analysis includes three sections (i.e., ORA, SSP and QEA) and Pathway Analysis only includes ORA and QEA. The main difference between Enrichment Analysis and Pathway Analysis are the data set that input metabolites are enriched to. In Enrichment Analysis, input metabolites are enriched to pre-defined metabolite sets while in Pathway Analysis, metabolites are enriched to pathways in KEGG. Workflow of Enrichment analysis and Pathway analysis is attached below. Users can choose analysis module according to their data type or interest. See more details please go to the below tutorial (MetaboAnalyst website): Functional Analysis Tutorial in MetaboAnalyst website 4.1 Enrichment Analysis In this tutorial, we aim to help you to walk through the enrichment analysis in Metaboanalyst5. This module performs metabolite set enrichment analysis (MSEA) for human and mammalian species based on several libraries containing ~9000 groups of metabolite sets. Users can upload either: 1) a list of compounds 2) a list of compounds with concentrations 3) a concentration table Before carrying out the analysis, you are advised to acquire a list of metabolites in your interest (e.g., Statistical Analysis), then apply them to different modules in this tutorial according to the input file format. Here, we apply SCFA sequencing data of stool samples in GvHD project as demo data. 4.1.1 Enviroment Setup library(MetaboAnalystR) library(tibble) library(readxl) library(magrittr) #library(googledrive) 4.1.2 Over representation analysis (ORA) ORA is used to evaluate whether a particular set of metabolites is represented more than expected by chance within a given compound list. ORA is performed when the user provides only a list of compound names. ## Read input from the SCFA data of GvHD project. SCFA_tbl &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/GvHD_stool_metabolites_SCFA.xlsx&#39;) %&gt;% as.data.frame() metabolite_lst &lt;- SCFA_tbl$Compounds ## Create mSetObj, always initiate your mSet at the beginning. mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;msetora&quot;, FALSE) [1] “MetaboAnalyst R objects initialized …” ## Set up mSetObj with the list of compounds mSet &lt;- Setup.MapData(mSet, metabolite_lst) ## Cross reference list of compounds against libraries (hmdb, pubchem, chebi, kegg, metlin) mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “1” [2] “Name matching OK, please inspect (and manual correct) the results then proceed.” ## Example compound name map mSet$name.map $query.vec [1] “Acetic acid” “Propionic acid” “Isobutyric acid” “Butyric acid” “Isovaleric acid” “Valeric acid” “Hexanoic acid” $hit.inx [1] 29 158 1241 28 566 708 409 $hit.values [1] “Acetic acid” “Propionic acid” “Isobutyric acid” “Butyric acid” “Isovaleric acid” “Valeric acid” “Caproic acid” $match.state [1] 1 1 1 1 1 1 1 ## Create the mapping results table mSet &lt;- CreateMappingResultTable(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ## Set the metabolite filter mSet &lt;- SetMetabolomeFilter(mSet, F) ## Select metabolite set library, we use fecal in this example, you can also choose &quot;kegg_pathway&quot;, &quot;smpdb_pathway&quot;, &quot;blood&quot;, &quot;urine&quot;, &quot;csf&quot;, &quot;snp&quot;, &quot;predicted&quot;, &quot;location&quot;, &quot;drug, etc,. mSet &lt;- SetCurrentMsetLib(mSet, &quot;fecal&quot;, 2) ## Calculate hypergeometric score, results table generated in your working directory mSet &lt;- CalculateHyperScore(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ora_res &lt;- read.csv(&#39;./msea_ora_result.csv&#39;, check.names = FALSE) ## Enrichment Ratio is computed by Hits / Expected, where hits = observed hits expected = expected hits (see the Table below) knitr::kable(head(ora_res)) total expected hits Raw p Holm p FDR Irritable Bowel Syndrome 93 0.5140 7 0e+00 4.0e-07 2.0e-07 Celiac Disease 98 0.5410 7 0e+00 6.0e-07 2.0e-07 Treated Celiac Disease 98 0.5410 7 0e+00 6.0e-07 2.0e-07 Juvenile Idiopathic Arthritis 3 0.0166 3 1e-07 4.1e-06 1.1e-06 Pervasive Developmental Disorder Not Otherwise Specified 82 0.4530 6 4e-07 1.6e-05 3.0e-06 Nonalcoholic Fatty Liver Disease 158 0.8730 7 4e-07 1.6e-05 3.0e-06 ## Plot the ORA, bar-graph mSet &lt;- PlotORA(mSet, &quot;./dataset/OutputFiles/ora_0_&quot;, &quot;bar&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/ora_0_dpi250.png&#39;) ## Plot DotPlot mSet &lt;- PlotEnrichDotPlot(mSet, &quot;ora&quot;, &quot;./dataset/OutputFiles/ora_dot_0_&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/ora_dot_0_dpi250.png&#39;) 4.1.3 Clean environment 1 Remove all variables in env because a new mSet object needs to be created for the following analysis. rm(list = ls()) 4.1.4 Single Sample Profiling For common human biofluids such as blood, urine, or CSF, normal concentration ranges are known for many metabolites. In clinical metabolomic studies, it is often desirable to know whether certain metabolite concentrations in a given sample are significantly higher or lower than their normal ranges. MSEA’s SSP module is designed to provide this kind of analysis. In particular, SSP is performed when the user provides a two-column list of both compounds and concentrations. When called, the SSP module will compare the measured concentration values of each compound to its recorded normal reference ranges of the corresponding biofluid. Input for this module should be a list of metabolites and their concentrations (could be one column (1 x N) from a N * M abundance table with M samples/columns with N metabolites/rows). ## Read input from the SCFA data of GvHD project. SCFA_tbl &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/GvHD_stool_metabolites_SCFA.xlsx&#39;) %&gt;% as.data.frame() ## Initialize mSet object mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;msetssp&quot;, FALSE) [1] “MetaboAnalyst R objects initialized …” ## Read in metabolites names from SCFA_tbl cmpd.vec &lt;- SCFA_tbl$Compounds mSet &lt;- Setup.MapData(mSet, cmpd.vec) ## Read in concentration of sample CJY-V0 from SCFA_tbl conc.vec &lt;- SCFA_tbl$`CJY-V0` mSet &lt;- Setup.ConcData(mSet, conc.vec) ## Set unit of metabolites&#39; concentration mSet &lt;- Setup.BiofluidType(mSet, &quot;urine&quot;) ## Check names mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “1” [2] “Name matching OK, please inspect (and manual correct) the results then proceed.” mSet &lt;- CreateMappingResultTable(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ## Calculate SSP mSet &lt;- CalculateSSP(mSetObj = mSet) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” ## Select all metabolites in our interests and do ORA. mSet &lt;- Setup.MapData(mSet, cmpd.vec) ## Filter mSet &lt;- SetMetabolomeFilter(mSet, F) ## Setup library mSet &lt;- SetCurrentMsetLib(mSet, &quot;smpdb_pathway&quot;, 2) ## Calculate hyperscore mSet &lt;- CalculateHyperScore(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ora_res &lt;- read.csv(&#39;./msea_ora_result.csv&#39;,check.names = FALSE) knitr::kable(head(ora_res)) total expected hits Raw p Holm p FDR Fatty Acid Biosynthesis 35 0.2390 3 0.00117 0.114 0.114 Vitamin K Metabolism 14 0.0957 1 0.09210 1.000 1.000 Beta Oxidation of Very Long Chain Fatty Acids 17 0.1160 1 0.11100 1.000 1.000 Butyrate Metabolism 19 0.1300 1 0.12300 1.000 1.000 Ethanol Degradation 19 0.1300 1 0.12300 1.000 1.000 Mitochondrial Beta-Oxidation of Short Chain Saturated Fatty Acids 27 0.1850 1 0.17100 1.000 1.000 ## Plot mSet &lt;- PlotORA(mSetObj = mSet, imgName = &quot;./dataset/OutputFiles/SSP_ora_0_&quot;, imgOpt = &quot;net&quot;, format = &quot;png&quot;, dpi = 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/SSP_ora_0_dpi250.png&#39;) mSet &lt;- PlotEnrichDotPlot(mSetObj = mSet, enrichType = &quot;ora&quot;, imgName = &quot;./dataset/OutputFiles/SSP_ora_dot_0_&quot;, format = &quot;png&quot;, dpi = 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/SSP_ora_dot_0_dpi250.png&#39;) 4.1.5 Clean environment 2 Remove all variables in env because a new mSet object needs to be created for the following analysis. rm(list = ls()) 4.1.6 Quantitative Enrichment Analysis (QEA) QEA is performed when the user uploads a concentration table containing metabolite concentration data from multiple samples. QEA is based on the globaltest algorithm to perform enrichment analysis directly from raw concentration data and does not require a list of significantly changed compounds. Especially, QEA adopted globaltest as the backend. Please find citation for detailed introduction. In short, globaltest calculates Q values, the formula to calculate Q-statistic can be obtained from the original publication by (Goeman JJ, et al). Q-statistic can be intuitively interpreted as an aggregate of squared covariance between concentration changes and the phenotypes - compounds with large variance have much more influence on the Q than compound with small variance. And the null hypothesis in QEA to be tested are made to be whether two groups of samples are not different with respect to their overall metabolites’ abundance pattern. Under this hypothesis, expectation and standard deviation can be calculated and p value can be estimated. If p &lt; 0.05, it means that two groups of samples are different with respect to their overall metabolites’ abundance pattern. ## Create mSetObj mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;msetqea&quot;, FALSE) Starting Rserve: /Library/Frameworks/R.framework/Resources/bin/R CMD /Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rserve/libs//Rserve –no-save [1] “MetaboAnalyst R objects initialized …” ## Read in data table SCFA_tbl &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/GvHD_stool_metabolites_SCFA.xlsx&#39;) %&gt;% as.data.frame() ## Replace N/A with NA SCFA_tbl[SCFA_tbl == &quot;N/A&quot;] &lt;- NA ## Select columns from input data table SCFA_tbl &lt;- SCFA_tbl[,c(2,5:ncol(SCFA_tbl))] %&gt;% column_to_rownames(&#39;Compounds&#39;) %&gt;% t() %&gt;% as.data.frame() ## Create Group Info SCFA_tbl %&lt;&gt;% dplyr::mutate(Group = c(rep(&#39;A&#39;,25), rep(&#39;B&#39;,31))) %&gt;% dplyr::select(c(&#39;Group&#39;, colnames(.)[colnames(.) != &#39;Group&#39;])) %&gt;% rownames_to_column(&#39;Samples&#39;) ## Write data table in csv file write.csv(SCFA_tbl, &#39;./dataset/OutputFiles/GvHD_stool_metabolites_SCFA.csv&#39;, row.names = FALSE) ## Read in data table mSet &lt;- Read.TextData(mSet, &quot;./dataset/OutputFiles/GvHD_stool_metabolites_SCFA.csv&quot;, &quot;rowu&quot;, &quot;disc&quot;) # Perform cross-referencing of compound names mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “1” [2] “Name matching OK, please inspect (and manual correct) the results then proceed.” # Create mapping results table mSet &lt;- CreateMappingResultTable(mSet) [1] “Loaded files from MetaboAnalyst web-server.” # Mandatory check of data mSet &lt;- SanityCheckData(mSet) [1] “Successfully passed sanity check!” [2] “Samples are not paired.” [3] “2 groups were detected in samples.” [4] “Only English letters, numbers, underscore, hyphen and forward slash (/) are allowed.” [5] “Other special characters or punctuations (if any) will be stripped off.” [6] “All data values are numeric.” [7] “A total of 26 (6.6%) missing values were detected.” [8] “By default, missing values will be replaced by 1/5 of min positive values of their corresponding variables” [9] “Click the Proceed button if you accept the default practice;” [10] “Or click the Missing Values button to use other methods.” # Replace missing values with minimum concentration levels mSet &lt;- ReplaceMin(mSet) # Perform no normalization mSet &lt;- PreparePrenormData(mSet) #mSet &lt;- Normalization(mSet, rowNorm = &quot;SumNorm&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;, ref = &quot;PIF_178&quot;, ratio=FALSE, ratioNum=20) mSet &lt;- Normalization(mSet, rowNorm = &quot;SumNorm&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;) # Plot normalization mSet &lt;- PlotNormSummary(mSet, &quot;./dataset/OutputFiles/norm_0_&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/norm_0_dpi250.png&#39;) # Plot sample-wise normalization mSet &lt;- PlotSampleNormSummary(mSet, &quot;./dataset/OutputFiles/snorm_0_&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/snorm_0_dpi250.png&#39;) # Set the metabolome filter mSet &lt;- SetMetabolomeFilter(mSet, F) # Set the metabolite set library to pathway mSet &lt;- SetCurrentMsetLib(mSet, &quot;smpdb_pathway&quot;, 2) # Calculate the global test score mSet &lt;- CalculateGlobalTestScore(mSet) [1] “Loaded files from MetaboAnalyst web-server.” msea_qea_res &lt;- read.csv(&#39;./msea_qea_result.csv&#39;) knitr::kable(head(msea_qea_res)) X Total.Cmpd Hits Statistic.Q Expected.Q Raw.p Holm.p FDR Propanoate Metabolism 42 1 4.3168 1.8182 0.12440 1 0.62002 Vitamin K Metabolism 14 1 4.3168 1.8182 0.12440 1 0.62002 Butyrate Metabolism 19 1 2.1853 1.8182 0.27692 1 0.62002 Fatty Acid Biosynthesis 35 3 1.7437 1.8182 0.37316 1 0.62002 Beta Oxidation of Very Long Chain Fatty Acids 17 1 1.4123 1.8182 0.38302 1 0.62002 Mitochondrial Beta-Oxidation of Short Chain Saturated Fatty Acids 27 1 1.4123 1.8182 0.38302 1 0.62002 # Plot the QEA mSet &lt;- PlotQEA.Overview(mSet, &quot;./dataset/OutputFiles/qea_0_&quot;, &quot;bar&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/qea_0_dpi250.png&#39;) mSet &lt;- PlotEnrichDotPlot(mSet, &quot;qea&quot;, &quot;./dataset/OutputFiles/qea_dot_0_&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/qea_dot_0_dpi250.png&#39;) Remove all variables in env because a new mSet object needs to be created for the following analysis. rm(list = ls()) 4.2 Pathway Analysis In this tutorial, we aim to help you to walk through the pathway analysis in Metaboanalyst5. This module supports pathway analysis (integrating enrichment analysis and pathway topology analysis) and visualization for 26 model organisms, including Human, Mouse, Rat, Cow, Chicken, Zebrafish, Arabidopsis thaliana, Rice, Drosophila, Malaria, S. cerevisae, E.coli, and others species. Here, we apply TM metabolites sequencing data of stool samples in GvHD project as demo data. Moreover, to reduce data noise, we selected differentially abundant metabolites in aGVHD patients from the differential analysis result in Xu XiaoMin’s analysis. 4.2.1 Enviroment Set up 4.2.2 Over representation analysis Similar to ORA in Enrichment analysis. ## Read in differentially abundant TM metanolites data from GVHD project DA_metabolites &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/DA_metabolites_agvhd_adult_result.xlsx&#39;) %&gt;% as.data.frame() ## Create vector consisting of compounds for enrichment analysis tmp.vec &lt;- DA_metabolites$Compounds ## Create mSetObj for storing objects created during your analysis mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;pathora&quot;, FALSE) [1] “MetaboAnalyst R objects initialized …” ## Set up mSetObj with the list of compounds mSet &lt;- Setup.MapData(mSet, tmp.vec) ## Cross reference list of compounds against libraries (hmdb, pubchem, chebi, kegg, metlin). This step is to make sure that all metabolites names provided match the metabolites&#39; names in KEGG database. mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “0” [2] “Over half of the compound IDs could not be matched to our database. Please make sure that correct compound IDs or common compound names are used.” ## Remove metabolites failed to match the metabolites&#39; names in KEGG database. tmp.vec &lt;- tmp.vec[mSet$name.map$match.state == 1] ## Re-initialize mSet object mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;pathora&quot;, FALSE) ## Set up mSetObj with the matched list of compounds mSet &lt;- Setup.MapData(mSet, tmp.vec) ## Cross reference list of compounds against libraries (hmdb, pubchem, chebi, kegg, metlin). Check again if all metabolites&#39; names have their matches in KEGG database mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “1” [2] “Name matching OK, please inspect (and manual correct) the results then proceed.” ## Creates a mapping result table shows HMDB, KEGG, PubChem, etc. IDs. Saved as &quot;name_map.csv&quot; or can be found in mSet$dataSet$map.table. Compounds with no hits will contain NAs across the columns. mSet &lt;- CreateMappingResultTable(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ## Select the pathway library, ranging from mammals to prokaryotes ## Note the third parameter, where users need to input the KEGG pathway version. ## Use &quot;current&quot; for the latest KEGG pathway library or &quot;v2018&quot; for the KEGG pathway library version prior to November 2019. mSet &lt;- SetKEGG.PathLib(mSet, &quot;hsa&quot;, &quot;current&quot;) ## Set the metabolite filter. Default set to false mSet &lt;- SetMetabolomeFilter(mSet, F) ## Calculate the over representation analysis score, here we selected to use the hypergeometric test (alternative is Fisher&#39;s exact test) ## A results table &quot;pathway_results.csv&quot; will be created and found within your working directory # mSet &lt;- CalculateOraScore(mSet, &quot;rbc&quot;, &quot;hyperg&quot;) # # pathway_res &lt;- read.csv(&#39;./pathway_results.csv&#39;) # # knitr::kable(head(pathway_res)) # # # Plot of the Pathway Analysis Overview # mSet &lt;- PlotPathSummary(mSet,show.grid=FALSE, &quot;./dataset/OutputFiles/path_view_0_&quot;, &quot;png&quot;, dpi =250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/path_view_0_dpi250.png&#39;) # Plot a specific metabolic pathway, in this case &quot;Glycine, serine and threonine metabolism&quot; # mSet &lt;- PlotKEGGPath(mSetObj = mSet, pathName = &quot;Glycine, serine and threonine metabolism&quot;, 528, 480, &quot;png&quot;, dpi=72) 4.2.3 Clean environment 3 rm(list = ls()) 4.2.4 Concentration Table (QEA) Similar to QEA in Enrichment analysis. KO enrichment is calculated via the global test algorithm when abundance of metabolites are provided. Global test evaluates whether a set of genes (i.e. KEGG pathways) is significantly associated with a variable of interest. Compared to ORA, which uses only the total number of KO hits in a pathway, global test considers the gene abundance values and is considered to be more sensitive than ORA. It assumes that if a gene set can be used to predict an outcome of interest, the gene expression patterns per outcome must be different. The global test algorithm is implemented in MicrobiomeAnalyst using the globaltest R package. P-values for both methods are corrected for multiple-testing using the Benjamini and Hochberg’s False-Discovery Rate (FDR). In this module, we use differentially abundant metabolites in aGVHD patients from the differential analysis result in Xu XiaoMin’s analysis and their abundance as input. ## Read in differentially abundant TM metanolites data from GVHD project DA_metabolites &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/DA_metabolites_agvhd_adult_result.xlsx&#39;) %&gt;% as.data.frame() ## Initialize data object mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;pathqea&quot;, FALSE) Starting Rserve: /Library/Frameworks/R.framework/Resources/bin/R CMD /Library/Frameworks/R.framework/Versions/4.1/Resources/library/Rserve/libs//Rserve –no-save [1] “MetaboAnalyst R objects initialized …” ## Read in data table input_df &lt;- readxl::read_xlsx(&#39;./dataset/InputFiles/GvHD_stool_metabolites_TM.xlsx&#39;) %&gt;% as.data.frame() %&gt;% .[,c(2,25:ncol(.))] %&gt;% column_to_rownames(&#39;Compounds&#39;) %&gt;% .[DA_metabolites$Compounds,] %&gt;% t() %&gt;% as.data.frame() Groupinfo &lt;- rownames(input_df) %&gt;% stringr::str_split(&#39;-&#39;) %&gt;% as.data.frame() %&gt;% .[2,] %&gt;% unlist() %&gt;% as.vector() input_df %&lt;&gt;% dplyr::mutate(Group = Groupinfo) %&gt;% dplyr::select(c(&#39;Group&#39;, colnames(.)[colnames(.) != &#39;Group&#39;])) %&gt;% rownames_to_column(&#39;Sample&#39;) ## Write reformed metabolites abundance table into csv file write.csv(input_df, &#39;./dataset/OutputFiles/GvHD_stool_metabolites_TM.csv&#39;,row.names = FALSE) mSet &lt;- Read.TextData(mSet, &#39;./dataset/OutputFiles/GvHD_stool_metabolites_TM.csv&#39;, &quot;rowu&quot;, &quot;disc&quot;) ## Show first few rows in data table knitr::kable(head(input_df)) Sample Group Erucic acid 5-Methylcytosine D-Gluconic Acid LPE(14:0/0:0) N-Acetylglucosamine 1-Phosphate 7-ketodeoxycholic acid Bis(1-inositol) -3,1’-phosphate 1-phosphate Asp-phe Phenylacetyl-L-Glutamine N-Acetylglycine Carnitine C2:0 Acetylcholine Lithocholic acid 3-Carboxypropyltrimethylammonium Biotinamide 5’-deoxy-5’-fluoroadenosine Carnitine C5:1 Val-Val Gly Leu Tyr Ile-Thr Isoleucyl-Serine Isoleucyl-Tyrosine Phe Val Ala Phosphonic acid, P-[(3R)-3-amino-4-[(3-hexylphenyl)amino]-4-oxobutyl]- 2-[2,4-dihydroxy-3-(3-methylbut-2-en-1-yl)phenyl]-1-[2,4,6-trihydroxy-3-(3-methylbut-2-en-1-yl)phenyl]propan-1-one Asp Ile Ile Gly Leu Val Ile Glu Leu Ile Ile Asn Lys Pro Ile Phylloquinone oxide Thr Val Met Val Leu Thr (2R,3S,4R,5R)-2,3,4,5,6-pentahydroxyhexanoate TZW-V0 V0 1629500 630750 11598000 1900000 1048900 142580.0 4516900 1896000 483960 75306000 35820000 169220 30462 169220 72050 52622 48756 6690500 382840 151620 863010 3696700 371890 419900 376300 1992200 304420 321110 243390 17617 3885 1950000 582200 208490000 LBC-V0 V0 17057 220290 8239500 68958 9880900 6446.1 313960 19488000 569570 11310000 81713000 90812 9 90812 533990 9 338900 1044600 9 99102 468170 7789300 46193 88988 14154 463070 10903 32430 29187 12902000 9 333220 210680 166450000 HXZ-V0 V0 3719000 316360 91189 14390000 37784000 21965000.0 459320 5671200 8502200 6758300 71495000 518950 438800 518950 1222000 36295 953350 8538900 88531 454250 952750 56697 45953 115110 2798900 348560 79613 134400 438750 7569200 24432 747830 86317 2163600 LJY-V0 V0 1641600 285270 72194 7366800 9557700 3289400.0 71782 756830 30602 531930 387590 1345400 6488400 1345400 544550 27188 295820 3163500 136380 180510 819430 21168 171330 159850 1478200 804870 128420 910850 379890 78433 459240 576110 123100 1502600 CJY-V0 V0 9 45013 25589 882500 561320 1603.1 9 7463500 556470 5814900 13723000 26319 9 26319 182350 18175 135980 1555700 38015 130400 441760 3275600 235320 154660 169880 568150 35916 48067 215340 328930 9 763870 97575 900440 WKM-V0 V0 3079600 228130 396980 8410000 12296000 7266400.0 42405 13785000 4553400 9620400 1311800 4392400 9 4392400 74831 79472 48558 5309200 88741 221440 593130 44678 250550 140720 1660200 522490 234090 263740 415690 9312900 586940 619550 136990 8894600 ## Check metabolites Names of input table. Found &gt;15 compounds without matches. mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “0” [2] “Over half of the compound IDs could not be matched to our database. Please make sure that correct compound IDs or common compound names are used.” ## Keep matched metabolites metabolites_keep &lt;- mSet$name.map$query.vec[mSet$name.map$match.state == 1] input_df &lt;- input_df[c(&#39;Sample&#39;,&#39;Group&#39;, metabolites_keep)] ## Overwrite previously generated abundance csv file with matched metabolites write.csv(input_df, &#39;./dataset/OutputFiles/GvHD_stool_metabolites_TM.csv&#39;,row.names = FALSE) ## Initialize data object again mSet &lt;- InitDataObjects(&quot;conc&quot;, &quot;pathqea&quot;, FALSE) ## Read in updated metabolites abundance table mSet &lt;- Read.TextData(mSet, &#39;./dataset/OutputFiles/GvHD_stool_metabolites_TM.csv&#39;, &quot;rowu&quot;, &quot;disc&quot;) ## Check Sanity and replace 0 mSet &lt;- SanityCheckData(mSet) [1] “Successfully passed sanity check!” [2] “Samples are not paired.” [3] “2 groups were detected in samples.” [4] “Only English letters, numbers, underscore, hyphen and forward slash (/) are allowed.” [5] “Other special characters or punctuations (if any) will be stripped off.” [6] “All data values are numeric.” [7] “A total of 0 (0%) missing values were detected.” [8] “By default, missing values will be replaced by 1/5 of min positive values of their corresponding variables” [9] “Click the Proceed button if you accept the default practice;” [10] “Or click the Missing Values button to use other methods.” mSet &lt;- ReplaceMin(mSet) ## Check metabolites Names of input table again mSet &lt;- CrossReferencing(mSet, &quot;name&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “Loaded files from MetaboAnalyst web-server.” [1] “1” [2] “Name matching OK, please inspect (and manual correct) the results then proceed.” ## Creates a mapping result table shows HMDB, KEGG, PubChem, etc. IDs. Saved as &quot;name_map.csv&quot; or can be found in mSet$dataSet$map.table. Compounds with no hits will contain NAs across the columns. mSet &lt;- CreateMappingResultTable(mSet) [1] “Loaded files from MetaboAnalyst web-server.” ## Normalize mSet &lt;- PreparePrenormData(mSet) mSet &lt;- Normalization(mSet, rowNorm = &quot;SumNorm&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;) mSet &lt;- PlotNormSummary(mSet, imgName = &quot;./dataset/OutputFiles/kegg_pathnorm_0_&quot;, format = &quot;png&quot;, dpi = 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/kegg_pathnorm_0_dpi250.png&#39;) mSet &lt;- PlotSampleNormSummary(mSet, &quot;./dataset/OutputFiles/kegg_pathsnorm_0_&quot;, &quot;png&quot;, 250, width=NA) knitr::include_graphics(&#39;./dataset/OutputFiles/kegg_pathsnorm_0_dpi250.png&#39;) ## Enrich to KEGG mSet &lt;- SetKEGG.PathLib(mSet, &quot;hsa&quot;, &quot;current&quot;) mSet &lt;- SetMetabolomeFilter(mSet, F) mSet &lt;- CalculateQeaScore(mSet, &quot;rbc&quot;, &quot;gt&quot;) [1] “Loaded files from MetaboAnalyst web-server.” [1] “http://api.xialab.ca/pathwayqea” [1] “Failed to connect to Xia Lab API Server!” # pathway_res &lt;- read.csv(&#39;./pathway_results.csv&#39;, check.names = FALSE) # knitr::kable(head(pathway_res)) # mSet &lt;- PlotPathSummary(mSet, F, &quot;./dataset/OutputFiles/kegg_path_view_0_&quot;, &quot;png&quot;, 250, width=NA, NA, NA ) knitr::include_graphics(&#39;./dataset/OutputFiles/kegg_path_view_0_dpi250.png&#39;) ## Plot specified pathway map # mSet &lt;- PlotKEGGPath(mSet, &quot;Phenylalanine, tyrosine and tryptophan biosynthesis&quot;,576, 480, &quot;png&quot;, NULL) # mSet &lt;- RerenderMetPAGraph(mSet, &quot;zoom1658398230135.png&quot;,576.0, 480.0, 100.0) # mSet &lt;- PlotKEGGPath(mSet, &quot;Glycine, serine and threonine metabolism&quot;,576, 480, &quot;png&quot;, NULL) 4.3 Functional Analysis by R package Functional Analysis for DE metabolites ORA: Over Representive Analysis GSEA: Gene Set Enrichment Analysis 4.3.1 Loading R packages library(dplyr) library(tibble) library(ggplot2) library(clusterProfiler) library(org.Mm.eg.db) library(readxl) library(ropls) library(Biobase) library(SummarizedExperiment) library(massdatabase) library(MicrobiomeProfiler) 4.3.2 Importing Data ExprSet &lt;- readRDS(&quot;./dataset/POMA/ExprSet_raw.RDS&quot;) se_impute &lt;- readRDS(&quot;./dataset/POMA/se_impute.RDS&quot;) se_norm &lt;- readRDS(&quot;./dataset/POMA/se_normalize.RDS&quot;) 4.3.3 Differential Analysis Fold change (group1 vs group2) RawData VIP (Variable influence on projection &amp; coefficient) Variable influence on projection (VIP) for orthogonal projections to latent structures (OPLS) Variable influence on projection (VIP) for projections to latent structures (PLS) T-test significant differences between two groups (p value) Merging result Foldchange by Raw Data VIP by Normalized Data test Pvalue by Normalized Data FoldChange &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } fc_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) mn &lt;- tapply(dat$value, dat$group, function(x){ mean(x, na.rm = TRUE) }) %&gt;% as.data.frame() %&gt;% stats::setNames(&quot;value&quot;) %&gt;% tibble::rownames_to_column(&quot;Group&quot;) mn1 &lt;- with(mn, mn[Group %in% group_names[1], &quot;value&quot;]) mn2 &lt;- with(mn, mn[Group %in% group_names[2], &quot;value&quot;]) mnall &lt;- mean(dat$value, na.rm = TRUE) if (all(mn1 != 0, mn2 != 0)) { fc &lt;- mn1 / mn2 } else { fc &lt;- NA } logfc &lt;- log2(fc) res &lt;- c(fc, logfc, mnall, mn1, mn2) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(fc_res) &lt;- c(&quot;FeatureID&quot;, &quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;Mean Abundance\\n(All)&quot;, paste0(&quot;Mean Abundance\\n&quot;, c(&quot;former&quot;, &quot;latter&quot;))) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) fc_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- fc_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } VIP_fun &lt;- function( x, group, group_names, VIPtype = c(&quot;OPLS&quot;, &quot;PLS&quot;), vip_cutoff = 1) { metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } dataMatrix &lt;- prof %&gt;% base::t() # row-&gt;sampleID; col-&gt;features sampleMetadata &lt;- phen # row-&gt;sampleID; col-&gt;features comparsionVn &lt;- sampleMetadata[, &quot;CompVar&quot;] # corrlation between group and features pvaVn &lt;- apply(dataMatrix, 2, function(feaVn) cor.test(as.numeric(comparsionVn), feaVn)[[&quot;p.value&quot;]]) if (VIPtype == &quot;OPLS&quot;) { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, orthoI = NA, fig.pdfC = &quot;none&quot;)) } else { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, fig.pdfC = &quot;none&quot;)) } quantVn &lt;- qnorm(1 - pvaVn / 2) rmsQuantN &lt;- sqrt(mean(quantVn^2)) opar &lt;- par(font = 2, font.axis = 2, font.lab = 2, las = 1, mar = c(5.1, 4.6, 4.1, 2.1), lwd = 2, pch = 16) plot(pvaVn, vipVn, col = &quot;red&quot;, pch = 16, xlab = &quot;p-value&quot;, ylab = &quot;VIP&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;) box(lwd = 2) curve(qnorm(1 - x / 2) / rmsQuantN, 0, 1, add = TRUE, col = &quot;red&quot;, lwd = 3) abline(h = 1, col = &quot;blue&quot;) abline(v = 0.05, col = &quot;blue&quot;) res_temp &lt;- data.frame( FeatureID = names(vipVn), VIP = vipVn, CorPvalue = pvaVn) %&gt;% dplyr::arrange(desc(VIP)) vip_select &lt;- res_temp %&gt;% dplyr::filter(VIP &gt; vip_cutoff) pl &lt;- ggplot(vip_select, aes(FeatureID, VIP)) + geom_segment(aes(x = FeatureID, xend = FeatureID, y = 0, yend = VIP)) + geom_point(shape = 21, size = 5, color = &#39;#008000&#39; ,fill = &#39;#008000&#39;) + geom_point(aes(1,2.5), color = &#39;white&#39;) + geom_hline(yintercept = 1, linetype = &#39;dashed&#39;) + scale_y_continuous(expand = c(0, 0)) + labs(x = &#39;&#39;, y = &#39;VIP value&#39;) + theme_bw() + theme(legend.position = &#39;none&#39;, legend.text = element_text(color = &#39;black&#39;,size = 12, family = &#39;Arial&#39;, face = &#39;plain&#39;), panel.background = element_blank(), panel.grid = element_blank(), axis.text = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.text.x = element_text(angle = 90), axis.title = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.ticks = element_line(color = &#39;black&#39;), axis.ticks.x = element_blank()) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) res_temp$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res_df &lt;- res_temp %&gt;% dplyr::select(FeatureID, Block, everything()) res &lt;- list(vip = res_df, plot = pl) return(res) } t_fun &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() # rename variables colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } t_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) rest &lt;- t.test(data = dat, value ~ group) res &lt;- c(rest$statistic, rest$p.value) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(t_res) &lt;- c(&quot;FeatureID&quot;, &quot;Statistic&quot;, &quot;Pvalue&quot;) t_res$AdjustedPvalue &lt;- p.adjust(as.numeric(t_res$Pvalue), method = &quot;BH&quot;) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) t_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- t_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } mergedResults &lt;- function( fc_result, vip_result, test_result, group_names, group_labels) { if (is.null(vip_result)) { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } else { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(vip_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, VIP, CorPvalue, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } return(res) } fc_res &lt;- FoldChange( x = se_impute, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Moderate&quot;)) vip_res &lt;- VIP_fun( x = se_norm, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), VIPtype = &quot;PLS&quot;, vip_cutoff = 1) ## PLS-DA ## 26 samples x 167 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.12 0.692 0.33 0.288 1 0 0.1 0.05 ttest_res &lt;- t_fun( x = se_norm, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;)) m_results &lt;- mergedResults( fc_result = fc_res, vip_result = vip_res$vip, test_result = ttest_res, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;)) head(m_results) ## FeatureID Block2 Block FoldChange Log2FoldChange VIP CorPvalue Statistic Pvalue AdjustedPvalue ## 1 M_42449 Mild vs Severe 14_Mild vs 19_Moderate 0.6571801 -0.6056393 2.362694 0.002247897 -3.498896 0.001881585 0.2132448 ## 2 M_52446 Mild vs Severe 14_Mild vs 19_Moderate 0.7040861 -0.5061763 2.059461 0.009476225 -2.892892 0.008125613 0.2132448 ## 3 M_1566 Mild vs Severe 14_Mild vs 19_Moderate 0.7161609 -0.4816443 2.143655 0.006556886 -3.077688 0.005431005 0.2132448 ## 4 M_19263 Mild vs Severe 14_Mild vs 19_Moderate 0.7165011 -0.4809592 2.128317 0.007023483 -3.073546 0.005774977 0.2132448 ## 5 M_42448 Mild vs Severe 14_Mild vs 19_Moderate 0.7577644 -0.4001788 2.006246 0.011828403 -2.793941 0.010215320 0.2132448 ## 6 M_43761 Mild vs Severe 14_Mild vs 19_Moderate 0.8685495 -0.2033201 2.043515 0.010136007 -2.822338 0.009428795 0.2132448 4.3.4 Metabolites ID for Merged Results HMDBID KEGG ID: cpd_ID get_metaboID &lt;- function( x = ExprSet, dat, group_names, index_names = c(&quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;VIP&quot;, &quot;CorPvalue&quot;, &quot;Pvalue&quot;, &quot;AdjustedPvalue&quot;), index_cutoff = c(1, 1, 1, 0.05, 0.05, 0.2)) { # x = ExprSet # dat = m_results # group_names = &quot;Mild vs Severe&quot; # index_names = c(&quot;Log2FoldChange&quot;, &quot;AdjustedPvalue&quot;) # index_cutoff = c(0, 1) feature &lt;- Biobase::fData(x) colnames(feature)[which(colnames(feature) == &quot;SampleID HMDBID&quot;)] &lt;- &quot;HMDB&quot; colnames(feature)[which(colnames(feature) == &quot;KEGG&quot;)] &lt;- &quot;cpd_ID&quot; colnames(feature)[which(colnames(feature) == &quot;BIOCHEMICAL&quot;)] &lt;- &quot;Compounds&quot; feature$HMDB &lt;- gsub(&quot;,\\\\S+&quot;, &quot;&quot;, feature$HMDB) temp_dat &lt;- dat %&gt;% dplyr::filter(Block2 %in% group_names) %&gt;% dplyr::inner_join(feature %&gt;% tibble::rownames_to_column(&quot;FeatureID&quot;), by = &quot;FeatureID&quot;) colnames(temp_dat)[which(colnames(temp_dat) == index_names[1])] &lt;- &quot;DA_index1&quot; colnames(temp_dat)[which(colnames(temp_dat) == index_names[2])] &lt;- &quot;DA_index2&quot; temp_dat_diff &lt;- temp_dat %&gt;% dplyr::filter(abs(DA_index1) &gt; index_cutoff[1]) %&gt;% dplyr::filter(DA_index2 &lt; index_cutoff[2]) if (nrow(temp_dat_diff) == 0) { stop(&quot;Beyond these thresholds, no significant metabolites were selected&quot;) } colnames(temp_dat_diff)[which(colnames(temp_dat_diff) == &quot;DA_index1&quot;)] &lt;- index_names[1] colnames(temp_dat_diff)[which(colnames(temp_dat_diff) == &quot;DA_index2&quot;)] &lt;- index_names[2] res &lt;- temp_dat_diff return(res) } m_results_ID &lt;- get_metaboID( x = ExprSet, dat = m_results, group_names = &quot;Mild vs Severe&quot;, index_names = c(&quot;Log2FoldChange&quot;, &quot;AdjustedPvalue&quot;), index_cutoff = c(0, 1)) head(m_results_ID) ## FeatureID Block2 Block FoldChange Log2FoldChange VIP CorPvalue Statistic Pvalue AdjustedPvalue ## 1 M_42449 Mild vs Severe 14_Mild vs 19_Moderate 0.6571801 -0.6056393 2.362694 0.002247897 -3.498896 0.001881585 0.2132448 ## 2 M_52446 Mild vs Severe 14_Mild vs 19_Moderate 0.7040861 -0.5061763 2.059461 0.009476225 -2.892892 0.008125613 0.2132448 ## 3 M_1566 Mild vs Severe 14_Mild vs 19_Moderate 0.7161609 -0.4816443 2.143655 0.006556886 -3.077688 0.005431005 0.2132448 ## 4 M_19263 Mild vs Severe 14_Mild vs 19_Moderate 0.7165011 -0.4809592 2.128317 0.007023483 -3.073546 0.005774977 0.2132448 ## 5 M_42448 Mild vs Severe 14_Mild vs 19_Moderate 0.7577644 -0.4001788 2.006246 0.011828403 -2.793941 0.010215320 0.2132448 ## 6 M_43761 Mild vs Severe 14_Mild vs 19_Moderate 0.8685495 -0.2033201 2.043515 0.010136007 -2.822338 0.009428795 0.2132448 ## Compounds SUPER PATHWAY SUB PATHWAY COMP ID PLATFORM CHEMICAL ID RI ## 1 1-palmitoyl-2-linoleoyl-GPE (16:0/18:2) Lipid Phosphatidylethanolamine (PE) 42449 LC/MS Pos Late 100001870 2350 ## 2 1-stearoyl-2-linoleoyl-GPE (18:0/18:2)* Lipid Phosphatidylethanolamine (PE) 52446 LC/MS Pos Late 100008976 2575 ## 3 3-aminoisobutyrate Nucleotide Pyrimidine Metabolism, Thymine containing 1566 LC/MS Pos Early 1114 2190 ## 4 1-palmitoyl-2-oleoyl-GPE (16:0/18:1) Lipid Phosphatidylethanolamine (PE) 19263 LC/MS Pos Late 1526 2600 ## 5 1-stearoyl-2-oleoyl-GPE (18:0/18:1) Lipid Phosphatidylethanolamine (PE) 42448 LC/MS Pos Late 100001856 2950 ## 6 2-aminoheptanoate Lipid Fatty Acid, Amino 43761 LC/MS Pos Early 100004542 3160 ## MASS PUBCHEM CAS cpd_ID HMDB ## 1 716.5225 9546747 &lt;NA&gt; &lt;NA&gt; HMDB0005322 ## 2 744.5538 9546749 &lt;NA&gt; &lt;NA&gt; HMDB0008994 ## 3 104.0706 64956 10569-72-9;214139-20-5 C05145 HMDB0002166 ## 4 718.5381 5283496 26662-94-2 &lt;NA&gt; HMDB0005320 ## 5 746.5694 9546742 &lt;NA&gt; &lt;NA&gt; HMDB0008993 ## 6 146.1176 227939 1115-90-8 &lt;NA&gt; HMDB0094649 4.3.5 KEGG PATHWAY COMPOUND KEGG pathway ID：request_kegg_pathway_info KEGG pathway compound: request_kegg_pathway data.frame with all pathway contained compounds id: 1st-&gt;pathwayID &amp; 2nd-&gt;compoundID get_kegg_pathway_compound &lt;- function( org_id = c(&quot;hsa&quot;, &quot;mmu&quot;)) { pathway_names &lt;- request_kegg_pathway_info(organism = org_id) res &lt;- data.frame() for (i in 1:nrow(pathway_names)) { # i = 12 temp_pathway &lt;- request_kegg_pathway(pathway_id = pathway_names$KEGG.ID[i]) temp_colnames &lt;- names(temp_pathway) if (all(c(&quot;COMPOUND&quot;, &quot;ENTRY&quot;, &quot;NAME&quot;, &quot;CLASS&quot;, &quot;PATHWAY_MAP&quot;) %in% temp_colnames)) { print(i) temp_compound &lt;- temp_pathway$COMPOUND temp_class &lt;- unlist(strsplit(temp_pathway$CLASS, &quot;; &quot;)) temp_df1 &lt;- data.frame(Pathway = temp_pathway$ENTRY, NAME = temp_pathway$NAME, #DESCRIPTION = temp_pathway$DESCRIPTION, CLASS1 = temp_class[1], CLASS2 = temp_class[2], PATHWAY_MAP = temp_pathway$PATHWAY_MAP) temp_df2 &lt;- data.frame(Pathway = rep(temp_pathway$ENTRY, length(temp_compound)), COMPOUND = names(temp_compound), COMPOUND_DESCRIPTION = temp_compound) temp_df &lt;- temp_df1 %&gt;% dplyr::full_join(temp_df2, by = &quot;Pathway&quot;) res &lt;- rbind(res, temp_df) } } return(res) } if (!dir.exists(&quot;./dataset/KEGG_COMPOUND_PATHWAY/&quot;)) { dir.create(&quot;./dataset/KEGG_COMPOUND_PATHWAY/&quot;, recursive = TRUE) } if (file.exists(&quot;./dataset/KEGG_COMPOUND_PATHWAY/KEGG_COMPOUND_PATHWAY_mmu.csv&quot;)) { kegg_compound &lt;- read.csv(&quot;./dataset/KEGG_COMPOUND_PATHWAY/KEGG_COMPOUND_PATHWAY_mmu.csv&quot;) } else { kegg_compound &lt;- get_kegg_pathway_compound(org_id = &quot;mmu&quot;) write.csv(kegg_compound, &quot;./dataset/KEGG_COMPOUND_PATHWAY/KEGG_COMPOUND_PATHWAY_mmu.csv&quot;, row.names = F) } 4.3.6 Functions related to Analysis significant metabolites enrichment analysis plotting results get_significant &lt;- function( dat, group_names, lg2fc_cutoff = 0.5, pval_cutoff = 0.05, qval_cutoff = 0.3) { dat_group &lt;- dat %&gt;% dplyr::filter(Block2 %in% paste(group_names, collapse = &quot; vs &quot;)) %&gt;% dplyr::distinct() # remove cp_id eq &quot;-&quot; dat_fa &lt;- dat_group %&gt;% dplyr::filter(cpd_ID != &quot;-&quot;) colnames(dat_fa)[which(colnames(dat_fa) == &quot;Log2FoldChange&quot;)] &lt;- &quot;lg2fc&quot; # Log2FoldChange (Median) colnames(dat_fa)[which(colnames(dat_fa) == &quot;Pvalue&quot;)] &lt;- &quot;pval&quot; colnames(dat_fa)[which(colnames(dat_fa) == &quot;AdjustedPvalue&quot;)] &lt;- &quot;qval&quot; # convert NA into 1 dat_fa$qval[is.na(dat_fa$qval)] &lt;- 1 # enrichment by beta and Pvalue AdjustedPvalue dat_fa[which(dat_fa$lg2fc &gt; lg2fc_cutoff &amp; dat_fa$pval &lt; pval_cutoff &amp; dat_fa$qval &lt; qval_cutoff), &quot;EnrichedDir&quot;] &lt;- group_names[1] dat_fa[which(dat_fa$lg2fc &lt; -lg2fc_cutoff &amp; dat_fa$pval &lt; pval_cutoff &amp; dat_fa$qval &lt; qval_cutoff), &quot;EnrichedDir&quot;] &lt;- group_names[2] dat_fa[which(abs(dat_fa$lg2fc) &lt;= lg2fc_cutoff | dat_fa$pval &gt;= pval_cutoff | dat_fa$qval &gt;= qval_cutoff), &quot;EnrichedDir&quot;] &lt;- &quot;Nonsignif&quot; # dat status dat_fa$EnrichedDir &lt;- factor(dat_fa$EnrichedDir, levels = c(group_names[1], &quot;Nonsignif&quot;, group_names[2])) df_status &lt;- table(dat_fa$EnrichedDir) %&gt;% data.frame() %&gt;% stats::setNames(c(&quot;Group&quot;, &quot;Number&quot;)) grp1_number &lt;- with(df_status, df_status[Group %in% group_names[1], &quot;Number&quot;]) grp2_number &lt;- with(df_status, df_status[Group %in% group_names[2], &quot;Number&quot;]) nsf_number &lt;- with(df_status, df_status[Group %in% &quot;Nonsignif&quot;, &quot;Number&quot;]) legend_label &lt;- c(paste0(group_names[1], &quot; (&quot;, grp1_number, &quot;)&quot;), paste0(&quot;Nonsignif&quot;, &quot; (&quot;, nsf_number, &quot;)&quot;), paste0(group_names[2], &quot; (&quot;, grp2_number, &quot;)&quot;)) # significant features dat_signif &lt;- dat_fa %&gt;% dplyr::arrange(lg2fc, pval, qval) %&gt;% dplyr::filter(pval &lt; pval_cutoff) %&gt;% dplyr::filter(qval &lt; qval_cutoff) %&gt;% dplyr::filter(abs(lg2fc) &gt; lg2fc_cutoff) %&gt;% dplyr::select(FeatureID, Block, EnrichedDir, lg2fc, pval, qval, cpd_ID, everything()) %&gt;% dplyr::mutate(FeatureID = gsub(&quot;\\\\.&quot;, &quot;-&quot;, FeatureID)) # print(table(dat_signif$EnrichedDir)) res_up &lt;- dat_signif %&gt;% # enriched in 1st group dplyr::filter(EnrichedDir == group_names[1]) %&gt;% dplyr::mutate(Status = &quot;UpRegulated&quot;) res_down &lt;- dat_signif %&gt;% # enriched in 2st group dplyr::filter(EnrichedDir == group_names[2]) %&gt;% dplyr::mutate(Status = &quot;DownRegulated&quot;) res &lt;- list(none = dat_fa %&gt;% dplyr::select(FeatureID, Block, EnrichedDir, lg2fc, pval, qval, cpd_ID, everything()), all = dat_signif, up = res_up, down = res_down) return(res) } get_enrichment &lt;- function( dat, ref = kegg_compound, direction = c(&quot;All&quot;, &quot;DownRegulated&quot;, &quot;UpRegulated&quot;), # DownRegulated-&gt;1st group; UpRegulated-&gt;2nd group group_names, enrich_type = c(&quot;ORA&quot;, &quot;GSEA&quot;), lg2fc_cutoff = 0.5, pval_cutoff = 0.05, qval_cutoff = 0.3) { # dat = m_results_ID # ref = kegg_compound # direction = &quot;none&quot; # group_names = c(&quot;Mild&quot;, &quot;Severe&quot;) # enrich_type = &quot;GSEA&quot; # lg2fc_cutoff = 0 # pval_cutoff = 1 # qval_cutoff = 1 temp_input &lt;- get_significant( dat = dat, group_names = group_names, lg2fc_cutoff = lg2fc_cutoff, pval_cutoff = pval_cutoff, qval_cutoff = qval_cutoff) if (direction == &quot;All&quot;) { inputdata &lt;- temp_input$all } else if (direction == &quot;UpRegulated&quot;) { inputdata &lt;- temp_input$up } else if (direction == &quot;DownRegulated&quot;) { inputdata &lt;- temp_input$down } else if (direction == &quot;none&quot;) { inputdata &lt;- temp_input$none } if (nrow(inputdata) == 0) { stop(&quot;Beyond these thresholds, no significant metabolites were selected&quot;) } inputdata$cpd_ID &lt;- gsub(&quot;\\\\s+\\\\|\\\\s+\\\\w+\\\\d+&quot;, &quot;&quot;, inputdata$cpd_ID) inputdata$cpd_ID &lt;- gsub(&quot;,\\\\S+&quot;, &quot;&quot;, inputdata$cpd_ID) ref_cln &lt;- ref %&gt;% dplyr::select(PATHWAY_MAP, COMPOUND) %&gt;% dplyr::rename(Pathway = PATHWAY_MAP) if (enrich_type == &quot;ORA&quot;) { fit &lt;- clusterProfiler::enricher( gene = inputdata$cpd_ID, pvalueCutoff = 0.05, pAdjustMethod = &quot;BH&quot;, minGSSize = 10, maxGSSize = 500, qvalueCutoff = 0.2, TERM2GENE = ref_cln) } else if (enrich_type == &quot;GSEA&quot;) { dat_GSEA &lt;- inputdata %&gt;% dplyr::arrange(desc(lg2fc)) cpd_lg2fc &lt;- dat_GSEA$lg2fc names(cpd_lg2fc) &lt;- dat_GSEA$cpd_ID fit &lt;- clusterProfiler::GSEA( geneList = cpd_lg2fc, pvalueCutoff = 0.05, pAdjustMethod = &quot;BH&quot;, minGSSize = 10, maxGSSize = 500, TERM2GENE = ref_cln) } if (nrow(fit@result) != 0) { if (enrich_type == &quot;ORA&quot;) { EA_res &lt;- fit@result %&gt;% dplyr::filter(!is.na(Description)) %&gt;% dplyr::rename(CompoundRatio = GeneRatio, CompoundID = geneID, NAME = Description) %&gt;% dplyr::select(ID, NAME, everything()) } else if (enrich_type == &quot;GSEA&quot;) { EA_res &lt;- fit@result %&gt;% dplyr::filter(!is.na(Description)) %&gt;% dplyr::rename(NAME = Description) %&gt;% dplyr::select(ID, NAME, everything()) } } else { EA_res &lt;- NULL } res &lt;- list(data = inputdata, enrich = EA_res) return(res) } plot_enrichment &lt;- function( inputdata, qval_cutoff = 0.05, topN = 10, plot_type = c(&quot;bubble&quot;, &quot;bar&quot;), enrich_type = c(&quot;ORA&quot;, &quot;GSEA&quot;)) { if (nrow(inputdata) == 0) { stop(&quot;No pathway please check your input&quot;) } if (enrich_type == &quot;ORA&quot;) { if (any(is.na(inputdata$qvalue))) { inputdata$qvalue &lt;- inputdata$p.adjust } plotdata_temp &lt;- inputdata %&gt;% dplyr::select(ID, NAME, CompoundRatio, qvalue, Count) %&gt;% dplyr::filter(qvalue &lt; qval_cutoff) if (nrow(plotdata_temp) == 0) { stop(&quot;No pathway met the threshold of qvalue&quot;) } plotdata &lt;- plotdata_temp %&gt;% dplyr::slice(1:topN) %&gt;% dplyr::mutate(qvalue = as.numeric(qvalue), Count = as.numeric(Count)) %&gt;% dplyr::group_by(ID) %&gt;% dplyr::mutate(CompoundRatio1 = unlist(strsplit(CompoundRatio, &quot;/&quot;))[1], CompoundRatio2 = unlist(strsplit(CompoundRatio, &quot;/&quot;))[2], CompoundRatio = as.numeric(CompoundRatio1) / as.numeric(CompoundRatio2)) %&gt;% dplyr::select(-all_of(c(&quot;CompoundRatio1&quot;, &quot;CompoundRatio2&quot;))) %&gt;% dplyr::mutate(NAME = gsub(&quot; - Mus musculus \\\\(house mouse\\\\)&quot;, &quot;&quot;, NAME)) %&gt;% dplyr::arrange(CompoundRatio) %&gt;% dplyr::rename(Yvalue = CompoundRatio) y_lab &lt;- &quot;CompoundRatio&quot; } else if (enrich_type == &quot;GSEA&quot;) { if (any(is.na(inputdata$qvalue))) { inputdata$qvalues &lt;- inputdata$p.adjust } plotdata_temp &lt;- inputdata %&gt;% dplyr::select(ID, NAME, enrichmentScore, qvalues, setSize) %&gt;% dplyr::filter(qvalues &lt; qval_cutoff) if (nrow(plotdata_temp) == 0) { stop(&quot;No pathway met the threshold of qvalue&quot;) } plotdata &lt;- plotdata_temp %&gt;% dplyr::slice(1:topN) %&gt;% dplyr::rename(qvalue = qvalues, Count = setSize) %&gt;% dplyr::mutate(qvalue = as.numeric(qvalue), Count = as.numeric(Count), enrichmentScore = as.numeric(enrichmentScore)) %&gt;% dplyr::mutate(NAME = gsub(&quot; - Mus musculus \\\\(house mouse\\\\)&quot;, &quot;&quot;, NAME)) %&gt;% dplyr::arrange(enrichmentScore) %&gt;% dplyr::rename(Yvalue = enrichmentScore) y_lab &lt;- &quot;enrichmentScore&quot; } plotdata$NAME &lt;- factor(plotdata$NAME, levels = as.character(plotdata$NAME)) final_topN &lt;- nrow(plotdata) if (plot_type == &quot;bubble&quot;) { pl &lt;- ggplot(plotdata, aes(x = NAME, y = Yvalue)) + geom_point(aes(size = Count, color = qvalue)) + coord_flip() + labs(x = &quot;&quot;, y = y_lab, title = paste(&quot;Top&quot;, final_topN, &quot;of Enrichment&quot;)) + theme_bw() + guides(size = guide_legend(order = 1), color = guide_legend(order = 2))+ scale_color_gradientn(name = &quot;q value&quot;, colours = rainbow(5)) + theme(plot.title = element_text(face = &#39;bold&#39;, size = 12, hjust = .5), axis.title = element_text(face = &#39;bold&#39;, size = 11), axis.text.y = element_text(face = &#39;bold&#39;, size = 10), legend.position = &quot;right&quot;) } else if (plot_type == &quot;bar&quot;) { pl &lt;- ggplot(plotdata, aes(x = NAME, y = Yvalue, fill = -log(qvalue))) + geom_bar(stat = &quot;identity&quot;, position = position_dodge()) + coord_flip() + labs(x = &quot;&quot;, y = y_lab, title = paste(&quot;Top&quot;, final_topN, &quot;of Enrichment&quot;)) + theme_bw() + guides(fill = guide_legend(order = 1))+ scale_color_gradientn(name = &quot;-log10(q value)&quot;, colours = rainbow(5)) + theme(plot.title = element_text(face = &#39;bold&#39;, size = 12, hjust = .5), axis.title = element_text(face = &#39;bold&#39;, size = 11), axis.text.y = element_text(face = &#39;bold&#39;, size = 10), legend.position = &quot;right&quot;) } return(pl) } 4.3.6.1 ORA ORA: Enriched KEGG pathway for Down-Regulated Metabolites Mild_Severe_ORA_Down &lt;- get_enrichment( dat = m_results_ID, direction = &quot;DownRegulated&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), enrich_type = &quot;ORA&quot;, lg2fc_cutoff = 0, pval_cutoff = 0.5, qval_cutoff = 1) plot_enrichment( inputdata = Mild_Severe_ORA_Down$enrich, qval_cutoff = 0.5, topN = 10, plot_type = &quot;bubble&quot;, enrich_type = &quot;ORA&quot;) head(Mild_Severe_ORA_Down$enrich) ## ID NAME CompoundRatio ## Retrograde endocannabinoid signaling Retrograde endocannabinoid signaling Retrograde endocannabinoid signaling 1/5 ## Thermogenesis Thermogenesis Thermogenesis 1/5 ## Pentose phosphate pathway Pentose phosphate pathway Pentose phosphate pathway 1/5 ## Histidine metabolism Histidine metabolism Histidine metabolism 1/5 ## Phenylalanine metabolism Phenylalanine metabolism Phenylalanine metabolism 1/5 ## Neuroactive ligand-receptor interaction Neuroactive ligand-receptor interaction Neuroactive ligand-receptor interaction 1/5 ## BgRatio pvalue p.adjust qvalue CompoundID Count ## Retrograde endocannabinoid signaling 19/3516 0.02674395 0.08982828 0.07354362 C13856 1 ## Thermogenesis 23/3516 0.03230064 0.08982828 0.07354362 C13856 1 ## Pentose phosphate pathway 36/3516 0.05018484 0.08982828 0.07354362 C00204 1 ## Histidine metabolism 47/3516 0.06511021 0.08982828 0.07354362 C01152 1 ## Phenylalanine metabolism 49/3516 0.06780364 0.08982828 0.07354362 C05852 1 ## Neuroactive ligand-receptor interaction 53/3516 0.07317187 0.08982828 0.07354362 C13856 1 4.3.6.2 GSEA GSEA: Enriched KEGG pathway for all Metabolites whose rank by log2foldchange Mild_Severe_GSEA &lt;- get_enrichment( dat = m_results_ID, direction = &quot;none&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), enrich_type = &quot;GSEA&quot;, lg2fc_cutoff = 0, pval_cutoff = 0.5, qval_cutoff = 1) # plot_enrichment( # inputdata = Mild_Severe_GSEA$enrich, # qval_cutoff = 0.5, # topN = 10, # plot_type = &quot;bubble&quot;, # enrich_type = &quot;GSEA&quot;) # # head(Mild_Severe_GSEA$enrich) 4.4 Session info devtools::session_info() ## ─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os macOS Monterey 12.2.1 ## system x86_64, darwin17.0 ## ui RStudio ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Asia/Shanghai ## date 2023-11-27 ## rstudio 2023.09.0+463 Desert Sunflower (desktop) ## pandoc 3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [2] CRAN (R 4.1.0) ## ade4 1.7-22 2023-02-06 [2] CRAN (R 4.1.2) ## affy 1.72.0 2021-10-26 [2] Bioconductor ## affyio 1.64.0 2021-10-26 [2] Bioconductor ## annotate 1.72.0 2021-10-26 [2] Bioconductor ## AnnotationDbi * 1.60.2 2023-03-10 [2] Bioconductor ## ape 5.7-1 2023-03-13 [2] CRAN (R 4.1.2) ## aplot 0.1.10 2023-03-08 [2] CRAN (R 4.1.2) ## attempt 0.3.1 2020-05-03 [2] CRAN (R 4.1.0) ## backports 1.4.1 2021-12-13 [2] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [2] CRAN (R 4.1.0) ## Biobase * 2.54.0 2021-10-26 [2] Bioconductor ## BiocGenerics * 0.40.0 2021-10-26 [2] Bioconductor ## BiocManager 1.30.21 2023-06-10 [2] CRAN (R 4.1.3) ## BiocParallel 1.28.3 2021-12-09 [2] Bioconductor ## biomformat 1.22.0 2021-10-26 [2] Bioconductor ## Biostrings 2.62.0 2021-10-26 [2] Bioconductor ## bit 4.0.5 2022-11-15 [2] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [2] CRAN (R 4.1.0) ## bitops 1.0-7 2021-04-24 [2] CRAN (R 4.1.0) ## blob 1.2.4 2023-03-17 [2] CRAN (R 4.1.2) ## bookdown 0.34 2023-05-09 [2] CRAN (R 4.1.2) ## broom 1.0.5 2023-06-09 [2] CRAN (R 4.1.3) ## bslib 0.6.0 2023-11-21 [1] CRAN (R 4.1.3) ## cachem 1.0.8 2023-05-01 [2] CRAN (R 4.1.2) ## Cairo 1.6-0 2022-07-05 [2] CRAN (R 4.1.2) ## callr 3.7.3 2022-11-02 [2] CRAN (R 4.1.2) ## car 3.1-2 2023-03-30 [2] CRAN (R 4.1.2) ## carData 3.0-5 2022-01-06 [2] CRAN (R 4.1.2) ## caret 6.0-94 2023-03-21 [2] CRAN (R 4.1.2) ## caTools 1.18.2 2021-03-28 [2] CRAN (R 4.1.0) ## cellranger 1.1.0 2016-07-27 [2] CRAN (R 4.1.0) ## checkmate 2.2.0 2023-04-27 [2] CRAN (R 4.1.2) ## circlize 0.4.15 2022-05-10 [2] CRAN (R 4.1.2) ## class 7.3-22 2023-05-03 [2] CRAN (R 4.1.2) ## cli 3.6.1 2023-03-23 [2] CRAN (R 4.1.2) ## clue 0.3-64 2023-01-31 [2] CRAN (R 4.1.2) ## cluster * 2.1.4 2022-08-22 [2] CRAN (R 4.1.2) ## clusterProfiler * 4.2.2 2022-01-13 [2] Bioconductor ## codetools 0.2-19 2023-02-01 [2] CRAN (R 4.1.2) ## coin 1.4-2 2021-10-08 [2] CRAN (R 4.1.0) ## colorspace 2.1-0 2023-01-23 [2] CRAN (R 4.1.2) ## ComplexHeatmap 2.10.0 2021-10-26 [2] Bioconductor ## config 0.3.1 2020-12-17 [2] CRAN (R 4.1.0) ## corpcor 1.6.10 2021-09-16 [2] CRAN (R 4.1.0) ## cowplot 1.1.1 2020-12-30 [2] CRAN (R 4.1.0) ## crayon 1.5.2 2022-09-29 [2] CRAN (R 4.1.2) ## crmn 0.0.21 2020-02-10 [2] CRAN (R 4.1.0) ## curl 5.0.1 2023-06-07 [2] CRAN (R 4.1.3) ## data.table 1.14.8 2023-02-17 [2] CRAN (R 4.1.2) ## DBI 1.1.3 2022-06-18 [2] CRAN (R 4.1.2) ## DelayedArray 0.20.0 2021-10-26 [2] Bioconductor ## dendextend * 1.17.1 2023-03-25 [2] CRAN (R 4.1.2) ## DESeq2 1.34.0 2021-10-26 [2] Bioconductor ## devtools 2.4.5 2022-10-11 [2] CRAN (R 4.1.2) ## digest 0.6.33 2023-07-07 [1] CRAN (R 4.1.3) ## DO.db 2.9 2022-04-11 [2] Bioconductor ## doParallel 1.0.17 2022-02-07 [2] CRAN (R 4.1.2) ## doRNG 1.8.6 2023-01-16 [2] CRAN (R 4.1.2) ## DOSE 3.20.1 2021-11-18 [2] Bioconductor ## doSNOW 1.0.20 2022-02-04 [2] CRAN (R 4.1.2) ## downloader 0.4 2015-07-09 [2] CRAN (R 4.1.0) ## dplyr * 1.1.2 2023-04-20 [2] CRAN (R 4.1.2) ## DT 0.28 2023-05-18 [2] CRAN (R 4.1.3) ## dynamicTreeCut * 1.63-1 2016-03-11 [2] CRAN (R 4.1.0) ## e1071 1.7-13 2023-02-01 [2] CRAN (R 4.1.2) ## edgeR 3.36.0 2021-10-26 [2] Bioconductor ## ellipse 0.4.5 2023-04-05 [2] CRAN (R 4.1.2) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.1.0) ## enrichplot 1.14.2 2022-02-24 [2] Bioconductor ## evaluate 0.21 2023-05-05 [2] CRAN (R 4.1.2) ## factoextra * 1.0.7 2020-04-01 [2] CRAN (R 4.1.0) ## fansi 1.0.4 2023-01-22 [2] CRAN (R 4.1.2) ## farver 2.1.1 2022-07-06 [2] CRAN (R 4.1.2) ## fastcluster * 1.2.3 2021-05-24 [2] CRAN (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] CRAN (R 4.1.2) ## fastmatch 1.1-3 2021-07-23 [2] CRAN (R 4.1.0) ## fdrtool 1.2.17 2021-11-13 [2] CRAN (R 4.1.0) ## fgsea 1.20.0 2021-10-26 [2] Bioconductor ## filematrix 1.3 2018-02-27 [2] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [2] CRAN (R 4.1.2) ## foreign 0.8-84 2022-12-06 [2] CRAN (R 4.1.2) ## forestplot 3.1.1 2022-12-06 [2] CRAN (R 4.1.2) ## Formula 1.2-5 2023-02-24 [2] CRAN (R 4.1.2) ## fs 1.6.2 2023-04-25 [2] CRAN (R 4.1.2) ## furrr 0.3.1 2022-08-15 [2] CRAN (R 4.1.2) ## future 1.33.0 2023-07-01 [2] CRAN (R 4.1.3) ## future.apply 1.11.0 2023-05-21 [2] CRAN (R 4.1.3) ## genefilter 1.76.0 2021-10-26 [2] Bioconductor ## geneplotter 1.72.0 2021-10-26 [2] Bioconductor ## generics 0.1.3 2022-07-05 [2] CRAN (R 4.1.2) ## GenomeInfoDb * 1.30.1 2022-01-30 [2] Bioconductor ## GenomeInfoDbData 1.2.7 2022-03-09 [2] Bioconductor ## GenomicRanges * 1.46.1 2021-11-18 [2] Bioconductor ## GetoptLong 1.0.5 2020-12-15 [2] CRAN (R 4.1.0) ## ggforce 0.4.1 2022-10-04 [2] CRAN (R 4.1.2) ## ggfun 0.1.1 2023-06-24 [2] CRAN (R 4.1.3) ## ggplot2 * 3.4.2 2023-04-03 [2] CRAN (R 4.1.2) ## ggplotify 0.1.1 2023-06-27 [2] CRAN (R 4.1.3) ## ggpubr 0.6.0 2023-02-10 [2] CRAN (R 4.1.2) ## ggraph * 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71) ## ggrepel 0.9.3 2023-02-03 [2] CRAN (R 4.1.2) ## ggsignif 0.6.4 2022-10-13 [2] CRAN (R 4.1.2) ## ggtree 3.2.1 2021-11-16 [2] Bioconductor ## glasso 1.11 2019-10-01 [2] CRAN (R 4.1.0) ## glmnet * 4.1-7 2023-03-23 [2] CRAN (R 4.1.2) ## GlobalOptions 0.1.2 2020-06-10 [2] CRAN (R 4.1.0) ## globals 0.16.2 2022-11-21 [2] CRAN (R 4.1.2) ## globaltest 5.48.0 2021-10-26 [2] Bioconductor ## glue * 1.6.2 2022-02-24 [2] CRAN (R 4.1.2) ## Gmisc * 3.0.2 2023-03-13 [2] CRAN (R 4.1.2) ## gmm 1.8 2023-06-06 [2] CRAN (R 4.1.3) ## gmp 0.7-1 2023-02-07 [2] CRAN (R 4.1.2) ## GO.db 3.14.0 2022-04-11 [2] Bioconductor ## golem 0.4.1 2023-06-05 [2] CRAN (R 4.1.3) ## GOSemSim 2.20.0 2021-10-26 [2] Bioconductor ## gower 1.0.1 2022-12-22 [2] CRAN (R 4.1.2) ## gplots 3.1.3 2022-04-25 [2] CRAN (R 4.1.2) ## graphlayouts 1.0.0 2023-05-01 [2] CRAN (R 4.1.2) ## gridExtra 2.3 2017-09-09 [2] CRAN (R 4.1.0) ## gridGraphics 0.5-1 2020-12-13 [2] CRAN (R 4.1.0) ## gtable 0.3.3 2023-03-21 [2] CRAN (R 4.1.2) ## gtools 3.9.4 2022-11-27 [2] CRAN (R 4.1.2) ## hardhat 1.3.0 2023-03-30 [2] CRAN (R 4.1.2) ## highr 0.10 2022-12-22 [2] CRAN (R 4.1.2) ## Hmisc 5.1-0 2023-05-08 [2] CRAN (R 4.1.2) ## hms 1.1.3 2023-03-21 [2] CRAN (R 4.1.2) ## htmlTable * 2.4.1 2022-07-07 [2] CRAN (R 4.1.2) ## htmltools 0.5.7 2023-11-03 [1] CRAN (R 4.1.3) ## htmlwidgets 1.6.2 2023-03-17 [2] CRAN (R 4.1.2) ## httpuv 1.6.11 2023-05-11 [2] CRAN (R 4.1.3) ## httr * 1.4.6 2023-05-08 [2] CRAN (R 4.1.2) ## huge 1.3.5 2021-06-30 [2] CRAN (R 4.1.0) ## igraph * 1.5.0 2023-06-16 [1] CRAN (R 4.1.3) ## impute 1.68.0 2021-10-26 [2] Bioconductor ## imputeLCMD 2.1 2022-06-10 [2] CRAN (R 4.1.2) ## ipred 0.9-14 2023-03-09 [2] CRAN (R 4.1.2) ## IRanges * 2.28.0 2021-10-26 [2] Bioconductor ## irlba 2.3.5.1 2022-10-03 [2] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [2] CRAN (R 4.1.2) ## itertools 0.1-3 2014-03-12 [2] CRAN (R 4.1.0) ## jpeg 0.1-10 2022-11-29 [2] CRAN (R 4.1.2) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.0) ## jsonlite 1.8.7 2023-06-29 [2] CRAN (R 4.1.3) ## KEGGREST 1.34.0 2021-10-26 [2] Bioconductor ## KernSmooth 2.23-22 2023-07-10 [2] CRAN (R 4.1.3) ## knitr 1.43 2023-05-25 [2] CRAN (R 4.1.3) ## labeling 0.4.2 2020-10-20 [2] CRAN (R 4.1.0) ## later 1.3.1 2023-05-02 [2] CRAN (R 4.1.2) ## lattice 0.21-8 2023-04-05 [2] CRAN (R 4.1.2) ## lava 1.7.2.1 2023-02-27 [2] CRAN (R 4.1.2) ## lavaan 0.6-15 2023-03-14 [2] CRAN (R 4.1.2) ## lazyeval 0.2.2 2019-03-15 [2] CRAN (R 4.1.0) ## libcoin 1.0-9 2021-09-27 [2] CRAN (R 4.1.0) ## lifecycle 1.0.3 2022-10-07 [2] CRAN (R 4.1.2) ## limma 3.50.3 2022-04-07 [2] Bioconductor ## listenv 0.9.0 2022-12-16 [2] CRAN (R 4.1.2) ## locfit 1.5-9.8 2023-06-11 [2] CRAN (R 4.1.3) ## lubridate 1.9.2 2023-02-10 [2] CRAN (R 4.1.2) ## magrittr * 2.0.3 2022-03-30 [2] CRAN (R 4.1.2) ## MALDIquant 1.22.1 2023-03-20 [2] CRAN (R 4.1.2) ## MASS 7.3-60 2023-05-04 [2] CRAN (R 4.1.2) ## massdatabase * 1.0.7 2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93) ## massdataset * 1.0.24 2023-05-30 [2] gitlab (jaspershen/massdataset@b397116) ## masstools * 1.0.10 2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc) ## Matrix * 1.6-0 2023-07-08 [2] CRAN (R 4.1.3) ## MatrixGenerics * 1.6.0 2021-10-26 [2] Bioconductor ## matrixStats * 1.0.0 2023-06-02 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.1.0) ## MetaboAnalystR * 3.2.0 2022-06-28 [2] Github (xia-lab/MetaboAnalystR@892a31b) ## metagenomeSeq 1.36.0 2021-10-26 [2] Bioconductor ## metid * 1.2.26 2023-05-30 [2] gitlab (jaspershen/metid@6bde121) ## metpath * 1.0.5 2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f) ## mgcv 1.8-42 2023-03-02 [2] CRAN (R 4.1.2) ## MicrobiomeProfiler * 1.0.0 2021-10-26 [2] Bioconductor ## mime 0.12 2021-09-28 [2] CRAN (R 4.1.0) ## miniUI 0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0) ## missForest 1.5 2022-04-14 [2] CRAN (R 4.1.2) ## mixedCCA 1.6.2 2022-09-09 [2] CRAN (R 4.1.2) ## mixOmics 6.18.1 2021-11-18 [2] Bioconductor (R 4.1.2) ## mnormt 2.1.1 2022-09-26 [2] CRAN (R 4.1.2) ## ModelMetrics 1.2.2.2 2020-03-17 [2] CRAN (R 4.1.0) ## modeltools 0.2-23 2020-03-05 [2] CRAN (R 4.1.0) ## MsCoreUtils 1.6.2 2022-02-24 [2] Bioconductor ## MSnbase * 2.20.4 2022-01-16 [2] Bioconductor ## multcomp 1.4-25 2023-06-20 [2] CRAN (R 4.1.3) ## multtest 2.50.0 2021-10-26 [2] Bioconductor ## munsell 0.5.0 2018-06-12 [2] CRAN (R 4.1.0) ## mvtnorm 1.2-2 2023-06-08 [2] CRAN (R 4.1.3) ## mzID 1.32.0 2021-10-26 [2] Bioconductor ## mzR * 2.28.0 2021-10-27 [2] Bioconductor ## ncdf4 1.21 2023-01-07 [2] CRAN (R 4.1.2) ## NetCoMi * 1.0.3 2022-07-14 [2] Github (stefpeschel/NetCoMi@d4d80d3) ## nlme 3.1-162 2023-01-31 [2] CRAN (R 4.1.2) ## nnet 7.3-19 2023-05-03 [2] CRAN (R 4.1.2) ## norm 1.0-11.1 2023-06-18 [2] CRAN (R 4.1.3) ## openxlsx 4.2.5.2 2023-02-06 [2] CRAN (R 4.1.2) ## org.Mm.eg.db * 3.14.0 2022-11-23 [2] Bioconductor ## parallelly 1.36.0 2023-05-26 [2] CRAN (R 4.1.3) ## patchwork 1.1.2 2022-08-19 [2] CRAN (R 4.1.2) ## pbapply 1.7-2 2023-06-27 [2] CRAN (R 4.1.3) ## pbivnorm 0.6.0 2015-01-23 [2] CRAN (R 4.1.0) ## pcaMethods 1.86.0 2021-10-26 [2] Bioconductor ## pcaPP 2.0-3 2022-10-24 [2] CRAN (R 4.1.2) ## permute 0.9-7 2022-01-27 [2] CRAN (R 4.1.2) ## pheatmap 1.0.12 2019-01-04 [2] CRAN (R 4.1.0) ## phyloseq 1.38.0 2021-10-26 [2] Bioconductor ## pillar 1.9.0 2023-03-22 [2] CRAN (R 4.1.2) ## pkgbuild 1.4.2 2023-06-26 [2] CRAN (R 4.1.3) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.1.0) ## pkgload 1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3) ## plotly * 4.10.2 2023-06-03 [2] CRAN (R 4.1.3) ## plyr 1.8.8 2022-11-11 [2] CRAN (R 4.1.2) ## png 0.1-8 2022-11-29 [2] CRAN (R 4.1.2) ## polyclip 1.10-4 2022-10-20 [2] CRAN (R 4.1.2) ## POMA * 1.7.2 2022-07-26 [2] Github (pcastellanoescuder/POMA@bc8a972) ## preprocessCore 1.56.0 2021-10-26 [2] Bioconductor ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.1.0) ## pROC 1.18.4 2023-07-06 [2] CRAN (R 4.1.3) ## processx 3.8.2 2023-06-30 [2] CRAN (R 4.1.3) ## prodlim 2023.03.31 2023-04-02 [2] CRAN (R 4.1.2) ## profvis 0.3.8 2023-05-02 [2] CRAN (R 4.1.2) ## progress 1.2.2 2019-05-16 [2] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0) ## ProtGenerics * 1.26.0 2021-10-26 [2] Bioconductor ## proxy 0.4-27 2022-06-09 [2] CRAN (R 4.1.2) ## ps 1.7.5 2023-04-18 [2] CRAN (R 4.1.2) ## psych 2.3.6 2023-06-21 [2] CRAN (R 4.1.3) ## pulsar 0.3.10 2023-01-26 [2] CRAN (R 4.1.2) ## purrr 1.0.1 2023-01-10 [2] CRAN (R 4.1.2) ## qgraph 1.9.5 2023-05-16 [2] CRAN (R 4.1.3) ## qs 0.25.5 2023-02-22 [2] CRAN (R 4.1.2) ## quadprog 1.5-8 2019-11-20 [2] CRAN (R 4.1.0) ## qvalue 2.26.0 2021-10-26 [2] Bioconductor ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.1.0) ## ragg 1.2.5 2023-01-12 [2] CRAN (R 4.1.2) ## randomForest 4.7-1.1 2022-05-23 [2] CRAN (R 4.1.2) ## RankProd 3.20.0 2021-10-26 [2] Bioconductor ## RApiSerialize 0.1.2 2022-08-25 [2] CRAN (R 4.1.2) ## rARPACK 0.11-0 2016-03-10 [2] CRAN (R 4.1.0) ## rbibutils 2.2.13 2023-01-13 [2] CRAN (R 4.1.2) ## RColorBrewer 1.1-3 2022-04-03 [2] CRAN (R 4.1.2) ## Rcpp * 1.0.11 2023-07-06 [1] CRAN (R 4.1.3) ## RcppParallel 5.1.7 2023-02-27 [2] CRAN (R 4.1.2) ## RCurl 1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2) ## Rdisop 1.54.0 2021-10-26 [2] Bioconductor ## Rdpack 2.4 2022-07-20 [2] CRAN (R 4.1.2) ## readr 2.1.4 2023-02-10 [2] CRAN (R 4.1.2) ## readxl * 1.4.3 2023-07-06 [2] CRAN (R 4.1.3) ## recipes 1.0.6 2023-04-25 [2] CRAN (R 4.1.2) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.1.0) ## reshape2 1.4.4 2020-04-09 [2] CRAN (R 4.1.0) ## rhdf5 2.38.1 2022-03-10 [2] Bioconductor ## rhdf5filters 1.6.0 2021-10-26 [2] Bioconductor ## Rhdf5lib 1.16.0 2021-10-26 [2] Bioconductor ## rjson 0.2.21 2022-01-09 [2] CRAN (R 4.1.2) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.1.2) ## rmarkdown 2.23 2023-07-01 [2] CRAN (R 4.1.3) ## Rmpfr 0.9-2 2023-04-22 [2] CRAN (R 4.1.2) ## rngtools 1.5.2 2021-09-20 [2] CRAN (R 4.1.0) ## rootSolve 1.8.2.3 2021-09-29 [2] CRAN (R 4.1.0) ## ropls * 1.26.4 2022-01-11 [2] Bioconductor ## rpart 4.1.19 2022-10-21 [2] CRAN (R 4.1.2) ## Rserve * 1.8-11 2022-11-28 [2] CRAN (R 4.1.2) ## RSpectra 0.16-1 2022-04-24 [2] CRAN (R 4.1.2) ## RSQLite 2.3.1 2023-04-03 [2] CRAN (R 4.1.2) ## rstatix 0.7.2 2023-02-01 [2] CRAN (R 4.1.2) ## rstudioapi 0.15.0 2023-07-07 [2] CRAN (R 4.1.3) ## rvest 1.0.3 2022-08-19 [2] CRAN (R 4.1.2) ## S4Vectors * 0.32.4 2022-03-29 [2] Bioconductor ## sandwich 3.0-2 2022-06-15 [2] CRAN (R 4.1.2) ## sass 0.4.6 2023-05-03 [2] CRAN (R 4.1.2) ## scales 1.2.1 2022-08-20 [2] CRAN (R 4.1.2) ## scatterpie 0.2.1 2023-06-07 [2] CRAN (R 4.1.3) ## scrime 1.3.5 2018-12-01 [2] CRAN (R 4.1.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.1.0) ## shadowtext 0.1.2 2022-04-22 [2] CRAN (R 4.1.2) ## shape 1.4.6 2021-05-19 [2] CRAN (R 4.1.0) ## shiny 1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3) ## shinycustomloader 0.9.0 2018-03-27 [2] CRAN (R 4.1.0) ## shinyWidgets 0.7.6 2023-01-08 [2] CRAN (R 4.1.2) ## siggenes 1.68.0 2021-10-26 [2] Bioconductor ## snow 0.4-4 2021-10-27 [2] CRAN (R 4.1.0) ## SpiecEasi * 1.1.2 2022-07-14 [2] Github (zdk123/SpiecEasi@c463727) ## SPRING * 1.0.4 2022-08-03 [2] Github (GraceYoon/SPRING@3d641a4) ## stringdist 0.9.10 2022-11-07 [2] CRAN (R 4.1.2) ## stringfish 0.15.8 2023-05-30 [2] CRAN (R 4.1.3) ## stringi 1.7.12 2023-01-11 [2] CRAN (R 4.1.2) ## stringr 1.5.0 2022-12-02 [2] CRAN (R 4.1.2) ## SummarizedExperiment * 1.24.0 2021-10-26 [2] Bioconductor ## survival 3.5-5 2023-03-12 [2] CRAN (R 4.1.2) ## systemfonts 1.0.4 2022-02-11 [2] CRAN (R 4.1.2) ## textshaping 0.3.6 2021-10-13 [2] CRAN (R 4.1.0) ## TH.data 1.1-2 2023-04-17 [2] CRAN (R 4.1.2) ## tibble * 3.2.1 2023-03-20 [2] CRAN (R 4.1.2) ## tidygraph 1.2.3 2023-02-01 [2] CRAN (R 4.1.2) ## tidyr 1.3.0 2023-01-24 [2] CRAN (R 4.1.2) ## tidyselect 1.2.0 2022-10-10 [2] CRAN (R 4.1.2) ## tidytree 0.4.2 2022-12-18 [2] CRAN (R 4.1.2) ## timechange 0.2.0 2023-01-11 [2] CRAN (R 4.1.2) ## timeDate 4022.108 2023-01-07 [2] CRAN (R 4.1.2) ## tmvtnorm 1.5 2022-03-22 [2] CRAN (R 4.1.2) ## treeio 1.18.1 2021-11-14 [2] Bioconductor ## tweenr 2.0.2 2022-09-06 [2] CRAN (R 4.1.2) ## tzdb 0.4.0 2023-05-12 [2] CRAN (R 4.1.3) ## urlchecker 1.0.1 2021-11-30 [2] CRAN (R 4.1.0) ## usethis 2.2.2 2023-07-06 [2] CRAN (R 4.1.3) ## utf8 1.2.3 2023-01-31 [2] CRAN (R 4.1.2) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.1.3) ## vegan 2.6-4 2022-10-11 [2] CRAN (R 4.1.2) ## VGAM 1.1-8 2023-03-09 [2] CRAN (R 4.1.2) ## viridis 0.6.3 2023-05-03 [2] CRAN (R 4.1.2) ## viridisLite 0.4.2 2023-05-02 [2] CRAN (R 4.1.2) ## vsn 3.62.0 2021-10-26 [2] Bioconductor ## WGCNA * 1.72-1 2023-01-18 [2] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.1.2) ## Wrench 1.12.0 2021-10-26 [2] Bioconductor ## xfun 0.40 2023-08-09 [1] CRAN (R 4.1.3) ## XMAS2 * 2.2.0 2023-10-27 [1] local ## XML 3.99-0.14 2023-03-19 [2] CRAN (R 4.1.2) ## xml2 1.3.5 2023-07-06 [2] CRAN (R 4.1.3) ## xtable 1.8-4 2019-04-21 [2] CRAN (R 4.1.0) ## XVector 0.34.0 2021-10-26 [2] Bioconductor ## yaml 2.3.7 2023-01-23 [2] CRAN (R 4.1.2) ## yulab.utils 0.0.6 2022-12-20 [2] CRAN (R 4.1.2) ## zip 2.3.0 2023-04-17 [2] CRAN (R 4.1.2) ## zlibbioc 1.40.0 2021-10-26 [2] Bioconductor ## zoo 1.8-12 2023-04-13 [2] CRAN (R 4.1.2) ## ## [1] /Users/zouhua/Library/R/x86_64/4.1/library ## [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library ## ## ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── "],["metorigin-analysis.html", "Chapter 5 MetOrigin Analysis 5.1 Loading packages 5.2 Importing data 5.3 Differential Analysis 5.4 DE metabolites 5.5 Obtain inputs for Metorigin 5.6 Save result 5.7 MetOrigin User Tutorial 5.8 Session info", " Chapter 5 MetOrigin Analysis Microbiome and its metabolites are closely associated with human health and diseases. However, it is challenging to understand the complex interplay between microbiome and metabolites. MetOrigin is a bioinformatics tool, aiming to identify which bacteria and how they participate in certain metabolic reactions, helping us to understand where metabolites come from: host, bacteria, or both? The tutorial was from https://metorigin.met-bioinformatics.cn/home/. Here, we gave example for how to prepare inputs to MetOrigin website. 5.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(Biobase) library(POMA) library(ggplot2) library(ropls) library(SummarizedExperiment) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 5.2 Importing data The dataset is from the Zeybel-2022 published paper (Zeybel et al. 2022). ExprSet &lt;- readRDS(&quot;./dataset/POMA/ExprSet_raw.RDS&quot;) se_impute &lt;- readRDS(&quot;./dataset/POMA/se_impute.RDS&quot;) se_norm &lt;- readRDS(&quot;./dataset/POMA/se_normalize.RDS&quot;) 5.3 Differential Analysis Fold change (group1 vs group2) RawData VIP (Variable influence on projection &amp; coefficient) Variable influence on projection (VIP) for orthogonal projections to latent structures (OPLS) Variable influence on projection (VIP) for projections to latent structures (PLS) T-test significant differences between two groups (p value) Merging result Foldchange by Raw Data VIP by Normalized Data test Pvalue by Normalized Data FoldChange &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } fc_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) mn &lt;- tapply(dat$value, dat$group, function(x){ mean(x, na.rm = TRUE) }) %&gt;% as.data.frame() %&gt;% stats::setNames(&quot;value&quot;) %&gt;% tibble::rownames_to_column(&quot;Group&quot;) mn1 &lt;- with(mn, mn[Group %in% group_names[1], &quot;value&quot;]) mn2 &lt;- with(mn, mn[Group %in% group_names[2], &quot;value&quot;]) mnall &lt;- mean(dat$value, na.rm = TRUE) if (all(mn1 != 0, mn2 != 0)) { fc &lt;- mn1 / mn2 } else { fc &lt;- NA } logfc &lt;- log2(fc) res &lt;- c(fc, logfc, mnall, mn1, mn2) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(fc_res) &lt;- c(&quot;FeatureID&quot;, &quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;Mean Abundance\\n(All)&quot;, paste0(&quot;Mean Abundance\\n&quot;, c(&quot;former&quot;, &quot;latter&quot;))) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) fc_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- fc_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } VIP_fun &lt;- function( x, group, group_names, VIPtype = c(&quot;OPLS&quot;, &quot;PLS&quot;), vip_cutoff = 1) { metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } dataMatrix &lt;- prof %&gt;% base::t() # row-&gt;sampleID; col-&gt;features sampleMetadata &lt;- phen # row-&gt;sampleID; col-&gt;features comparsionVn &lt;- sampleMetadata[, &quot;CompVar&quot;] # corrlation between group and features pvaVn &lt;- apply(dataMatrix, 2, function(feaVn) cor.test(as.numeric(comparsionVn), feaVn)[[&quot;p.value&quot;]]) if (VIPtype == &quot;OPLS&quot;) { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, orthoI = NA, fig.pdfC = &quot;none&quot;)) } else { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, fig.pdfC = &quot;none&quot;)) } quantVn &lt;- qnorm(1 - pvaVn / 2) rmsQuantN &lt;- sqrt(mean(quantVn^2)) opar &lt;- par(font = 2, font.axis = 2, font.lab = 2, las = 1, mar = c(5.1, 4.6, 4.1, 2.1), lwd = 2, pch = 16) plot(pvaVn, vipVn, col = &quot;red&quot;, pch = 16, xlab = &quot;p-value&quot;, ylab = &quot;VIP&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;) box(lwd = 2) curve(qnorm(1 - x / 2) / rmsQuantN, 0, 1, add = TRUE, col = &quot;red&quot;, lwd = 3) abline(h = 1, col = &quot;blue&quot;) abline(v = 0.05, col = &quot;blue&quot;) res_temp &lt;- data.frame( FeatureID = names(vipVn), VIP = vipVn, CorPvalue = pvaVn) %&gt;% dplyr::arrange(desc(VIP)) vip_select &lt;- res_temp %&gt;% dplyr::filter(VIP &gt; vip_cutoff) pl &lt;- ggplot(vip_select, aes(FeatureID, VIP)) + geom_segment(aes(x = FeatureID, xend = FeatureID, y = 0, yend = VIP)) + geom_point(shape = 21, size = 5, color = &#39;#008000&#39; ,fill = &#39;#008000&#39;) + geom_point(aes(1,2.5), color = &#39;white&#39;) + geom_hline(yintercept = 1, linetype = &#39;dashed&#39;) + scale_y_continuous(expand = c(0, 0)) + labs(x = &#39;&#39;, y = &#39;VIP value&#39;) + theme_bw() + theme(legend.position = &#39;none&#39;, legend.text = element_text(color = &#39;black&#39;,size = 12, family = &#39;Arial&#39;, face = &#39;plain&#39;), panel.background = element_blank(), panel.grid = element_blank(), axis.text = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.text.x = element_text(angle = 90), axis.title = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.ticks = element_line(color = &#39;black&#39;), axis.ticks.x = element_blank()) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) res_temp$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res_df &lt;- res_temp %&gt;% dplyr::select(FeatureID, Block, everything()) res &lt;- list(vip = res_df, plot = pl) return(res) } t_fun &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() # rename variables colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } t_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) rest &lt;- t.test(data = dat, value ~ group) res &lt;- c(rest$statistic, rest$p.value) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(t_res) &lt;- c(&quot;FeatureID&quot;, &quot;Statistic&quot;, &quot;Pvalue&quot;) t_res$AdjustedPvalue &lt;- p.adjust(as.numeric(t_res$Pvalue), method = &quot;BH&quot;) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) t_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- t_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } mergedResults &lt;- function( fc_result, vip_result, test_result, group_names, group_labels) { if (is.null(vip_result)) { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } else { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(vip_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, VIP, CorPvalue, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } return(res) } 5.4 DE metabolites fc_res &lt;- FoldChange( x = se_impute, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Moderate&quot;)) vip_res &lt;- VIP_fun( x = se_norm, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), VIPtype = &quot;PLS&quot;, vip_cutoff = 1) ## PLS-DA ## 26 samples x 167 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.12 0.692 0.33 0.288 1 0 0.2 0.05 ttest_res &lt;- t_fun( x = se_norm, group = &quot;group&quot;, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;)) m_results &lt;- mergedResults( fc_result = fc_res, vip_result = vip_res$vip, test_result = ttest_res, group_names = c(&quot;Mild&quot;, &quot;Severe&quot;), group_labels = c(&quot;Mild&quot;, &quot;Severe&quot;)) head(m_results) ## FeatureID Block2 Block FoldChange Log2FoldChange VIP CorPvalue Statistic Pvalue AdjustedPvalue ## 1 M_42449 Mild vs Severe 14_Mild vs 19_Moderate 0.6571801 -0.6056393 2.362694 0.002247897 -3.498896 0.001881585 0.2132448 ## 2 M_52446 Mild vs Severe 14_Mild vs 19_Moderate 0.7040861 -0.5061763 2.059461 0.009476225 -2.892892 0.008125613 0.2132448 ## 3 M_1566 Mild vs Severe 14_Mild vs 19_Moderate 0.7161609 -0.4816443 2.143655 0.006556886 -3.077688 0.005431005 0.2132448 ## 4 M_19263 Mild vs Severe 14_Mild vs 19_Moderate 0.7165011 -0.4809592 2.128317 0.007023483 -3.073546 0.005774977 0.2132448 ## 5 M_42448 Mild vs Severe 14_Mild vs 19_Moderate 0.7577644 -0.4001788 2.006246 0.011828403 -2.793941 0.010215320 0.2132448 ## 6 M_43761 Mild vs Severe 14_Mild vs 19_Moderate 0.8685495 -0.2033201 2.043515 0.010136007 -2.822338 0.009428795 0.2132448 5.5 Obtain inputs for Metorigin The metabolite table must contain at least one column of “HMDBID”, “KEGGID” or “Name”, and a column of 0/1 values indicating statistical significance (1-significant, 0-nonsignificant). If the “Diff” column is missing, all metabolites will be considered as differential metabolites. get_metabolites &lt;- function( x = ExprSet, dat, group_names, index_names = c(&quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;VIP&quot;, &quot;CorPvalue&quot;, &quot;Pvalue&quot;, &quot;AdjustedPvalue&quot;), index_cutoff = c(1, 1, 1, 0.05, 0.05, 0.2)) { # x = ExprSet # dat = m_results # group_names = &quot;Mild vs Severe&quot; # index_names = c(&quot;Log2FoldChange&quot;, &quot;AdjustedPvalue&quot;) # index_cutoff = c(0, 0.2) feature &lt;- Biobase::fData(x) colnames(feature)[which(colnames(feature) == &quot;SampleID HMDBID&quot;)] &lt;- &quot;HMDB&quot; colnames(feature)[which(colnames(feature) == &quot;KEGG&quot;)] &lt;- &quot;cpd_ID&quot; colnames(feature)[which(colnames(feature) == &quot;BIOCHEMICAL&quot;)] &lt;- &quot;Compounds&quot; feature$HMDB &lt;- gsub(&quot;,\\\\S+&quot;, &quot;&quot;, feature$HMDB) temp_dat &lt;- dat %&gt;% dplyr::filter(Block2 %in% group_names) %&gt;% dplyr::inner_join(feature %&gt;% tibble::rownames_to_column(&quot;FeatureID&quot;), by = &quot;FeatureID&quot;) %&gt;% dplyr::filter(HMDB != &quot;-&quot;) colnames(temp_dat)[which(colnames(temp_dat) == index_names[1])] &lt;- &quot;DA_index1&quot; colnames(temp_dat)[which(colnames(temp_dat) == index_names[2])] &lt;- &quot;DA_index2&quot; temp_dat_diff &lt;- temp_dat %&gt;% dplyr::filter(abs(DA_index1) &gt; index_cutoff[1]) %&gt;% dplyr::filter(DA_index2 &lt; index_cutoff[2]) %&gt;% dplyr::mutate(Diff = 1) if (nrow(temp_dat_diff) == 0) { stop(&quot;Beyond these thresholds, no significant metabolites were selected&quot;) } temp_dat_nodiff &lt;- temp_dat %&gt;% dplyr::filter(!HMDB %in% temp_dat_diff$HMDB) %&gt;% dplyr::mutate(Diff = 0) res &lt;- rbind(temp_dat_diff, temp_dat_nodiff) %&gt;% dplyr::select(HMDB, cpd_ID, Compounds, DA_index1, DA_index2, Diff) %&gt;% dplyr::rename(HMDBID = HMDB, KEGGID = cpd_ID, Name = Compounds) %&gt;% dplyr::select(HMDBID, KEGGID, Name, Diff) return(res) } pre_result &lt;- get_metabolites( x = ExprSet, dat = m_results, group_names = &quot;Mild vs Severe&quot;, index_names = c(&quot;Log2FoldChange&quot;, &quot;AdjustedPvalue&quot;), index_cutoff = c(0, 1)) head(pre_result) ## HMDBID KEGGID Name Diff ## 1 HMDB0005322 &lt;NA&gt; 1-palmitoyl-2-linoleoyl-GPE (16:0/18:2) 1 ## 2 HMDB0008994 &lt;NA&gt; 1-stearoyl-2-linoleoyl-GPE (18:0/18:2)* 1 ## 3 HMDB0002166 C05145 3-aminoisobutyrate 1 ## 4 HMDB0005320 &lt;NA&gt; 1-palmitoyl-2-oleoyl-GPE (16:0/18:1) 1 ## 5 HMDB0008993 &lt;NA&gt; 1-stearoyl-2-oleoyl-GPE (18:0/18:1) 1 ## 6 HMDB0094649 &lt;NA&gt; 2-aminoheptanoate 1 5.6 Save result the csv file could be used as inputs in the MetOrigin website. if(!dir.exists(&quot;./dataset/MetOrigin&quot;)) { dir.create(&quot;./dataset/MetOrigin&quot;, recursive = TRUE) } write.csv(pre_result, &quot;./dataset/MetOrigin/MetOrigin_inputs.csv&quot;, row.names = F) 5.7 MetOrigin User Tutorial MetOrigin comprises five parts: Load data Please select the analysis mode at first “Simple MetOrigin Analysis” or “Deep MetOrigin Analysis”. Then you can try “Load Example Data” or upload your own data. Host information needs to be confirmed before moving to the next step. Origin Analysis This step is to identify where metabolites come from: host, bacteria, both, or unknown? Function Analysis This step is to perform the metabolic pathway enrichment analysis according to different categories of metabolites: metabolites belonging to the host, bacteria, or both. Sankey Network This step is to link all the possible bacteria that may participate in a specific metabolic reaction, helping you to identify important interplay between bacteria and metabolites. Download Results All the analysis results can be downloaded for your further data exploration. See more details please go to the below tutorial (MetOrigin website): MetOrigin User Tutorial 5.8 Session info devtools::session_info() ## ─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os macOS Monterey 12.2.1 ## system x86_64, darwin17.0 ## ui RStudio ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Asia/Shanghai ## date 2023-11-27 ## rstudio 2023.09.0+463 Desert Sunflower (desktop) ## pandoc 3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [2] CRAN (R 4.1.0) ## ade4 1.7-22 2023-02-06 [2] CRAN (R 4.1.2) ## affy 1.72.0 2021-10-26 [2] Bioconductor ## affyio 1.64.0 2021-10-26 [2] Bioconductor ## annotate 1.72.0 2021-10-26 [2] Bioconductor ## AnnotationDbi * 1.60.2 2023-03-10 [2] Bioconductor ## ape 5.7-1 2023-03-13 [2] CRAN (R 4.1.2) ## aplot 0.1.10 2023-03-08 [2] CRAN (R 4.1.2) ## attempt 0.3.1 2020-05-03 [2] CRAN (R 4.1.0) ## backports 1.4.1 2021-12-13 [2] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [2] CRAN (R 4.1.0) ## Biobase * 2.54.0 2021-10-26 [2] Bioconductor ## BiocGenerics * 0.40.0 2021-10-26 [2] Bioconductor ## BiocManager 1.30.21 2023-06-10 [2] CRAN (R 4.1.3) ## BiocParallel 1.28.3 2021-12-09 [2] Bioconductor ## biomformat 1.22.0 2021-10-26 [2] Bioconductor ## Biostrings 2.62.0 2021-10-26 [2] Bioconductor ## bit 4.0.5 2022-11-15 [2] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [2] CRAN (R 4.1.0) ## bitops 1.0-7 2021-04-24 [2] CRAN (R 4.1.0) ## blob 1.2.4 2023-03-17 [2] CRAN (R 4.1.2) ## bookdown 0.34 2023-05-09 [2] CRAN (R 4.1.2) ## broom 1.0.5 2023-06-09 [2] CRAN (R 4.1.3) ## bslib 0.6.0 2023-11-21 [1] CRAN (R 4.1.3) ## cachem 1.0.8 2023-05-01 [2] CRAN (R 4.1.2) ## Cairo 1.6-0 2022-07-05 [2] CRAN (R 4.1.2) ## callr 3.7.3 2022-11-02 [2] CRAN (R 4.1.2) ## car 3.1-2 2023-03-30 [2] CRAN (R 4.1.2) ## carData 3.0-5 2022-01-06 [2] CRAN (R 4.1.2) ## caret 6.0-94 2023-03-21 [2] CRAN (R 4.1.2) ## caTools 1.18.2 2021-03-28 [2] CRAN (R 4.1.0) ## cellranger 1.1.0 2016-07-27 [2] CRAN (R 4.1.0) ## checkmate 2.2.0 2023-04-27 [2] CRAN (R 4.1.2) ## circlize 0.4.15 2022-05-10 [2] CRAN (R 4.1.2) ## class 7.3-22 2023-05-03 [2] CRAN (R 4.1.2) ## cli 3.6.1 2023-03-23 [2] CRAN (R 4.1.2) ## clue 0.3-64 2023-01-31 [2] CRAN (R 4.1.2) ## cluster * 2.1.4 2022-08-22 [2] CRAN (R 4.1.2) ## clusterProfiler * 4.2.2 2022-01-13 [2] Bioconductor ## codetools 0.2-19 2023-02-01 [2] CRAN (R 4.1.2) ## coin 1.4-2 2021-10-08 [2] CRAN (R 4.1.0) ## colorspace 2.1-0 2023-01-23 [2] CRAN (R 4.1.2) ## ComplexHeatmap 2.10.0 2021-10-26 [2] Bioconductor ## config 0.3.1 2020-12-17 [2] CRAN (R 4.1.0) ## corpcor 1.6.10 2021-09-16 [2] CRAN (R 4.1.0) ## cowplot 1.1.1 2020-12-30 [2] CRAN (R 4.1.0) ## crayon 1.5.2 2022-09-29 [2] CRAN (R 4.1.2) ## crmn 0.0.21 2020-02-10 [2] CRAN (R 4.1.0) ## curl 5.0.1 2023-06-07 [2] CRAN (R 4.1.3) ## data.table 1.14.8 2023-02-17 [2] CRAN (R 4.1.2) ## DBI 1.1.3 2022-06-18 [2] CRAN (R 4.1.2) ## DelayedArray 0.20.0 2021-10-26 [2] Bioconductor ## dendextend * 1.17.1 2023-03-25 [2] CRAN (R 4.1.2) ## DESeq2 1.34.0 2021-10-26 [2] Bioconductor ## devtools 2.4.5 2022-10-11 [2] CRAN (R 4.1.2) ## digest 0.6.33 2023-07-07 [1] CRAN (R 4.1.3) ## DO.db 2.9 2022-04-11 [2] Bioconductor ## doParallel 1.0.17 2022-02-07 [2] CRAN (R 4.1.2) ## doRNG 1.8.6 2023-01-16 [2] CRAN (R 4.1.2) ## DOSE 3.20.1 2021-11-18 [2] Bioconductor ## doSNOW 1.0.20 2022-02-04 [2] CRAN (R 4.1.2) ## downloader 0.4 2015-07-09 [2] CRAN (R 4.1.0) ## dplyr * 1.1.2 2023-04-20 [2] CRAN (R 4.1.2) ## DT 0.28 2023-05-18 [2] CRAN (R 4.1.3) ## dynamicTreeCut * 1.63-1 2016-03-11 [2] CRAN (R 4.1.0) ## e1071 1.7-13 2023-02-01 [2] CRAN (R 4.1.2) ## edgeR 3.36.0 2021-10-26 [2] Bioconductor ## ellipse 0.4.5 2023-04-05 [2] CRAN (R 4.1.2) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.1.0) ## enrichplot 1.14.2 2022-02-24 [2] Bioconductor ## evaluate 0.21 2023-05-05 [2] CRAN (R 4.1.2) ## factoextra * 1.0.7 2020-04-01 [2] CRAN (R 4.1.0) ## fansi 1.0.4 2023-01-22 [2] CRAN (R 4.1.2) ## farver 2.1.1 2022-07-06 [2] CRAN (R 4.1.2) ## fastcluster * 1.2.3 2021-05-24 [2] CRAN (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] CRAN (R 4.1.2) ## fastmatch 1.1-3 2021-07-23 [2] CRAN (R 4.1.0) ## fdrtool 1.2.17 2021-11-13 [2] CRAN (R 4.1.0) ## fgsea 1.20.0 2021-10-26 [2] Bioconductor ## filematrix 1.3 2018-02-27 [2] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [2] CRAN (R 4.1.2) ## foreign 0.8-84 2022-12-06 [2] CRAN (R 4.1.2) ## forestplot 3.1.1 2022-12-06 [2] CRAN (R 4.1.2) ## Formula 1.2-5 2023-02-24 [2] CRAN (R 4.1.2) ## fs 1.6.2 2023-04-25 [2] CRAN (R 4.1.2) ## furrr 0.3.1 2022-08-15 [2] CRAN (R 4.1.2) ## future 1.33.0 2023-07-01 [2] CRAN (R 4.1.3) ## future.apply 1.11.0 2023-05-21 [2] CRAN (R 4.1.3) ## genefilter 1.76.0 2021-10-26 [2] Bioconductor ## geneplotter 1.72.0 2021-10-26 [2] Bioconductor ## generics 0.1.3 2022-07-05 [2] CRAN (R 4.1.2) ## GenomeInfoDb * 1.30.1 2022-01-30 [2] Bioconductor ## GenomeInfoDbData 1.2.7 2022-03-09 [2] Bioconductor ## GenomicRanges * 1.46.1 2021-11-18 [2] Bioconductor ## GetoptLong 1.0.5 2020-12-15 [2] CRAN (R 4.1.0) ## ggforce 0.4.1 2022-10-04 [2] CRAN (R 4.1.2) ## ggfun 0.1.1 2023-06-24 [2] CRAN (R 4.1.3) ## ggplot2 * 3.4.2 2023-04-03 [2] CRAN (R 4.1.2) ## ggplotify 0.1.1 2023-06-27 [2] CRAN (R 4.1.3) ## ggpubr 0.6.0 2023-02-10 [2] CRAN (R 4.1.2) ## ggraph * 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71) ## ggrepel 0.9.3 2023-02-03 [2] CRAN (R 4.1.2) ## ggsignif 0.6.4 2022-10-13 [2] CRAN (R 4.1.2) ## ggtree 3.2.1 2021-11-16 [2] Bioconductor ## glasso 1.11 2019-10-01 [2] CRAN (R 4.1.0) ## glmnet * 4.1-7 2023-03-23 [2] CRAN (R 4.1.2) ## GlobalOptions 0.1.2 2020-06-10 [2] CRAN (R 4.1.0) ## globals 0.16.2 2022-11-21 [2] CRAN (R 4.1.2) ## globaltest 5.48.0 2021-10-26 [2] Bioconductor ## glue * 1.6.2 2022-02-24 [2] CRAN (R 4.1.2) ## Gmisc * 3.0.2 2023-03-13 [2] CRAN (R 4.1.2) ## gmm 1.8 2023-06-06 [2] CRAN (R 4.1.3) ## gmp 0.7-1 2023-02-07 [2] CRAN (R 4.1.2) ## GO.db 3.14.0 2022-04-11 [2] Bioconductor ## golem 0.4.1 2023-06-05 [2] CRAN (R 4.1.3) ## GOSemSim 2.20.0 2021-10-26 [2] Bioconductor ## gower 1.0.1 2022-12-22 [2] CRAN (R 4.1.2) ## gplots 3.1.3 2022-04-25 [2] CRAN (R 4.1.2) ## graphlayouts 1.0.0 2023-05-01 [2] CRAN (R 4.1.2) ## gridExtra 2.3 2017-09-09 [2] CRAN (R 4.1.0) ## gridGraphics 0.5-1 2020-12-13 [2] CRAN (R 4.1.0) ## gtable 0.3.3 2023-03-21 [2] CRAN (R 4.1.2) ## gtools 3.9.4 2022-11-27 [2] CRAN (R 4.1.2) ## hardhat 1.3.0 2023-03-30 [2] CRAN (R 4.1.2) ## highr 0.10 2022-12-22 [2] CRAN (R 4.1.2) ## Hmisc 5.1-0 2023-05-08 [2] CRAN (R 4.1.2) ## hms 1.1.3 2023-03-21 [2] CRAN (R 4.1.2) ## htmlTable * 2.4.1 2022-07-07 [2] CRAN (R 4.1.2) ## htmltools 0.5.7 2023-11-03 [1] CRAN (R 4.1.3) ## htmlwidgets 1.6.2 2023-03-17 [2] CRAN (R 4.1.2) ## httpuv 1.6.11 2023-05-11 [2] CRAN (R 4.1.3) ## httr * 1.4.6 2023-05-08 [2] CRAN (R 4.1.2) ## huge 1.3.5 2021-06-30 [2] CRAN (R 4.1.0) ## igraph * 1.5.0 2023-06-16 [1] CRAN (R 4.1.3) ## impute 1.68.0 2021-10-26 [2] Bioconductor ## imputeLCMD 2.1 2022-06-10 [2] CRAN (R 4.1.2) ## ipred 0.9-14 2023-03-09 [2] CRAN (R 4.1.2) ## IRanges * 2.28.0 2021-10-26 [2] Bioconductor ## irlba 2.3.5.1 2022-10-03 [2] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [2] CRAN (R 4.1.2) ## itertools 0.1-3 2014-03-12 [2] CRAN (R 4.1.0) ## jpeg 0.1-10 2022-11-29 [2] CRAN (R 4.1.2) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.0) ## jsonlite 1.8.7 2023-06-29 [2] CRAN (R 4.1.3) ## KEGGREST 1.34.0 2021-10-26 [2] Bioconductor ## KernSmooth 2.23-22 2023-07-10 [2] CRAN (R 4.1.3) ## knitr 1.43 2023-05-25 [2] CRAN (R 4.1.3) ## labeling 0.4.2 2020-10-20 [2] CRAN (R 4.1.0) ## later 1.3.1 2023-05-02 [2] CRAN (R 4.1.2) ## lattice 0.21-8 2023-04-05 [2] CRAN (R 4.1.2) ## lava 1.7.2.1 2023-02-27 [2] CRAN (R 4.1.2) ## lavaan 0.6-15 2023-03-14 [2] CRAN (R 4.1.2) ## lazyeval 0.2.2 2019-03-15 [2] CRAN (R 4.1.0) ## libcoin 1.0-9 2021-09-27 [2] CRAN (R 4.1.0) ## lifecycle 1.0.3 2022-10-07 [2] CRAN (R 4.1.2) ## limma 3.50.3 2022-04-07 [2] Bioconductor ## listenv 0.9.0 2022-12-16 [2] CRAN (R 4.1.2) ## locfit 1.5-9.8 2023-06-11 [2] CRAN (R 4.1.3) ## lubridate 1.9.2 2023-02-10 [2] CRAN (R 4.1.2) ## magrittr * 2.0.3 2022-03-30 [2] CRAN (R 4.1.2) ## MALDIquant 1.22.1 2023-03-20 [2] CRAN (R 4.1.2) ## MASS 7.3-60 2023-05-04 [2] CRAN (R 4.1.2) ## massdatabase * 1.0.7 2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93) ## massdataset * 1.0.24 2023-05-30 [2] gitlab (jaspershen/massdataset@b397116) ## masstools * 1.0.10 2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc) ## Matrix * 1.6-0 2023-07-08 [2] CRAN (R 4.1.3) ## MatrixGenerics * 1.6.0 2021-10-26 [2] Bioconductor ## matrixStats * 1.0.0 2023-06-02 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.1.0) ## MetaboAnalystR * 3.2.0 2022-06-28 [2] Github (xia-lab/MetaboAnalystR@892a31b) ## metagenomeSeq 1.36.0 2021-10-26 [2] Bioconductor ## metid * 1.2.26 2023-05-30 [2] gitlab (jaspershen/metid@6bde121) ## metpath * 1.0.5 2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f) ## mgcv 1.8-42 2023-03-02 [2] CRAN (R 4.1.2) ## MicrobiomeProfiler * 1.0.0 2021-10-26 [2] Bioconductor ## mime 0.12 2021-09-28 [2] CRAN (R 4.1.0) ## miniUI 0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0) ## missForest 1.5 2022-04-14 [2] CRAN (R 4.1.2) ## mixedCCA 1.6.2 2022-09-09 [2] CRAN (R 4.1.2) ## mixOmics 6.18.1 2021-11-18 [2] Bioconductor (R 4.1.2) ## mnormt 2.1.1 2022-09-26 [2] CRAN (R 4.1.2) ## ModelMetrics 1.2.2.2 2020-03-17 [2] CRAN (R 4.1.0) ## modeltools 0.2-23 2020-03-05 [2] CRAN (R 4.1.0) ## MsCoreUtils 1.6.2 2022-02-24 [2] Bioconductor ## MSnbase * 2.20.4 2022-01-16 [2] Bioconductor ## multcomp 1.4-25 2023-06-20 [2] CRAN (R 4.1.3) ## multtest 2.50.0 2021-10-26 [2] Bioconductor ## munsell 0.5.0 2018-06-12 [2] CRAN (R 4.1.0) ## mvtnorm 1.2-2 2023-06-08 [2] CRAN (R 4.1.3) ## mzID 1.32.0 2021-10-26 [2] Bioconductor ## mzR * 2.28.0 2021-10-27 [2] Bioconductor ## ncdf4 1.21 2023-01-07 [2] CRAN (R 4.1.2) ## NetCoMi * 1.0.3 2022-07-14 [2] Github (stefpeschel/NetCoMi@d4d80d3) ## nlme 3.1-162 2023-01-31 [2] CRAN (R 4.1.2) ## nnet 7.3-19 2023-05-03 [2] CRAN (R 4.1.2) ## norm 1.0-11.1 2023-06-18 [2] CRAN (R 4.1.3) ## openxlsx 4.2.5.2 2023-02-06 [2] CRAN (R 4.1.2) ## org.Mm.eg.db * 3.14.0 2022-11-23 [2] Bioconductor ## parallelly 1.36.0 2023-05-26 [2] CRAN (R 4.1.3) ## patchwork 1.1.2 2022-08-19 [2] CRAN (R 4.1.2) ## pbapply 1.7-2 2023-06-27 [2] CRAN (R 4.1.3) ## pbivnorm 0.6.0 2015-01-23 [2] CRAN (R 4.1.0) ## pcaMethods 1.86.0 2021-10-26 [2] Bioconductor ## pcaPP 2.0-3 2022-10-24 [2] CRAN (R 4.1.2) ## permute 0.9-7 2022-01-27 [2] CRAN (R 4.1.2) ## pheatmap 1.0.12 2019-01-04 [2] CRAN (R 4.1.0) ## phyloseq 1.38.0 2021-10-26 [2] Bioconductor ## pillar 1.9.0 2023-03-22 [2] CRAN (R 4.1.2) ## pkgbuild 1.4.2 2023-06-26 [2] CRAN (R 4.1.3) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.1.0) ## pkgload 1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3) ## plotly * 4.10.2 2023-06-03 [2] CRAN (R 4.1.3) ## plyr 1.8.8 2022-11-11 [2] CRAN (R 4.1.2) ## png 0.1-8 2022-11-29 [2] CRAN (R 4.1.2) ## polyclip 1.10-4 2022-10-20 [2] CRAN (R 4.1.2) ## POMA * 1.7.2 2022-07-26 [2] Github (pcastellanoescuder/POMA@bc8a972) ## preprocessCore 1.56.0 2021-10-26 [2] Bioconductor ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.1.0) ## pROC 1.18.4 2023-07-06 [2] CRAN (R 4.1.3) ## processx 3.8.2 2023-06-30 [2] CRAN (R 4.1.3) ## prodlim 2023.03.31 2023-04-02 [2] CRAN (R 4.1.2) ## profvis 0.3.8 2023-05-02 [2] CRAN (R 4.1.2) ## progress 1.2.2 2019-05-16 [2] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0) ## ProtGenerics * 1.26.0 2021-10-26 [2] Bioconductor ## proxy 0.4-27 2022-06-09 [2] CRAN (R 4.1.2) ## ps 1.7.5 2023-04-18 [2] CRAN (R 4.1.2) ## psych 2.3.6 2023-06-21 [2] CRAN (R 4.1.3) ## pulsar 0.3.10 2023-01-26 [2] CRAN (R 4.1.2) ## purrr 1.0.1 2023-01-10 [2] CRAN (R 4.1.2) ## qgraph 1.9.5 2023-05-16 [2] CRAN (R 4.1.3) ## qs 0.25.5 2023-02-22 [2] CRAN (R 4.1.2) ## quadprog 1.5-8 2019-11-20 [2] CRAN (R 4.1.0) ## qvalue 2.26.0 2021-10-26 [2] Bioconductor ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.1.0) ## ragg 1.2.5 2023-01-12 [2] CRAN (R 4.1.2) ## randomForest 4.7-1.1 2022-05-23 [2] CRAN (R 4.1.2) ## RankProd 3.20.0 2021-10-26 [2] Bioconductor ## RApiSerialize 0.1.2 2022-08-25 [2] CRAN (R 4.1.2) ## rARPACK 0.11-0 2016-03-10 [2] CRAN (R 4.1.0) ## rbibutils 2.2.13 2023-01-13 [2] CRAN (R 4.1.2) ## RColorBrewer 1.1-3 2022-04-03 [2] CRAN (R 4.1.2) ## Rcpp * 1.0.11 2023-07-06 [1] CRAN (R 4.1.3) ## RcppParallel 5.1.7 2023-02-27 [2] CRAN (R 4.1.2) ## RCurl 1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2) ## Rdisop 1.54.0 2021-10-26 [2] Bioconductor ## Rdpack 2.4 2022-07-20 [2] CRAN (R 4.1.2) ## readr 2.1.4 2023-02-10 [2] CRAN (R 4.1.2) ## readxl * 1.4.3 2023-07-06 [2] CRAN (R 4.1.3) ## recipes 1.0.6 2023-04-25 [2] CRAN (R 4.1.2) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.1.0) ## reshape2 1.4.4 2020-04-09 [2] CRAN (R 4.1.0) ## rhdf5 2.38.1 2022-03-10 [2] Bioconductor ## rhdf5filters 1.6.0 2021-10-26 [2] Bioconductor ## Rhdf5lib 1.16.0 2021-10-26 [2] Bioconductor ## rjson 0.2.21 2022-01-09 [2] CRAN (R 4.1.2) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.1.2) ## rmarkdown 2.23 2023-07-01 [2] CRAN (R 4.1.3) ## Rmpfr 0.9-2 2023-04-22 [2] CRAN (R 4.1.2) ## rngtools 1.5.2 2021-09-20 [2] CRAN (R 4.1.0) ## rootSolve 1.8.2.3 2021-09-29 [2] CRAN (R 4.1.0) ## ropls * 1.26.4 2022-01-11 [2] Bioconductor ## rpart 4.1.19 2022-10-21 [2] CRAN (R 4.1.2) ## Rserve * 1.8-11 2022-11-28 [2] CRAN (R 4.1.2) ## RSpectra 0.16-1 2022-04-24 [2] CRAN (R 4.1.2) ## RSQLite 2.3.1 2023-04-03 [2] CRAN (R 4.1.2) ## rstatix 0.7.2 2023-02-01 [2] CRAN (R 4.1.2) ## rstudioapi 0.15.0 2023-07-07 [2] CRAN (R 4.1.3) ## rvest 1.0.3 2022-08-19 [2] CRAN (R 4.1.2) ## S4Vectors * 0.32.4 2022-03-29 [2] Bioconductor ## sandwich 3.0-2 2022-06-15 [2] CRAN (R 4.1.2) ## sass 0.4.6 2023-05-03 [2] CRAN (R 4.1.2) ## scales 1.2.1 2022-08-20 [2] CRAN (R 4.1.2) ## scatterpie 0.2.1 2023-06-07 [2] CRAN (R 4.1.3) ## scrime 1.3.5 2018-12-01 [2] CRAN (R 4.1.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.1.0) ## shadowtext 0.1.2 2022-04-22 [2] CRAN (R 4.1.2) ## shape 1.4.6 2021-05-19 [2] CRAN (R 4.1.0) ## shiny 1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3) ## shinycustomloader 0.9.0 2018-03-27 [2] CRAN (R 4.1.0) ## shinyWidgets 0.7.6 2023-01-08 [2] CRAN (R 4.1.2) ## siggenes 1.68.0 2021-10-26 [2] Bioconductor ## snow 0.4-4 2021-10-27 [2] CRAN (R 4.1.0) ## SpiecEasi * 1.1.2 2022-07-14 [2] Github (zdk123/SpiecEasi@c463727) ## SPRING * 1.0.4 2022-08-03 [2] Github (GraceYoon/SPRING@3d641a4) ## stringdist 0.9.10 2022-11-07 [2] CRAN (R 4.1.2) ## stringfish 0.15.8 2023-05-30 [2] CRAN (R 4.1.3) ## stringi 1.7.12 2023-01-11 [2] CRAN (R 4.1.2) ## stringr 1.5.0 2022-12-02 [2] CRAN (R 4.1.2) ## SummarizedExperiment * 1.24.0 2021-10-26 [2] Bioconductor ## survival 3.5-5 2023-03-12 [2] CRAN (R 4.1.2) ## systemfonts 1.0.4 2022-02-11 [2] CRAN (R 4.1.2) ## textshaping 0.3.6 2021-10-13 [2] CRAN (R 4.1.0) ## TH.data 1.1-2 2023-04-17 [2] CRAN (R 4.1.2) ## tibble * 3.2.1 2023-03-20 [2] CRAN (R 4.1.2) ## tidygraph 1.2.3 2023-02-01 [2] CRAN (R 4.1.2) ## tidyr 1.3.0 2023-01-24 [2] CRAN (R 4.1.2) ## tidyselect 1.2.0 2022-10-10 [2] CRAN (R 4.1.2) ## tidytree 0.4.2 2022-12-18 [2] CRAN (R 4.1.2) ## timechange 0.2.0 2023-01-11 [2] CRAN (R 4.1.2) ## timeDate 4022.108 2023-01-07 [2] CRAN (R 4.1.2) ## tmvtnorm 1.5 2022-03-22 [2] CRAN (R 4.1.2) ## treeio 1.18.1 2021-11-14 [2] Bioconductor ## tweenr 2.0.2 2022-09-06 [2] CRAN (R 4.1.2) ## tzdb 0.4.0 2023-05-12 [2] CRAN (R 4.1.3) ## urlchecker 1.0.1 2021-11-30 [2] CRAN (R 4.1.0) ## usethis 2.2.2 2023-07-06 [2] CRAN (R 4.1.3) ## utf8 1.2.3 2023-01-31 [2] CRAN (R 4.1.2) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.1.3) ## vegan 2.6-4 2022-10-11 [2] CRAN (R 4.1.2) ## VGAM 1.1-8 2023-03-09 [2] CRAN (R 4.1.2) ## viridis 0.6.3 2023-05-03 [2] CRAN (R 4.1.2) ## viridisLite 0.4.2 2023-05-02 [2] CRAN (R 4.1.2) ## vsn 3.62.0 2021-10-26 [2] Bioconductor ## WGCNA * 1.72-1 2023-01-18 [2] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.1.2) ## Wrench 1.12.0 2021-10-26 [2] Bioconductor ## xfun 0.40 2023-08-09 [1] CRAN (R 4.1.3) ## XMAS2 * 2.2.0 2023-10-27 [1] local ## XML 3.99-0.14 2023-03-19 [2] CRAN (R 4.1.2) ## xml2 1.3.5 2023-07-06 [2] CRAN (R 4.1.3) ## xtable 1.8-4 2019-04-21 [2] CRAN (R 4.1.0) ## XVector 0.34.0 2021-10-26 [2] Bioconductor ## yaml 2.3.7 2023-01-23 [2] CRAN (R 4.1.2) ## yulab.utils 0.0.6 2022-12-20 [2] CRAN (R 4.1.2) ## zip 2.3.0 2023-04-17 [2] CRAN (R 4.1.2) ## zlibbioc 1.40.0 2021-10-26 [2] Bioconductor ## zoo 1.8-12 2023-04-13 [2] CRAN (R 4.1.2) ## ## [1] /Users/zouhua/Library/R/x86_64/4.1/library ## [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library ## ## ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── References "],["example.html", "Chapter 6 Example 6.1 Loading packages 6.2 Importing data 6.3 Data Processing 6.4 Cluster Analysis 6.5 Chemometrics Analysis 6.6 Univariate Analysis 6.7 Feature Selection 6.8 Network Analysis 6.9 Network Analysis by WGCNA 6.10 Systematic Information", " Chapter 6 Example We perform all the data analysis on our own metabolomic data in this chapter. There are several datasets: GvHD stool metabolites TM wide-target sequencing: /home/xuxiaomin/project/NanFangHospitalGvHD/00.data/metabolites_TM/MWY-20-522-01_2021-03-25_17-34-06/1.Data_assess/ALL_sample_data.xlsx GvHD stool metabolites SCFA: /home/xuxiaomin/project/NanFangHospitalGvHD/00.data/metabolites_scfa/SCFA.levels.xlsx PD-1 mice trial (round 2) serum metabolites TM wide-target sequencing: /home/xuxiaomin/project/pd1_mice/Round_2/00.data/MetaboliteSerum/MWY-20-049/1.Data_assess/all_group/ALL_sample_data.xlsx and the metadata: GvHD metadata: /home/xuxiaomin/project/NanFangHospitalGvHD/00.data/metadata/metadata_v4.txt We transform their names as following: GvHD_stool_metabolites_TM.xlsx GvHD_stool_metabolites_SCFA.xlsx PD1_mice_serum_metabolites_TM.xlsx GvHD_metadata.txt Here, we use the GvHD_stool_metabolites_TM.xlsx to practice our template. 6.1 Loading packages knitr::opts_chunk$set(warning = F) library(dplyr) library(tibble) library(POMA) library(ropls) library(ggplot2) library(ggraph) library(plotly) library(SummarizedExperiment) library(readxl) library(cluster) # clustering algorithms library(factoextra) # clustering visualization library(dendextend) # for comparing two dendrograms library(NetCoMi) library(SPRING) library(SpiecEasi) library(WGCNA) # rm(list = ls()) options(stringsAsFactors = F) options(future.globals.maxSize = 1000 * 1024^2) 6.2 Importing data features table profile &lt;- readxl::read_xlsx(&quot;./dataset/GvHD_stool_metabolites_TM.xlsx&quot;, sheet = 1) head(profile) ## # A tibble: 6 × 78 ## Index Compounds 物质 `Class I` 物质一级分类 `Class II` 物质二级分类 `Q1 (Da)` Molecular Weight (Da…¹ `Ionization model` Formula ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 MEDL00066 2-Hydroxy-2-m… - - - - - 117. 118. [M-H]- C5H10O3 ## 2 MEDL00356 Phe-Asp - - - - - 245. 348. [M+H-2H2O]+ C13H16… ## 3 MEDL00369 Glu-Phe - - - - - 293. 294. [M-H]- C14H18… ## 4 MEDL00375 Glu-Trp - - - - - 334. 333. [M+H]+ C16H19… ## 5 MEDL00392 1-Oleoyl-sn-g… - - - - - 525. 521. [M+H]+ C26H52… ## 6 MEDL00401 Confertifoline - - - - - 233. 234. [M-H]- C15H22… ## # ℹ abbreviated name: ¹​`Molecular Weight (Da)` ## # ℹ 67 more variables: `KEGG ID` &lt;chr&gt;, HMDB &lt;chr&gt;, `Pubchem CID` &lt;chr&gt;, CAS &lt;chr&gt;, ChEBI &lt;chr&gt;, Metlin &lt;chr&gt;, mix01 &lt;dbl&gt;, mix02 &lt;dbl&gt;, ## # mix03 &lt;dbl&gt;, mix04 &lt;dbl&gt;, mix05 &lt;dbl&gt;, mix06 &lt;dbl&gt;, mix07 &lt;dbl&gt;, `TZW-V0` &lt;dbl&gt;, `LBC-V0` &lt;dbl&gt;, `HXZ-V0` &lt;dbl&gt;, `LJY-V0` &lt;dbl&gt;, ## # `CJY-V0` &lt;dbl&gt;, `WKM-V0` &lt;dbl&gt;, `WJH-V0` &lt;dbl&gt;, `ZTX2-V0` &lt;dbl&gt;, `DGL-V0` &lt;dbl&gt;, `ZHP-V0` &lt;dbl&gt;, `MZH-V0` &lt;dbl&gt;, `WL-V0` &lt;dbl&gt;, ## # `LWJ2-V0` &lt;dbl&gt;, `SZP-V0` &lt;dbl&gt;, `LPQ-V0` &lt;dbl&gt;, `LHR-V0` &lt;dbl&gt;, `XQ-V0` &lt;dbl&gt;, `LJD-V0` &lt;dbl&gt;, `LXH-V0` &lt;dbl&gt;, `YF-V0` &lt;dbl&gt;, ## # `ZJW-V0` &lt;dbl&gt;, `LHC-V0` &lt;dbl&gt;, `LQB-V0` &lt;dbl&gt;, `LWL-V0` &lt;dbl&gt;, `XD-V0` &lt;dbl&gt;, `ZCY-V0` &lt;dbl&gt;, `ZTX1-V0` &lt;dbl&gt;, `TZW-V1` &lt;dbl&gt;, ## # `HXZ-V1` &lt;dbl&gt;, `LJY-V1` &lt;dbl&gt;, `CJY-V1` &lt;dbl&gt;, `WKM-V1` &lt;dbl&gt;, `WJH-V1` &lt;dbl&gt;, `ZTX2-V1` &lt;dbl&gt;, `DGL-V1` &lt;dbl&gt;, `ZHP-V1` &lt;dbl&gt;, … metadata table metadata &lt;- data.table::fread(&quot;./dataset/GvHD_metadata.txt&quot;) head(metadata) ## seq_id SampleName FMT_status SampleType Group V1_outcome GVHD_type GVHD_type_phynotype Donor baseline_merge ## 1: 4371 CJY V0 stool kid CR cGVHD diarrhea DO1 ## 2: 4389 CJY V1 stool kid CR cGVHD diarrhea DO1 ## 3: 4426 CJY_WKM_LXH_FMTdonor bacteria_solution donor ## 4: 4375 DGL V0 stool adult CR cGVHD bowel DO2 medium ## 5: 4393 DGL V1 stool adult CR cGVHD bowel DO2 ## 6: 4435 DGL_FMTdonor bacteria_solution donor ## baseline_aGVHD_sainai baseline_aGVHD_sainai_detail baseline_aGVHD_glucksberg baseline_aGVHD_glucksberg_detail baseline_cGVHD_NIH ## 1: ## 2: ## 3: ## 4: 中度 ## 5: ## 6: ## baseline_cGVHD_NIH_detail Baseline_infection antibiotics_48h_pre_or_post_FMT GVHDdrug_antiMicrobiomeDrug_2weeksPreV0 ## 1: ## 2: ## 3: ## 4: 肠道2级，皮肤1级 他克莫司、麦考酚酯、伊曲康唑 ## 5: 他克莫司、麦考酚酯、伊曲康唑 ## 6: ## GVHDdrug_antiMicrobiomeDrug_V0toV1 FMT_method gender age Diagnosis HSCT_DLI_date ## 1: nasojejunal tube male 3 AML 2020/5/28 ## 2: nasojejunal tube male 3 AML 2020/5/28 ## 3: NA ## 4: 他克莫司、麦考酚酯、伊曲康唑 colonoscope male 36 AML 2019/12/1 ## 5: 他克莫司、麦考酚酯、伊曲康唑 colonoscope male 36 AML 2019/12/1 ## 6: NA ## Pretreatment Pretreatment_type GVHD_prevention death relapse ## 1: Ara-c+CY+IVBu+ATG+Flu+PTCy+PTCy（Ara+Cy+Bu+Flu+PTCy） marrow cleansing PTCY+PTFLU+MMF+FK506 ## 2: Ara-c+CY+IVBu+ATG+Flu+PTCy+PTCy（Ara+Cy+Bu+Flu+PTCy） marrow cleansing PTCY+PTFLU+MMF+FK506 ## 3: ## 4: BUCY marrow cleansing CSA+MTX+MMF+ATG ## 5: BUCY marrow cleansing CSA+MTX+MMF+ATG ## 6: Data Preparation: SummarizedExperiment object Renaming column Replace 9 by NA column with mix prefix are regards as QC samples getSEobject &lt;- function(x, y) { # x = metadata # y = profile # mix : qc samples qc_samples &lt;- grep(&quot;mix&quot;, colnames(profile), value = T) qc_groups &lt;- data.frame(SampleID = qc_samples, V1_outcome = rep(&quot;QC&quot;, length(qc_samples)), SampleName = rep(&quot;SampleName&quot;, length(qc_samples)), FMT_status = rep(&quot;FMT_status&quot;, length(qc_samples)), gender = rep(&quot;gender&quot;, length(qc_samples)), age = rep(&quot;age&quot;, length(qc_samples))) # target table target &lt;- x %&gt;% dplyr::filter(FMT_status != &quot;&quot;) %&gt;% dplyr::mutate(SampleID = paste(SampleName, FMT_status, sep = &quot;_&quot;)) %&gt;% dplyr::select(SampleID, V1_outcome, SampleName, FMT_status, gender, age) %&gt;% rbind(qc_groups) # profile column colnames(y) &lt;- gsub(&quot;-&quot;, &quot;_&quot;, colnames(y)) sid &lt;- intersect(target$SampleID, colnames(y)) features &lt;- y %&gt;% dplyr::select(all_of(sid)) %&gt;% data.frame() %&gt;% t() colnames(features) &lt;- y$Index # replace 9 by NA features[features == 9] &lt;- NA target &lt;- target[pmatch(sid, target$SampleID), , F] res &lt;- PomaSummarizedExperiment(target = target, features = features) return(res) } se_raw &lt;- getSEobject(metadata, profile) se_raw ## class: SummarizedExperiment ## dim: 1235 61 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(1235): MEDL00066 MEDL00356 ... MW0169477 MW0169569 ## rowData names(0): ## colnames(61): CJY_V0 CJY_V1 ... mix06 mix07 ## colData names(5): group SampleName FMT_status gender age 6.3 Data Processing 6.3.1 Data Checking Features in PomaSummarizedExperiment object must have the following criterion: All data values are numeric. A total of 0 (0%) missing values were detected. CheckData &lt;- function(object) { features_tab &lt;- SummarizedExperiment::assay(object) # numeric &amp; missing values int_mat &lt;- features_tab rowNms &lt;- rownames(int_mat) colNms &lt;- colnames(int_mat) naNms &lt;- sum(is.na(int_mat)) for (i in 1:ncol(int_mat)) { if (class(int_mat[, i]) == &quot;integer64&quot;) { int_mat[, i] &lt;- as.double(int_mat[, i]) } } num_mat &lt;- apply(int_mat, 2, as.numeric) if (sum(is.na(num_mat)) &gt; naNms) { num_mat &lt;- apply(int_mat, 2, function(x) as.numeric(gsub(&quot;,&quot;, &quot;&quot;, x))) if (sum(is.na(num_mat)) &gt; naNms) { message(&quot;&lt;font color=\\&quot;red\\&quot;&gt;Non-numeric values were found and replaced by NA.&lt;/font&gt;&quot;) } else { message(&quot;All data values are numeric.&quot;) } } else { message(&quot;All data values are numeric.&quot;) } int_mat &lt;- num_mat rownames(int_mat) &lt;- rowNms colnames(int_mat) &lt;- colNms varCol &lt;- apply(int_mat, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;&lt;font color=\\&quot;red\\&quot;&gt;&quot;, constNum, &quot;features with a constant or single value across samples were found and deleted.&lt;/font&gt;&quot;)) int_mat &lt;- int_mat[, !constCol, drop = FALSE] } totalCount &lt;- nrow(int_mat) * ncol(int_mat) naCount &lt;- sum(is.na(int_mat)) naPercent &lt;- round(100 * naCount/totalCount, 1) message(paste(&quot;A total of &quot;, naCount, &quot; (&quot;, naPercent, &quot;%) missing values were detected.&quot;, sep = &quot;&quot;)) # save int_mat into se object target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = t(int_mat)) return(res) } se_check &lt;- CheckData(object = se_raw) se_check ## class: SummarizedExperiment ## dim: 1235 61 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(1235): MEDL00066 MEDL00356 ... MW0169477 MW0169569 ## rowData names(0): ## colnames(61): CJY_V0 CJY_V1 ... mix06 mix07 ## colData names(5): group SampleName FMT_status gender age 6.3.2 Missing value imputation “none”: all missing values will be replaced by zero. “LOD”: specific Limit Of Detection which provides by user. “half_min”: half minimal values across samples except zero. “median”: median values across samples except zero. “mean”: mean values across samples except zero. “min”: minimal values across samples except zero. “knn”: k-nearest neighbors samples. “rf”: nonparametric missing value imputation using Random Forest. “QRILC”: missing values imputation based quantile regression. (default: “none”). impute_abundance &lt;- function( object, group, ZerosAsNA = FALSE, RemoveNA = TRUE, prevalence = 0.5, method = c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;), LOD = NULL) { # object = se_check # group = &quot;group&quot; # ZerosAsNA = TRUE # RemoveNA = TRUE # prevalence = 0.5 # method = &quot;knn&quot; if (base::missing(object)) { stop(&quot;object argument is empty!&quot;) } if (!methods::is(object, &quot;SummarizedExperiment&quot;)) { stop(&quot;object is not either a phyloseq or SummarizedExperiment object.&quot;) } method &lt;- match.arg( method, c(&quot;none&quot;, &quot;LOD&quot;, &quot;half_min&quot;, &quot;median&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;knn&quot;, &quot;rf&quot;, &quot;QRILC&quot;) ) if (base::missing(method)) { message(&quot;method argument is empty! KNN will be used&quot;) } # profile: row-&gt;samples; col-&gt;features if (all(!is.null(object), inherits(object, &quot;SummarizedExperiment&quot;))) { # sample table &amp; profile table sam_tab &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;TempRowNames&quot;) prf_tab &lt;- SummarizedExperiment::assay(object) %&gt;% data.frame() %&gt;% t() } group_index &lt;- which(colnames(sam_tab) == group) samples_groups &lt;- sam_tab[, group_index] to_imp_data &lt;- prf_tab %&gt;% as.matrix() if (ZerosAsNA) { to_imp_data[to_imp_data == 0] &lt;- NA to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } else { to_imp_data &lt;- data.frame(cbind(Group = samples_groups, to_imp_data)) colnames(to_imp_data)[2:ncol(to_imp_data)] &lt;- colnames(prf_tab) } percent_na &lt;- sum(is.na(to_imp_data)) if (percent_na == 0) { message(&quot;No missing values detected in your data&quot;) if (method != &quot;none&quot;) { method &lt;- &quot;none&quot; } } if (isTRUE(RemoveNA)) { count_NA &lt;- stats::aggregate( . ~ Group, data = to_imp_data, function(x) {(sum(is.na(x)) / (sum(is.na(x)) + sum(!is.na(x))) ) }, na.action = NULL) count_NA &lt;- count_NA %&gt;% dplyr::select(-Group) correct_names &lt;- names(count_NA) supress &lt;- unlist(as.data.frame(lapply(count_NA, function(x) any(x &gt; prevalence)))) names(supress) &lt;- correct_names correct_names &lt;- names(supress[supress == &quot;FALSE&quot;]) depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)][!supress] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) } else { depurdata &lt;- to_imp_data[, 2:ncol(to_imp_data)] depurdata &lt;- sapply(depurdata, function(x) as.numeric(as.character(x))) correct_names &lt;- colnames(prf_tab) } # Row-&gt;feature;Col-&gt;sample if (method == &quot;none&quot;) { depurdata[is.na(depurdata)] &lt;- 0 } else if (method == &quot;LOD&quot;) { if (is.null(LOD)) { message(&quot;No LOD provided, regard one-tenth mininal value as LOD&quot;) depurdata_withoutNA &lt;- depurdata[!is.na(depurdata)] LOD &lt;- min(depurdata_withoutNA[depurdata_withoutNA != 0]) / 10 } depurdata[is.na(depurdata)] &lt;- LOD depurdata[depurdata == 0] &lt;- LOD } else if (method == &quot;half_min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE)/2, x) else x}) } else if (method == &quot;median&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), median(x, na.rm = TRUE), x) else x}) } else if (method == &quot;mean&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), mean(x, na.rm = TRUE), x) else x}) } else if (method == &quot;min&quot;) { depurdata &lt;- apply(depurdata, 2, function(x) { if(is.numeric(x)) ifelse(is.na(x), min(x, na.rm = TRUE), x) else x}) } else if (method == &quot;knn&quot;) { depurdata &lt;- t(depurdata) datai &lt;- impute::impute.knn(depurdata, k = 20) depurdata &lt;- t(datai$data) } else if (method == &quot;rf&quot;) { fit &lt;- missForest::missForest(t(depurdata)) depurdata &lt;- fit$ximp %&gt;% t() } else if (method == &quot;QRILC&quot;) { fit &lt;- log(t(depurdata)) %&gt;% imputeLCMD::impute.QRILC() depurdata &lt;- t(fit[[1]]) } colnames(depurdata) &lt;- correct_names rownames(depurdata) &lt;- rownames(prf_tab) if (methods::is(object, &quot;SummarizedExperiment&quot;)) { target &lt;- SummarizedExperiment::colData(object) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;SampleID&quot;) res &lt;- PomaSummarizedExperiment(target = target, features = depurdata) } return(res) } se_impute &lt;- impute_abundance( se_check, group = &quot;group&quot;, ZerosAsNA = TRUE, RemoveNA = TRUE, prevalence = 0.5, method = &quot;knn&quot;) se_impute ## class: SummarizedExperiment ## dim: 978 61 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(978): MEDL00066 MEDL00356 ... MW0168866 MW0169569 ## rowData names(0): ## colnames(61): CJY_V0 CJY_V1 ... mix06 mix07 ## colData names(5): group SampleName FMT_status gender age # profile head(SummarizedExperiment::assay(se_impute)) ## CJY_V0 CJY_V1 DGL_V0 DGL_V1 HXZ_V0 HXZ_V1 LBC_V0 LBC_V1 LHC_V1 LHC_V0 LHR_V0 LHR_V1 LJD_V0 LJD_V1 ## MEDL00066 10447.00 4011900.00 560560 149120.00 442540 181010.00 12620.0 173400.00 97848.0 7682.475 744910.00 95554.00 29999 65406.0 ## MEDL00356 50530.92 38175.58 71717 128990.00 162090 106800.00 8524300.0 61881.00 88503.0 21030.000 32277.89 28348.57 30666 34586.0 ## MEDL00369 40739.79 85573.00 36339 50110.28 135600 26164.00 7287.5 11808.00 86864.6 34776.883 39771.74 34645.75 52056 17594.0 ## MEDL00375 31087.00 88306.00 449150 263050.00 216830 37280.00 302150.0 607850.00 87101.0 7595.700 3162900.00 83160.00 293680 80921.0 ## MEDL00392 238370.00 260320.00 250350 21585.00 480800 91366.73 225860.0 53617.11 809940.0 9993.000 964380.00 65519.00 99231 5760.1 ## MEDL00401 12589.00 12590.00 15954 16425.00 14961 8432.20 16545.0 9618.60 20929.0 12400.000 17539.00 10249.00 13183 12489.0 ## LJY_V0 LJY_V1 LPQ_V0 LPQ_V1 LQB_V1 LQB_V0 LWJ2_V0 LWJ2_V1 LWL_V1 LWL_V0 LXH_V0 LXH_V1 MZH_V0 MZH_V1 SZP_V0 ## MEDL00066 321900 5065100 363640.0 464980 5664000 6312.7 131810.0 262810.0 4501100.0 786330.0 342390 13018.0 1351000.00 2677700.0 574420 ## MEDL00356 48010 20193 14003.0 1818200 65151 37127.0 23929.0 17193.0 15555.0 182650.0 277870 121210.8 27022.93 53654.0 90642 ## MEDL00369 17115 27850 5519.3 110600 13576 5116.1 175290.0 122980.0 55525.0 8868.3 48983 10114.0 33974.00 9057.1 112340 ## MEDL00375 75261 39253 127590.0 96760 166800 69780.0 244030.0 174640.0 77431.0 227830.0 55610 19619.0 291990.00 31441.0 524740 ## MEDL00392 223600 37209 679940.0 467250 16911 10461.0 123994.5 125642.8 5700.4 10468.0 52219 25862.0 88710.00 1032412.4 42641 ## MEDL00401 12513 10672 17804.0 15920 10570 14307.0 12191.0 12257.0 11169.0 16478.0 13150 9346.6 10180.00 4854.2 15582 ## SZP_V1 TZW_V0 TZW_V1 WJH_V0 WJH_V1 WKM_V0 WKM_V1 WL_V0 WL_V1 XD_V0 XD_V1 XQ_V0 XQ_V1 YF_V1 YF_V0 ## MEDL00066 137160 562570.00 10292000 365240 48338 226940 2036500 124550.00 128280.00 1742800 137230.0 257980.00 88932.00 13412.00 12427 ## MEDL00356 77216 39512.75 22893 21026 38348 20400 23115 54844.55 232230.00 32944 243850.0 119550.00 57710.00 35455.33 19786 ## MEDL00369 56780 80875.26 48794 211510 32971 85272 44528 9265.80 42110.64 422050 15741.0 44267.07 46179.76 34615.38 17800 ## MEDL00375 537650 121470.00 431950 90307 81435 205780 140470 135240.00 220610.00 290030 233800.0 53591.00 70224.00 21049.00 202080 ## MEDL00392 32157 993620.00 31457 23587 19511 312710 107940 39497.38 39986.00 113640 19644.0 46579.00 44633.00 19111.00 156870 ## MEDL00401 13955 15942.00 13843 15067 16507 13660 12523 12381.00 11528.00 10740 8921.5 7834.50 11835.00 13978.00 11395 ## ZCY_V1 ZCY_V0 ZHP_V0 ZHP_V1 ZJW_V1 ZJW_V0 ZTX1_V1 ZTX1_V0 ZTX2_V0 ZTX2_V1 mix01 mix02 mix03 ## MEDL00066 121830.0 859300.0 1908600.00 2960800.00 803940.00 498920.00 22789.0 12131.0 74144.00 378000.00 1042600 1159400 1167400 ## MEDL00356 260550.0 89027.0 94463.00 64879.00 20510.52 35318.84 84165.0 13540.0 33362.67 58783.00 314180 288500 279550 ## MEDL00369 39220.0 52984.0 37201.74 50596.39 13670.00 29996.22 4734.5 8474.4 65541.00 35292.96 33037 37579 29471 ## MEDL00375 1038100.0 782630.0 738020.00 609040.00 1744600.00 993080.00 794930.0 111690.0 50044.00 2155000.00 436160 428120 453000 ## MEDL00392 101906.1 105220.8 56996.37 84620.86 79583.00 72859.00 80132.8 48640.0 203680.00 236080.00 183070 196370 206210 ## MEDL00401 13510.0 15545.0 16938.00 17509.00 11082.00 14200.00 27791.0 12716.0 17282.00 13456.00 11124 11093 11136 ## mix04 mix05 mix06 mix07 ## MEDL00066 981970 912960 1092400 1106700 ## MEDL00356 265550 276420 299290 291510 ## MEDL00369 36386 35111 35431 37024 ## MEDL00375 490780 373010 499630 474080 ## MEDL00392 195750 191210 169370 134860 ## MEDL00401 11020 11076 11432 12582 6.3.3 Data Filtering FilterFeature &lt;- function( object, qc_label, method = c(&quot;none&quot;, &quot;iqr&quot;, &quot;rsd&quot;, &quot;nrsd&quot;, &quot;mean&quot;, &quot;sd&quot;, &quot;mad&quot;, &quot;median&quot;), rsd_cutoff = 25) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) # QC samples qc_samples &lt;- metadata_tab %&gt;% data.frame() %&gt;% dplyr::filter(group == qc_label) if (dim(qc_samples)[1] == 0) { stop(&quot;No qc samples have been chosen, please check your input&quot;) } # QC samples&#39; feature table qc_feature &lt;- features_tab[, colnames(features_tab) %in% rownames(qc_samples)] %&gt;% t() # filter features by QC RSD rsd &lt;- rsd_cutoff / 100 sds &lt;- apply(qc_feature, 2, sd, na.rm = T) mns &lt;- apply(qc_feature, 2, mean, na.rm = T) rsd_vals &lt;- abs(sds/mns) %&gt;% na.omit() gd_inx &lt;- rsd_vals &lt; rsd int_mat &lt;- features_tab[gd_inx, ] message(&quot;Removed &quot;, (dim(qc_feature)[2] - dim(int_mat)[1]), &quot; features based on QC RSD values. QC samples are excluded from downstream functional analysis.&quot;) # whether to filter features by percentage according to the number PerformFeatureFilter &lt;- function(datMatrix, qc_method = method, remain_num = NULL) { dat &lt;- datMatrix feat_num &lt;- ncol(dat) feat_nms &lt;- colnames(dat) nm &lt;- NULL if (qc_method == &quot;none&quot; &amp;&amp; feat_num &lt; 5000) { # only allow for less than 4000 remain &lt;- rep(TRUE, feat_num) nm &lt;- &quot;No filtering was applied&quot; } else { if (qc_method == &quot;rsd&quot;){ sds &lt;- apply(dat, 2, sd, na.rm = T) mns &lt;- apply(dat, 2, mean, na.rm = T) filter_val &lt;- abs(sds/mns) nm &lt;- &quot;Relative standard deviation&quot; } else if (qc_method == &quot;nrsd&quot; ) { mads &lt;- apply(dat, 2, mad, na.rm = T) meds &lt;- apply(dat, 2, median, na.rm = T) filter_val &lt;- abs(mads/meds) nm &lt;- &quot;Non-paramatric relative standard deviation&quot; } else if (qc_method == &quot;mean&quot;) { filter_val &lt;- apply(dat, 2, mean, na.rm = T) nm &lt;- &quot;mean&quot; } else if (qc_method == &quot;sd&quot;) { filter_val &lt;- apply(dat, 2, sd, na.rm = T) nm &lt;- &quot;standard deviation&quot; } else if (qc_method == &quot;mad&quot;) { filter_val &lt;- apply(dat, 2, mad, na.rm = T) nm &lt;- &quot;Median absolute deviation&quot; } else if (qc_method == &quot;median&quot;) { filter_val &lt;- apply(dat, 2, median, na.rm = T) nm &lt;- &quot;median&quot; } else if (qc_method == &quot;iqr&quot;) { # iqr filter_val &lt;- apply(dat, 2, IQR, na.rm = T) nm &lt;- &quot;Interquantile Range&quot; } # get the rank of the filtered variables rk &lt;- rank(-filter_val, ties.method = &quot;random&quot;) if (is.null(remain_num)) { # apply empirical filtering based on data size if (feat_num &lt; 250) { # reduce 5% remain &lt;- rk &lt; feat_num * 0.95 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 500) { # reduce 10% remain &lt;- rk &lt; feat_num * 0.9 message(&quot;Further feature filtering based on &quot;, nm) } else if (feat_num &lt; 1000) { # reduce 25% remain &lt;- rk &lt; feat_num * 0.75 message(&quot;Further feature filtering based on &quot;, nm) } else { # reduce 40%, if still over 5000, then only use top 5000 remain &lt;- rk &lt; feat_num * 0.6 message(&quot;Further feature filtering based on &quot;, nm) } } else { remain &lt;- rk &lt; remain_num } } res &lt;- datMatrix[, remain] return(res) } feature_res &lt;- PerformFeatureFilter(t(int_mat)) # remove QC samples feature_final &lt;- feature_res[!rownames(feature_res) %in% rownames(qc_samples), ] # save int_mat into se object target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID %in% rownames(feature_final)) res &lt;- PomaSummarizedExperiment(target = target, features = feature_final) return(res) } se_filter &lt;- FilterFeature(object = se_impute, qc_label = &quot;QC&quot;, method = &quot;iqr&quot;) se_filter ## class: SummarizedExperiment ## dim: 705 54 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(705): MEDL00066 MEDL00375 ... MW0168376 MW0169569 ## rowData names(0): ## colnames(54): CJY_V0 CJY_V1 ... ZTX2_V0 ZTX2_V1 ## colData names(5): group SampleName FMT_status gender age 6.3.4 Data Normalization 6.3.4.1 Normalization by NormalizeData function NormalizeData &lt;- function( object, rowNorm = c(&quot;Quantile&quot;, &quot;GroupPQN&quot;, &quot;SamplePQN&quot;, &quot;CompNorm&quot;, &quot;SumNorm&quot;, &quot;MedianNorm&quot;, &quot;SpecNorm&quot;, &quot;None&quot;), transNorm = c(&quot;LogNorm&quot;, &quot;SrNorm&quot;, &quot;CrNorm&quot;, &quot;None&quot;), scaleNorm = c(&quot;MeanCenter&quot;, &quot;AutoNorm&quot;, &quot;ParetoNorm&quot;, &quot;RangeNorm&quot;, &quot;None&quot;), ref = NULL, SpeWeight = 1) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) data &lt;- t(features_tab) colNames &lt;- colnames(data) rowNames &lt;- rownames(data) ############################################# # Sample normalization # perform quantile normalization on the raw data (can be log transformed later by user) QuantileNormalize &lt;- function(data) { return(t(preprocessCore::normalize.quantiles(t(data), copy=FALSE))); } # normalize by a reference sample (probability quotient normalization) # ref should be the name of the reference sample ProbNorm &lt;- function(x, ref_smpl) { return(x/median(as.numeric(x/ref_smpl), na.rm = T)) } # normalize by a reference reference (i.e. creatinine) # ref should be the name of the cmpd CompNorm &lt;- function(x, ref) { return(1000*x/x[ref]) } SumNorm &lt;- function(x) { return(1000*x/sum(x, na.rm = T)) } # normalize by median MedianNorm &lt;- function(x) { return(x/median(x, na.rm = T)) } # row-wise normalization if (rowNorm == &quot;Quantile&quot;) { data &lt;- QuantileNormalize(data) # this can introduce constant variables if a variable is # at the same rank across all samples (replaced by its average across all) varCol &lt;- apply(data, 2, var, na.rm = T) constCol &lt;- (varCol == 0 | is.na(varCol)) constNum &lt;- sum(constCol, na.rm = T) if (constNum &gt; 0) { message(paste(&quot;After quantile normalization&quot;, constNum, &quot;features with a constant value were found and deleted.&quot;)) data &lt;- data[, !constCol, drop = FALSE] colNames &lt;- colnames(data) rowNames &lt;- rownames(data) } rownm &lt;- &quot;Quantile Normalization&quot; } else if (rowNorm == &quot;GroupPQN&quot;) { grp_inx &lt;- metadata_tab$group == ref ref.smpl &lt;- apply(data[grp_inx, , drop = FALSE], 2, mean) data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference group&quot; } else if (rowNorm == &quot;SamplePQN&quot;) { ref.smpl &lt;- data[ref, , drop = FALSE] data &lt;- t(apply(data, 1, ProbNorm, ref.smpl)) rownm &lt;- &quot;Probabilistic Quotient Normalization by a reference sample&quot; } else if (rowNorm == &quot;CompNorm&quot;) { data &lt;- t(apply(t(data), 1, CompNorm, ref)) rownm &lt;- &quot;Normalization by a reference feature&quot;; } else if (rowNorm == &quot;SumNorm&quot;) { data &lt;- t(apply(data, 1, SumNorm)) rownm &lt;- &quot;Normalization to constant sum&quot; } else if (rowNorm == &quot;MedianNorm&quot;) { data &lt;- t(apply(data, 1, MedianNorm)) rownm &lt;- &quot;Normalization to sample median&quot; } else if(rowNorm == &quot;SpecNorm&quot;) { norm.vec &lt;- rep(SpeWeight, nrow(data)) # default all same weight vec to prevent error data &lt;- data / norm.vec message(&quot;No sample specific information were given, all set to 1.0&quot;) rownm &lt;- &quot;Normalization by sample-specific factor&quot; } else { # nothing to do rownm &lt;- &quot;N/A&quot; } ################################################ # use apply will lose dimension info (i.e. row names and colnames) rownames(data) &lt;- rowNames colnames(data) &lt;- colNames # if the reference by feature, the feature column should be removed, since it is all 1 if(rowNorm == &quot;CompNorm&quot; &amp;&amp; !is.null(ref)){ inx &lt;- match(ref, colnames(data)) data &lt;- data[, -inx, drop=FALSE] colNames &lt;- colNames[-inx] } ############################################# # Data transformation # generalize log, tolerant to 0 and negative values LogNorm &lt;- function(x, min.val) { return(log10((x + sqrt(x^2 + min.val^2))/2)) } # square root, tolerant to negative values SquareRootNorm &lt;- function(x, min.val) { return(((x + sqrt(x^2 + min.val^2))/2)^(1/2)) } if (transNorm == &quot;LogNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, LogNorm, min.val) transnm &lt;- &quot;Log10 Normalization&quot; } else if (transNorm == &quot;SrNorm&quot;) { min.val &lt;- min(abs(data[data != 0]))/10 data &lt;- apply(data, 2, SquareRootNorm, min.val) transnm &lt;- &quot;Square Root Transformation&quot; } else if (transNorm == &quot;CrNorm&quot;) { norm.data &lt;- abs(data)^(1/3) norm.data[data &lt; 0] &lt;- -norm.data[data &lt; 0] data &lt;- norm.data transnm &lt;- &quot;Cubic Root Transformation&quot; } else { transnm &lt;- &quot;N/A&quot; } ############################################# ############################################# # Data scaling # normalize to zero mean and unit variance AutoNorm &lt;- function(x) { return((x - mean(x))/sd(x, na.rm = T)) } # normalize to zero mean but variance/SE ParetoNorm &lt;- function(x) { return((x - mean(x))/sqrt(sd(x, na.rm = T))) } # normalize to zero mean but variance/SE MeanCenter &lt;- function(x) { return(x - mean(x)) } # normalize to zero mean but variance/SE RangeNorm &lt;- function(x) { if (max(x) == min(x)) { return(x) } else { return((x - mean(x))/(max(x) - min(x))) } } if (scaleNorm == &quot;MeanCenter&quot;) { data &lt;- apply(data, 2, MeanCenter) scalenm &lt;- &quot;Mean Centering&quot; } else if (scaleNorm == &quot;AutoNorm&quot;) { data &lt;- apply(data, 2, AutoNorm) scalenm &lt;- &quot;Autoscaling&quot; } else if (scaleNorm == &quot;ParetoNorm&quot;) { data &lt;- apply(data, 2, ParetoNorm) scalenm &lt;- &quot;Pareto Scaling&quot; } else if (scaleNorm == &quot;RangeNorm&quot;) { data &lt;- apply(data, 2, RangeNorm) scalenm &lt;- &quot;Range Scaling&quot; } else { scalenm &lt;- &quot;N/A&quot; } ############################################# message(&quot;Row norm: &quot;, rownm, &quot;\\n&quot;, &quot;Data Transformation norm: &quot;, transnm, &quot;\\n&quot;, &quot;Data Scaling norm: &quot;, scalenm, &quot;\\n&quot;) # note after using &quot;apply&quot; function, all the attribute lost, need to add back rownames(data) &lt;- rowNames colnames(data) &lt;- colNames target &lt;- metadata_tab %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;SampleID&quot;) %&gt;% dplyr::filter(SampleID%in%rownames(data)) se &lt;- PomaSummarizedExperiment(target = target, features = data) # need to do some sanity check, for log there may be Inf values introduced res &lt;- CheckData(se) return(res) } se_normalize &lt;- NormalizeData( object = se_impute, rowNorm = &quot;None&quot;, transNorm = &quot;LogNorm&quot;, scaleNorm = &quot;ParetoNorm&quot;) se_normalize ## class: SummarizedExperiment ## dim: 978 61 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(978): MEDL00066 MEDL00356 ... MW0168866 MW0169569 ## rowData names(0): ## colnames(61): CJY_V0 CJY_V1 ... mix06 mix07 ## colData names(5): group SampleName FMT_status gender age 6.3.4.2 Normalization by POMA R package se_normalize_v2 &lt;- PomaNorm(se_impute, method = &quot;log_pareto&quot;) se_normalize_v2 ## class: SummarizedExperiment ## dim: 978 61 ## metadata(0): ## assays(1): &#39;&#39; ## rownames(978): MEDL00066 MEDL00356 ... MW0168866 MW0169569 ## rowData names(0): ## colnames(61): CJY_V0 CJY_V1 ... mix06 mix07 ## colData names(5): group SampleName FMT_status gender age 6.3.4.3 Comparison of unnormalized and normalized dataset boxplot pl_unnor &lt;- PomaBoxplots(se_impute, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaBoxplots(se_normalize, group = &quot;samples&quot;, jitter = FALSE) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) density pl_unnor &lt;- PomaDensity(se_impute, group = &quot;features&quot;) + ggtitle(&quot;Not Normalized&quot;) + theme(legend.position = &quot;none&quot;) # data before normalization pl_nor &lt;- PomaDensity(se_normalize, group = &quot;features&quot;) + ggtitle(&quot;Normalized&quot;) # data after normalization cowplot::plot_grid(pl_unnor, pl_nor, ncol = 1, align = &quot;v&quot;) 6.4 Cluster Analysis 6.4.1 Hierarchical Clustering HieraCluster &lt;- function(object, method_dis = c(&quot;euclidean&quot;, &quot;bray&quot;), method_cluster = c(&quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;, &quot;ward.D2&quot;), cluster_type = c(&quot;Agglomerative&quot;, &quot;Divisive&quot;), tree_num = 4) { features_tab &lt;- SummarizedExperiment::assay(object) metadata_tab &lt;- SummarizedExperiment::colData(object) df &lt;- t(features_tab) if (cluster_type == &quot;Agglomerative&quot;) { # Agglomerative Hierarchical Clustering # Dissimilarity matrix d &lt;- dist(df, method = method_dis) # Hierarchical clustering using Linkage method hc &lt;- hclust(d, method = method_cluster) # hc &lt;- agnes(df, method = method_cluster) ####### identifying the strongest clustering structure ################ # # methods to assess # m &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;) # names(m) &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward&quot;) # # # function to compute coefficient # ac &lt;- function(x) { # agnes(df, method = x)$ac # } # # map_dbl(m, ac) } else if (cluster_type == &quot;Divisive&quot;) { # Divisive Hierarchical Clustering hc &lt;- diana(df, metric = method_dis) } hc_res &lt;- as.hclust(hc) sub_grp &lt;- cutree(hc_res, k = tree_num) plot(hc_res, cex = 0.6) rect.hclust(hc_res, k = tree_num, border = 2:(tree_num+1)) res &lt;- list(data=df, cluster=sub_grp, hc=hc_res) return(res) } Calculation Agg_hc_res &lt;- HieraCluster( object = se_normalize, method_dis = &quot;euclidean&quot;, method_cluster = &quot;ward.D2&quot;, cluster_type = &quot;Agglomerative&quot;, tree_num = 3) Visualization: visualize the result in a scatter plot fviz_cluster(list(data = Agg_hc_res$data, cluster = Agg_hc_res$cluster)) 6.5 Chemometrics Analysis 6.5.1 Partial Least Squares-Discriminant Analysis (PLS-DA) Calculation poma_plsda &lt;- PomaMultivariate(se_normalize, method = &quot;plsda&quot;) scatter plot poma_plsda$scoresplot + ggtitle(&quot;Scores Plot (plsda)&quot;) errors plot poma_plsda$errors_plsda_plot + ggtitle(&quot;Error Plot (plsda)&quot;) 6.5.2 Sparse Partial Least Squares-Discriminant Analysis (sPLS-DA) Even though PLS is highly efficient in a high dimensional context, the interpretability of PLS needed to be improved. sPLS has been recently developed by our team to perform simultaneous variable selection in both data sets X and Y data sets, by including LASSO penalizations in PLS on each pair of loading vectors Calculation poma_splsda &lt;- PomaMultivariate(se_normalize, method = &quot;splsda&quot;) scatter plot poma_splsda$scoresplot + ggtitle(&quot;Scores Plot (splsda)&quot;) 6.6 Univariate Analysis 6.6.1 Fold Change Analysis RawData (inputed data) FoldChange &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } fc_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) mn &lt;- tapply(dat$value, dat$group, function(x){ mean(x, na.rm = TRUE) }) %&gt;% as.data.frame() %&gt;% stats::setNames(&quot;value&quot;) %&gt;% tibble::rownames_to_column(&quot;Group&quot;) mn1 &lt;- with(mn, mn[Group %in% group_names[1], &quot;value&quot;]) mn2 &lt;- with(mn, mn[Group %in% group_names[2], &quot;value&quot;]) mnall &lt;- mean(dat$value, na.rm = TRUE) if (all(mn1 != 0, mn2 != 0)) { fc &lt;- mn1 / mn2 } else { fc &lt;- NA } logfc &lt;- log2(fc) res &lt;- c(fc, logfc, mnall, mn1, mn2) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(fc_res) &lt;- c(&quot;FeatureID&quot;, &quot;FoldChange&quot;, &quot;Log2FoldChange&quot;, &quot;Mean Abundance\\n(All)&quot;, paste0(&quot;Mean Abundance\\n&quot;, c(&quot;former&quot;, &quot;latter&quot;))) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) fc_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- fc_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } fc_res &lt;- FoldChange( x = se_impute, group = &quot;group&quot;, group_names = c(&quot;NR&quot;, &quot;PR&quot;)) head(fc_res) ## FeatureID Block FoldChange Log2FoldChange Mean Abundance\\n(All) Mean Abundance\\nformer Mean Abundance\\nlatter ## 1 MEDL00066 22_NR vs 22_PR 0.3725103 -1.42464778 884972.39 480377.20 1289567.58 ## 2 MEDL00356 22_NR vs 22_PR 0.2998209 -1.73782728 296756.21 136901.49 456610.93 ## 3 MEDL00369 22_NR vs 22_PR 0.8976511 -0.15577325 57818.66 54700.24 60937.08 ## 4 MEDL00375 22_NR vs 22_PR 1.1237471 0.16831736 391121.42 413911.40 368331.45 ## 5 MEDL00392 22_NR vs 22_PR 1.6597914 0.73100193 169984.74 212151.38 127818.10 ## 6 MEDL00401 22_NR vs 22_PR 0.9665848 -0.04903182 13670.47 13438.19 13902.75 6.6.2 VIP (Variable influence on projection &amp; coefficient) Variable influence on projection (VIP) for orthogonal projections to latent structures (OPLS) Variable influence on projection (VIP) for projections to latent structures (PLS) VIP_fun &lt;- function( x, group, group_names, VIPtype = c(&quot;OPLS&quot;, &quot;PLS&quot;), vip_cutoff = 1) { metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } dataMatrix &lt;- prof %&gt;% base::t() # row-&gt;sampleID; col-&gt;features sampleMetadata &lt;- phen # row-&gt;sampleID; col-&gt;features comparsionVn &lt;- sampleMetadata[, &quot;CompVar&quot;] # corrlation between group and features pvaVn &lt;- apply(dataMatrix, 2, function(feaVn) cor.test(as.numeric(comparsionVn), feaVn)[[&quot;p.value&quot;]]) library(ropls) if (VIPtype == &quot;OPLS&quot;) { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, orthoI = NA, fig.pdfC = &quot;none&quot;)) } else { vipVn &lt;- getVipVn(opls(dataMatrix, comparsionVn, predI = 1, fig.pdfC = &quot;none&quot;)) } quantVn &lt;- qnorm(1 - pvaVn / 2) rmsQuantN &lt;- sqrt(mean(quantVn^2)) opar &lt;- par(font = 2, font.axis = 2, font.lab = 2, las = 1, mar = c(5.1, 4.6, 4.1, 2.1), lwd = 2, pch = 16) plot(pvaVn, vipVn, col = &quot;red&quot;, pch = 16, xlab = &quot;p-value&quot;, ylab = &quot;VIP&quot;, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;) box(lwd = 2) curve(qnorm(1 - x / 2) / rmsQuantN, 0, 1, add = TRUE, col = &quot;red&quot;, lwd = 3) abline(h = 1, col = &quot;blue&quot;) abline(v = 0.05, col = &quot;blue&quot;) res_temp &lt;- data.frame( FeatureID = names(vipVn), VIP = vipVn, CorPvalue = pvaVn) %&gt;% dplyr::arrange(desc(VIP)) vip_select &lt;- res_temp %&gt;% dplyr::filter(VIP &gt; vip_cutoff) pl &lt;- ggplot(vip_select, aes(FeatureID, VIP)) + geom_segment(aes(x = FeatureID, xend = FeatureID, y = 0, yend = VIP)) + geom_point(shape = 21, size = 5, color = &#39;#008000&#39; ,fill = &#39;#008000&#39;) + geom_point(aes(1,2.5), color = &#39;white&#39;) + geom_hline(yintercept = 1, linetype = &#39;dashed&#39;) + scale_y_continuous(expand = c(0, 0)) + labs(x = &#39;&#39;, y = &#39;VIP value&#39;) + theme_bw() + theme(legend.position = &#39;none&#39;, legend.text = element_text(color = &#39;black&#39;,size = 12, family = &#39;Arial&#39;, face = &#39;plain&#39;), panel.background = element_blank(), panel.grid = element_blank(), axis.text = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.text.x = element_text(angle = 90), axis.title = element_text(color = &#39;black&#39;,size = 15, family = &#39;Arial&#39;, face = &#39;plain&#39;), axis.ticks = element_line(color = &#39;black&#39;), axis.ticks.x = element_blank()) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) res_temp$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res_df &lt;- res_temp %&gt;% dplyr::select(FeatureID, Block, everything()) res &lt;- list(vip = res_df, plot = pl) return(res) } vip_res &lt;- VIP_fun( x = se_normalize, group = &quot;group&quot;, group_names = c(&quot;NR&quot;, &quot;PR&quot;), VIPtype = &quot;PLS&quot;, vip_cutoff = 1) ## PLS-DA ## 44 samples x 978 variables and 1 response ## standard scaling of predictors and response(s) ## R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2 ## Total 0.101 0.483 0.048 0.368 1 0 0.75 0.2 head(vip_res$vip) ## FeatureID Block VIP CorPvalue ## MEDP0151 MEDP0151 22_NR vs 22_PR 2.903799 0.0001855852 ## MEDP1276 MEDP1276 22_NR vs 22_PR 2.903799 0.0001855852 ## MEDP1177 MEDP1177 22_NR vs 22_PR 2.885603 0.0002072022 ## MEDP1040 MEDP1040 22_NR vs 22_PR 2.881680 0.0002121518 ## MW0166596 MW0166596 22_NR vs 22_PR 2.712717 0.0005586171 ## MW0168376 MW0168376 22_NR vs 22_PR 2.673082 0.0006919501 vip_res$plot 6.6.3 T-test by local codes significant differences between two groups (p value) t_fun &lt;- function( x, group, group_names) { # dataseat metadata &lt;- SummarizedExperiment::colData(x) %&gt;% as.data.frame() profile &lt;- SummarizedExperiment::assay(x) %&gt;% as.data.frame() # rename variables colnames(metadata)[which(colnames(metadata) == group)] &lt;- &quot;CompVar&quot; phenotype &lt;- metadata %&gt;% dplyr::filter(CompVar %in% group_names) %&gt;% dplyr::mutate(CompVar = as.character(CompVar)) %&gt;% dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) sid &lt;- intersect(rownames(phenotype), colnames(profile)) phen &lt;- phenotype[pmatch(sid, rownames(phenotype)), , ] prof &lt;- profile %&gt;% dplyr::select(all_of(sid)) if (!all(colnames(prof) == rownames(phen))) { stop(&quot;Wrong Order&quot;) } t_res &lt;- apply(prof, 1, function(x1, y1) { dat &lt;- data.frame(value = as.numeric(x1), group = y1) rest &lt;- t.test(data = dat, value ~ group) res &lt;- c(rest$statistic, rest$p.value) return(res) }, phen$CompVar) %&gt;% base::t() %&gt;% data.frame() %&gt;% tibble::rownames_to_column(&quot;Feature&quot;) colnames(t_res) &lt;- c(&quot;FeatureID&quot;, &quot;Statistic&quot;, &quot;Pvalue&quot;) t_res$AdjustedPvalue &lt;- p.adjust(as.numeric(t_res$Pvalue), method = &quot;BH&quot;) # Number of Group dat_status &lt;- table(phen$CompVar) dat_status_number &lt;- as.numeric(dat_status) dat_status_name &lt;- names(dat_status) t_res$Block &lt;- paste(paste(dat_status_number[1], dat_status_name[1], sep = &quot;_&quot;), &quot;vs&quot;, paste(dat_status_number[2], dat_status_name[2], sep = &quot;_&quot;)) res &lt;- t_res %&gt;% dplyr::select(FeatureID, Block, everything()) return(res) } ttest_res &lt;- t_fun( x = se_normalize, group = &quot;group&quot;, group_names = c(&quot;NR&quot;, &quot;PR&quot;)) head(ttest_res) ## FeatureID Block Statistic Pvalue AdjustedPvalue ## 1 MEDL00066 22_NR vs 22_PR -0.7561238 0.4541166 0.8276388 ## 2 MEDL00356 22_NR vs 22_PR -0.6643555 0.5102652 0.8479872 ## 3 MEDL00369 22_NR vs 22_PR 0.6039380 0.5493194 0.8636438 ## 4 MEDL00375 22_NR vs 22_PR -0.6759149 0.5030887 0.8449287 ## 5 MEDL00392 22_NR vs 22_PR 1.1826181 0.2436510 0.7285392 ## 6 MEDL00401 22_NR vs 22_PR -0.2537679 0.8010020 0.9393045 6.6.4 Merging result Foldchange by Raw Data VIP by Normalized Data test Pvalue by Normalized Data mergedResults &lt;- function( fc_result, vip_result, test_result, group_names, group_labels) { if (is.null(vip_result)) { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } else { mdat &lt;- fc_result %&gt;% dplyr::mutate(Block2 = paste(group_labels, collapse = &quot; vs &quot;)) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)) %&gt;% dplyr::select(-all_of(c(&quot;Mean Abundance\\n(All)&quot;, &quot;Mean Abundance\\nformer&quot;, &quot;Mean Abundance\\nlatter&quot;))) %&gt;% dplyr::inner_join(vip_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) %&gt;% dplyr::inner_join(test_result %&gt;% dplyr::select(-Block) %&gt;% dplyr::mutate(FeatureID = make.names(FeatureID)), by = &quot;FeatureID&quot;) res &lt;- mdat %&gt;% dplyr::select(FeatureID, Block2, Block, FoldChange, Log2FoldChange, VIP, CorPvalue, Statistic, Pvalue, AdjustedPvalue, everything()) %&gt;% dplyr::arrange(AdjustedPvalue, Log2FoldChange) } return(res) } m_results &lt;- mergedResults( fc_result = fc_res, vip_result = vip_res$vip, test_result = ttest_res, group_names = c(&quot;NR&quot;, &quot;PR&quot;), group_labels = c(&quot;NR&quot;, &quot;PR&quot;)) head(m_results) ## FeatureID Block2 Block FoldChange Log2FoldChange VIP CorPvalue Statistic Pvalue AdjustedPvalue ## 1 MEDP0151 NR vs PR 22_NR vs 22_PR 0.06937088 -3.849526 2.903799 0.0001855852 -4.099188 0.0002012845 0.05342607 ## 2 MEDP1276 NR vs PR 22_NR vs 22_PR 0.06937088 -3.849526 2.903799 0.0001855852 -4.099188 0.0002012845 0.05342607 ## 3 MEDP1177 NR vs PR 22_NR vs 22_PR 0.17373447 -2.525044 2.885603 0.0002072022 -4.063360 0.0002078791 0.05342607 ## 4 MEDP1040 NR vs PR 22_NR vs 22_PR 0.25634493 -1.963842 2.881680 0.0002121518 -4.055669 0.0002185115 0.05342607 ## 5 MW0166596 NR vs PR 22_NR vs 22_PR 0.34037949 -1.554784 2.712717 0.0005586171 -3.735517 0.0005936658 0.11612104 ## 6 MW0168376 NR vs PR 22_NR vs 22_PR 0.28801993 -1.795759 2.673082 0.0006919501 -3.663326 0.0007354806 0.11988334 6.6.5 Volcano of Merged Results get_volcano &lt;- function( inputdata, group_names, group_labels, group_colors, x_index, x_cutoff, y_index, y_cutoff, plot = TRUE) { selected_group2 &lt;- paste(group_labels, collapse = &quot; vs &quot;) dat &lt;- inputdata %&gt;% dplyr::filter(Block2 %in% selected_group2) plotdata &lt;- dat %&gt;% dplyr::mutate(FeatureID = paste(FeatureID, sep = &quot;:&quot;)) %&gt;% dplyr::select(all_of(c(&quot;FeatureID&quot;, &quot;Block2&quot;, x_index, y_index))) if (!any(colnames(plotdata) %in% &quot;TaxaID&quot;)) { colnames(plotdata)[1] &lt;- &quot;TaxaID&quot; } if (y_index == &quot;CorPvalue&quot;) { colnames(plotdata)[which(colnames(plotdata) == y_index)] &lt;- &quot;Pvalue&quot; y_index &lt;- &quot;Pvalue&quot; } pl &lt;- plot_volcano( da_res = plotdata, group_names = group_labels, x_index = x_index, x_index_cutoff = x_cutoff, y_index = y_index, y_index_cutoff = y_cutoff, group_color = c(group_colors[1], &quot;grey&quot;, group_colors[2])) if (plot) { res &lt;- pl } else { colnames(plotdata)[which(colnames(plotdata) == x_index)] &lt;- &quot;Xindex&quot; colnames(plotdata)[which(colnames(plotdata) == y_index)] &lt;- &quot;Yindex&quot; datsignif &lt;- plotdata %&gt;% dplyr::filter(abs(Xindex) &gt; x_cutoff) %&gt;% dplyr::filter(Yindex &lt; y_cutoff) colnames(datsignif)[which(colnames(datsignif) == &quot;Xindex&quot;)] &lt;- x_index colnames(datsignif)[which(colnames(datsignif) == &quot;Yindex&quot;)] &lt;- y_index res &lt;- list(figure = pl, data = datsignif) } return(res) } lgfc_FDR_vol &lt;- get_volcano( inputdata = m_results, group_names = c(&quot;NR&quot;, &quot;PR&quot;), group_labels = c(&quot;NR&quot;, &quot;PR&quot;), group_colors = c(&quot;red&quot;, &quot;blue&quot;), x_index = &quot;Log2FoldChange&quot;, x_cutoff = 0.5, y_index = &quot;AdjustedPvalue&quot;, y_cutoff = 0.5, plot = FALSE) lgfc_FDR_vol$figure 6.6.6 T Test group_names &lt;- c(&quot;NR&quot;, &quot;PR&quot;) se_normalize_subset &lt;- se_normalize[, se_normalize$group %in% group_names] se_normalize_subset$group &lt;- factor(as.character(se_normalize_subset$group)) ttest_res &lt;- PomaUnivariate(se_normalize_subset, method = &quot;ttest&quot;) head(ttest_res) ## # A tibble: 6 × 9 ## feature FC diff_means pvalue pvalueAdj mean_NR mean_PR sd_NR sd_PR ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MEDL00066 0.215 0.201 0.454 0.828 -0.255 -0.0548 0.749 0.994 ## 2 MEDL00356 0.309 0.151 0.510 0.848 -0.218 -0.0675 0.665 0.830 ## 3 MEDL00369 -0.936 -0.131 0.549 0.864 0.0676 -0.0633 0.626 0.800 ## 4 MEDL00375 -0.436 0.151 0.503 0.845 -0.105 0.0459 0.838 0.629 ## 5 MEDL00392 -5.65 -0.279 0.244 0.729 0.0419 -0.237 0.811 0.751 ## 6 MEDL00401 1.81 0.024 0.801 0.939 0.0295 0.0533 0.266 0.350 6.6.7 Volcano plot se_impute_subset &lt;- se_impute[, se_impute$group %in% group_names] se_impute_subset$group &lt;- factor(as.character(se_impute_subset$group)) PomaVolcano(se_impute_subset, pval = &quot;raw&quot;, pval_cutoff = 0.05, log2FC = 0.5, xlim = 3, labels = TRUE, plot_title = TRUE) 6.7 Feature Selection 6.7.1 Regularized Generalized Linear Models (Lasso: alpha = 1) lasso_res &lt;- PomaLasso(se_normalize_subset, alpha = 1, labels = TRUE) cowplot::plot_grid(lasso_res$cvLassoPlot, lasso_res$coefficientPlot, ncol = 2, align = &quot;h&quot;) lasso_res$coefficients ## # A tibble: 22 × 2 ## feature coefficient ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) 0.00959 ## 2 MEDN0366 -0.427 ## 3 MEDN0411 -0.0107 ## 4 MEDN0490 -0.316 ## 5 MEDN1135 0.485 ## 6 MEDN1285 -0.00470 ## 7 MEDP0006 0.265 ## 8 MEDP1040 1.71 ## 9 MEDP1170 1.23 ## 10 MEDP1177 1.47 ## # ℹ 12 more rows 6.7.2 Classification (Random Forest) Calculation poma_rf &lt;- PomaRandForest(se_normalize_subset, ntest = 10, nvar = 10) poma_rf$error_tree table poma_rf$confusionMatrix$table ## Reference ## Prediction 1 2 ## 1 1 0 ## 2 1 2 Important features poma_rf$MeanDecreaseGini_plot 6.8 Network Analysis 6.8.1 Data curation features_tab &lt;- SummarizedExperiment::assay(se_filter) %&gt;% t() features_tab[is.na(features_tab)] &lt;- 0 print(features_tab[1:6, 1:10]) ## MEDL00066 MEDL00375 MEDL00392 MEDL00568 MEDL00587 MEDL01764 MEDL01799 MEDL01837 MEDL01844 MEDL01922 ## CJY_V0 10447 31087 238370.00 10248.00 618200 113031.3 335795.7 801660 127250 309560.3 ## CJY_V1 4011900 88306 260320.00 96595.00 563130 233660.0 51267.0 830010 4172100 107560.0 ## DGL_V0 560560 449150 250350.00 78849.00 1079300 109130.2 304040.0 739880 19462000 39149.0 ## DGL_V1 149120 263050 21585.00 44336.38 2047500 277960.0 24342.0 866470 14373000 964600.0 ## HXZ_V0 442540 216830 480800.00 134607.77 1399700 2022600.0 1481800.0 842220 7830000 269570.0 ## HXZ_V1 181010 37280 91366.73 69526.92 1171700 12301.0 166435.5 735560 5171400 196770.0 6.8.2 Building network model net_single &lt;- netConstruct(features_tab, measure = &quot;sparcc&quot;, measurePar = list(iter = 20, inner_iter = 10, th = 0.1), filtTax = &quot;highestVar&quot;, filtTaxPar = list(highestVar = 50), filtSamp = &quot;totalReads&quot;, filtSampPar = list(totalReads = 100), verbose = 3, seed = 123) 6.8.3 Visualizing the network props_single &lt;- netAnalyze(net_single, clustMethod = &quot;cluster_fast_greedy&quot;) plot(props_single, nodeColor = &quot;cluster&quot;, nodeSize = &quot;eigenvector&quot;, repulsion = 0.8, rmSingles = TRUE, labelScale = FALSE, cexLabels = 1.6, nodeSizeSpread = 3, cexNodes = 2, title1 = &quot;Network on metabolomics with Pearson correlations&quot;, showTitle = TRUE, cexTitle = 1.5) legend(0.7, 1.1, cex = 1.2, title = &quot;estimated correlation:&quot;, legend = c(&quot;+&quot;,&quot;-&quot;), lty = 1, lwd = 3, col = c(&quot;#009900&quot;,&quot;red&quot;), bty = &quot;n&quot;, horiz = TRUE) 6.9 Network Analysis by WGCNA Performing Network Analysis step by step through WGCNA R package. 6.9.1 Data curation Data Matrix Row -&gt; metabolites Column -&gt; samples features_tab &lt;- SummarizedExperiment::assay(se_impute) print(features_tab[1:6, 1:10]) ## CJY_V0 CJY_V1 DGL_V0 DGL_V1 HXZ_V0 HXZ_V1 LBC_V0 LBC_V1 LHC_V1 LHC_V0 ## MEDL00066 10447.00 4011900.00 560560 149120.00 442540 181010.00 12620.0 173400.00 97848.0 7682.475 ## MEDL00356 50530.92 38175.58 71717 128990.00 162090 106800.00 8524300.0 61881.00 88503.0 21030.000 ## MEDL00369 40739.79 85573.00 36339 50110.28 135600 26164.00 7287.5 11808.00 86864.6 34776.883 ## MEDL00375 31087.00 88306.00 449150 263050.00 216830 37280.00 302150.0 607850.00 87101.0 7595.700 ## MEDL00392 238370.00 260320.00 250350 21585.00 480800 91366.73 225860.0 53617.11 809940.0 9993.000 ## MEDL00401 12589.00 12590.00 15954 16425.00 14961 8432.20 16545.0 9618.60 20929.0 12400.000 Data normalization # TSS features_tab_norm &lt;- XMAS2::norm_tss(phyloseq::otu_table(features_tab, taxa_are_rows = T)) %&gt;% data.frame() %&gt;% t() print(features_tab_norm[1:6, 1:10]) ## MEDL00066 MEDL00356 MEDL00369 MEDL00375 MEDL00392 MEDL00401 MEDL00404 MEDL00416 MEDL00568 MEDL00587 ## CJY_V0 7.044680e-06 3.407429e-05 2.747189e-05 2.096276e-05 1.607390e-04 8.489085e-06 2.581116e-04 1.401990e-05 6.910489e-06 0.0004168681 ## CJY_V1 1.930100e-03 1.836604e-05 4.116864e-05 4.248347e-05 1.252383e-04 6.056971e-06 9.460709e-06 7.009055e-05 4.647125e-05 0.0002709183 ## DGL_V0 1.373244e-04 1.756903e-05 8.902225e-06 1.100315e-04 6.133003e-05 3.908366e-06 6.912275e-06 6.819184e-06 1.931620e-05 0.0002644038 ## DGL_V1 3.576173e-05 3.093418e-05 1.201737e-05 6.308424e-05 5.176481e-06 3.939018e-06 1.145229e-05 1.549515e-05 1.063268e-05 0.0004910283 ## HXZ_V0 1.046211e-04 3.831977e-05 3.205725e-05 5.126087e-05 1.136661e-04 3.536936e-06 2.507133e-05 6.972689e-06 3.182268e-05 0.0003309037 ## HXZ_V1 5.993074e-05 3.536049e-05 8.662658e-06 1.234306e-05 3.025068e-05 2.791823e-06 2.311676e-06 3.888661e-05 2.301972e-05 0.0003879390 # # CSS # features_tab_norm &lt;- XMAS2::norm_css(phyloseq::otu_table(features_tab, taxa_are_rows = T)) %&gt;% # data.frame() %&gt;% t() # print(features_tab_norm[1:6, 1:10]) 6.9.2 Tuning soft thresholds Picking a threshhold value (if correlation is below threshold, remove the edge). WGCNA will try a range of soft thresholds and create a diagnostic plot. Choose a set of soft-thresholding powers powers &lt;- c(c(1:10), seq(12, 20, 2)) Call the network topology analysis function Row -&gt; samples Column -&gt; metabolites sft &lt;- pickSoftThreshold( features_tab_norm, powerVector = powers, networkType = &quot;unsigned&quot;, verbose = 2) ## pickSoftThreshold: will use block size 978. ## pickSoftThreshold: calculating connectivity for given powers... ## ..working on genes 1 through 978 of 978 ## Power SFT.R.sq slope truncated.R.sq mean.k. median.k. max.k. ## 1 1 0.236 -0.883 0.803 138.00 131.000 228.0 ## 2 2 0.724 -1.560 0.655 40.30 32.500 116.0 ## 3 3 0.820 -1.520 0.787 19.00 12.300 83.3 ## 4 4 0.843 -1.420 0.834 11.70 6.020 66.8 ## 5 5 0.872 -1.350 0.877 8.29 3.570 56.5 ## 6 6 0.906 -1.290 0.921 6.39 2.420 49.3 ## 7 7 0.919 -1.250 0.938 5.19 1.760 44.0 ## 8 8 0.876 -1.240 0.887 4.36 1.320 39.8 ## 9 9 0.880 -1.230 0.880 3.76 1.090 36.4 ## 10 10 0.923 -1.210 0.942 3.30 0.934 33.6 ## 11 12 0.944 -1.200 0.959 2.64 0.674 29.3 ## 12 14 0.970 -1.200 0.982 2.20 0.507 26.0 ## 13 16 0.917 -1.230 0.908 1.88 0.354 23.3 ## 14 18 0.949 -1.240 0.945 1.63 0.261 21.1 ## 15 20 0.948 -1.250 0.943 1.45 0.180 19.3 the optimal power value par(mfrow = c(1, 2)) cex1 = 1.2 plot(sft$fitIndices[, 1], -sign(sft$fitIndices[, 3]) * sft$fitIndices[, 2], xlab = &quot;Soft Threshold (power)&quot;, ylab = &quot;Scale Free Topology Model Fit, signed R^2&quot;, main = paste(&quot;Scale independence&quot;) ) text(sft$fitIndices[, 1], -sign(sft$fitIndices[, 3]) * sft$fitIndices[, 2], labels = powers, cex = cex1, col = &quot;red&quot; ) abline(h = 0.90, col = &quot;red&quot;) plot(sft$fitIndices[, 1], sft$fitIndices[, 5], xlab = &quot;Soft Threshold (power)&quot;, ylab = &quot;Mean Connectivity&quot;, type = &quot;n&quot;, main = paste(&quot;Mean connectivity&quot;) ) text(sft$fitIndices[, 1], sft$fitIndices[, 5], labels = powers, cex = cex1, col = &quot;red&quot;) Notice: We’ pick 5 but feel free to experiment with other powers to see how it affects your results. 6.9.3 Create the network using the blockwiseModules building network picked_power &lt;- 5 # temp_cor &lt;- cor # cor &lt;- WGCNA::cor netwk &lt;- blockwiseModules(features_tab_norm, # == Adjacency Function == power = picked_power, # &lt;= power here networkType = &quot;signed&quot;, # == Network construction arguments: correlation options corType = &quot;bicor&quot;, maxPOutliers = 0.05, # == Tree and Block Options == deepSplit = 2, pamRespectsDendro = F, minModuleSize = 20, maxBlockSize = 4000, # == Module Adjustments == reassignThreshold = 0, mergeCutHeight = 0.25, # == TOM == Archive the run results in TOM file (saves time) saveTOMs = T, saveTOMFileBase = paste0(&quot;./dataset/&quot;, &quot;GvHD&quot;), # == Output Options numericLabels = T, verbose = 3, randomSeed = 123) ## Calculating module eigengenes block-wise from all genes ## Flagging genes and samples with too many missing values... ## ..step 1 ## ..Working on block 1 . ## TOM calculation: adjacency.. ## ..will not use multithreading. ## Fraction of slow calculations: 0.000000 ## ..connectivity.. ## ..matrix multiplication (system BLAS).. ## ..normalization.. ## ..done. ## ..saving TOM for block 1 into file ./dataset/GvHD-block.1.RData ## ....clustering.. ## ....detecting modules.. ## ....calculating module eigengenes.. ## ....checking kME in modules.. ## ..removing 19 genes from module 1 because their KME is too low. ## ..removing 113 genes from module 2 because their KME is too low. ## ..removing 32 genes from module 3 because their KME is too low. ## ..removing 45 genes from module 4 because their KME is too low. ## ..removing 4 genes from module 5 because their KME is too low. ## ..removing 17 genes from module 6 because their KME is too low. ## ..removing 1 genes from module 7 because their KME is too low. ## ..merging modules that are too close.. ## mergeCloseModules: Merging modules whose distance is less than 0.25 ## Calculating new MEs... Modules’ number table(netwk$colors) ## ## 0 1 2 3 4 5 6 7 ## 231 224 139 96 86 73 71 58 hubs rownames(netwk$MEs) &lt;- rownames(features_tab_norm) names(netwk$colors) &lt;- colnames(features_tab_norm) names(netwk$unmergedColors) &lt;- colnames(features_tab_norm) hubs &lt;- chooseTopHubInEachModule(features_tab_norm, netwk$colors) hubs ## 0 1 2 3 4 5 6 7 ## &quot;MW0146102&quot; &quot;MW0155806&quot; &quot;MEDL02751&quot; &quot;MEDP1201&quot; &quot;MW0145567&quot; &quot;MEDP1033&quot; &quot;MW0156874&quot; &quot;MEDP0434&quot; The number of features per module table(netwk$colors) %&gt;% data.frame() %&gt;% dplyr::rename(Module = Var1, Number = Freq) %&gt;% dplyr::mutate(Module_color = labels2colors(as.numeric(as.character(Module)))) %&gt;% ggplot(aes(x = Module, y = Number, fill = Module)) + geom_text(aes(label = Number), vjust = 0.5, hjust = -0.18, size = 3.5) + geom_col(color = &quot;#000000&quot;) + ggtitle(&quot;Number of features per module&quot;) + coord_flip() + scale_y_continuous(expand = c(0, 0)) + theme_classic() + theme(plot.margin = margin(2, 2, 2, 2, &quot;pt&quot;), plot.title = element_text(size = 14, hjust = 0.5, face = &quot;bold&quot;), legend.position = &quot;none&quot;) 6.9.4 plot modules mergedColors &lt;- labels2colors(netwk$colors) plotDendroAndColors( netwk$dendrograms[[1]], mergedColors[netwk$blockGenes[[1]]], &quot;Module colors&quot;, dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05 ) 6.9.5 Relationships among modules plotEigengeneNetworks(netwk$MEs, &quot;Eigengene adjacency heatmap&quot;, marDendro = c(3, 3, 2, 4), marHeatmap = c(3, 4, 2, 2), plotDendrograms = T, xLabelsAngle = 90) 6.9.6 Module (Eigengene) correlation MEs &lt;- netwk$MEs MEs_R &lt;- bicor(MEs, MEs, maxPOutliers = 0.05) idx.r &lt;- which(rownames(MEs_R) == &quot;ME0&quot;) idx.c &lt;- which(colnames(MEs_R) == &quot;ME0&quot;) MEs_R_noME0 &lt;- MEs_R[-idx.r, -idx.c] MEs_R_density &lt;- MEs_R[upper.tri(MEs_R_noME0)] %&gt;% as.data.frame() %&gt;% dplyr::rename(&quot;correlation&quot; = &quot;.&quot;) %&gt;% ggplot(aes(x=correlation)) + geom_density() + ggtitle(paste0(&quot;ME correlation density\\n without &quot;, &quot;ME0&quot;)) MEs_R_Corr &lt;- pheatmap::pheatmap(MEs_R, color = colorRampPalette(c(&quot;Blue&quot;, &quot;White&quot;, &quot;Red&quot;))(100), silent = T, breaks = seq(-1,1,length.out = 101), treeheight_row = 5, treeheight_col = 5, main = paste0(&quot;ME correlation heatmap&quot;), labels_row = rownames(MEs_R), labels_col = colnames(MEs_R)) cowplot::plot_grid(MEs_R_density, MEs_R_Corr$gtable, labels = c(&quot;A&quot;, &quot;B&quot;), label_size = 15, rel_widths = c(0.6, 1), align = &quot;h&quot;) 6.9.7 Relate Module (cluster) Assignments to Groups module_df &lt;- data.frame( featureID = names(netwk$colors), colors = labels2colors(netwk$colors) ) # Get Module Eigengenes per cluster MEs0 &lt;- moduleEigengenes(features_tab_norm, mergedColors)$eigengenes # Reorder modules so similar modules are next to each other MEs0 &lt;- orderMEs(MEs0) module_order &lt;- names(MEs0) %&gt;% gsub(&quot;ME&quot;,&quot;&quot;, .) # Add group names MEs0$group &lt;- paste0(se_impute$group, rownames(colData(se_impute))) # row.names(MEs0) == rownames(colData(se_impute)) # tidy &amp; plot data mME &lt;- MEs0 %&gt;% tidyr::pivot_longer(-group) %&gt;% mutate( name = gsub(&quot;ME&quot;, &quot;&quot;, name), name = factor(name, levels = module_order) ) mME %&gt;% ggplot(., aes(x=group, y=name, fill=value)) + geom_tile() + labs(title = &quot;Module-samples Relationships&quot;, y = &quot;Modules&quot;, fill = &quot;corr&quot;) + scale_fill_gradient2( low = &quot;blue&quot;, high = &quot;red&quot;, mid = &quot;white&quot;, midpoint = 0, limit = c(-1,1)) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) Result: the black modules seems negatively associated (red shading) with the PR groups. 6.9.8 Generate and Export Networks # modules_of_interest &lt;- c(&quot;green&quot;, &quot;brown&quot;, &quot;black&quot;) # # genes_of_interest &lt;- module_df %&gt;% # subset(colors %in% modules_of_interest) # # expr_of_interest &lt;- features_tab_norm[, genes_of_interest$featureID] # # # Only recalculate TOM for modules of interest # TOM &lt;- TOMsimilarityFromExpr(expr_of_interest, # power = picked_power) # # # Add feature id to row and columns # rownames(TOM) &lt;- colnames(expr_of_interest) # colnames(TOM) &lt;- colnames(expr_of_interest) # # edge_list &lt;- data.frame(TOM) %&gt;% # tibble::rownames_to_column(&quot;featureID&quot;) %&gt;% # tidyr::pivot_longer(-featureID) %&gt;% # dplyr::rename(featureID2 = name, correlation = value) %&gt;% # unique() %&gt;% # subset(!(featureID == featureID2)) %&gt;% # dplyr::mutate( # module1 = module_df[featureID, ]$colors, # module2 = module_df[featureID2, ]$colors) # # head(edge_list) 6.9.9 Network visualization library(igraph) strength_adjust &lt;- 1 TOM &lt;- TOMsimilarityFromExpr(features_tab_norm, power = picked_power) ## TOM calculation: adjacency.. ## ..will not use multithreading. ## Fraction of slow calculations: 0.000000 ## ..connectivity.. ## ..matrix multiplication (system BLAS).. ## ..normalization.. ## ..done. # Add feature id to row and columns rownames(TOM) &lt;- colnames(features_tab_norm) colnames(TOM) &lt;- colnames(features_tab_norm) g &lt;- graph.adjacency(TOM, mode=&quot;undirected&quot;, weighted= TRUE) delete.edges(g, which(E(g)$weight &lt;1)) ## IGRAPH fef3bb7 UNW- 978 978 -- ## + attr: name (v/c), weight (e/n) ## + edges from fef3bb7 (vertex names): ## [1] MEDL00066--MEDL00066 MEDL00356--MEDL00356 MEDL00369--MEDL00369 MEDL00375--MEDL00375 MEDL00392--MEDL00392 MEDL00401--MEDL00401 ## [7] MEDL00404--MEDL00404 MEDL00416--MEDL00416 MEDL00568--MEDL00568 MEDL00587--MEDL00587 MEDL01764--MEDL01764 MEDL01799--MEDL01799 ## [13] MEDL01837--MEDL01837 MEDL01844--MEDL01844 MEDL01857--MEDL01857 MEDL01867--MEDL01867 MEDL01879--MEDL01879 MEDL01922--MEDL01922 ## [19] MEDL01994--MEDL01994 MEDL01999--MEDL01999 MEDL02002--MEDL02002 MEDL02018--MEDL02018 MEDL02044--MEDL02044 MEDL02106--MEDL02106 ## [25] MEDL02174--MEDL02174 MEDL02177--MEDL02177 MEDL02187--MEDL02187 MEDL02519--MEDL02519 MEDL02561--MEDL02561 MEDL02562--MEDL02562 ## [31] MEDL02582--MEDL02582 MEDL02630--MEDL02630 MEDL02681--MEDL02681 MEDL02751--MEDL02751 MEDN0004 --MEDN0004 MEDN0005 --MEDN0005 ## [37] MEDN0006 --MEDN0006 MEDN0007 --MEDN0007 MEDN0010 --MEDN0010 MEDN0015 --MEDN0015 MEDN0018 --MEDN0018 MEDN0025 --MEDN0025 ## [43] MEDN0027 --MEDN0027 MEDN0028 --MEDN0028 MEDN0032 --MEDN0032 MEDN0036 --MEDN0036 MEDN0041 --MEDN0041 MEDN0042 --MEDN0042 ## + ... omitted several edges E(g)$width &lt;- E(g)$weight*strength_adjust + min(E(g)$weight) E(g)$color &lt;- &quot;red&quot; plot(g) 6.10 Systematic Information devtools::session_info() ## ─ Session info ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os macOS Monterey 12.2.1 ## system x86_64, darwin17.0 ## ui RStudio ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Asia/Shanghai ## date 2023-11-27 ## rstudio 2023.09.0+463 Desert Sunflower (desktop) ## pandoc 3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown) ## ## ─ Packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## abind 1.4-5 2016-07-21 [2] CRAN (R 4.1.0) ## ade4 1.7-22 2023-02-06 [2] CRAN (R 4.1.2) ## affy 1.72.0 2021-10-26 [2] Bioconductor ## affyio 1.64.0 2021-10-26 [2] Bioconductor ## annotate 1.72.0 2021-10-26 [2] Bioconductor ## AnnotationDbi * 1.60.2 2023-03-10 [2] Bioconductor ## ape 5.7-1 2023-03-13 [2] CRAN (R 4.1.2) ## aplot 0.1.10 2023-03-08 [2] CRAN (R 4.1.2) ## attempt 0.3.1 2020-05-03 [2] CRAN (R 4.1.0) ## backports 1.4.1 2021-12-13 [2] CRAN (R 4.1.0) ## base64enc 0.1-3 2015-07-28 [2] CRAN (R 4.1.0) ## Biobase * 2.54.0 2021-10-26 [2] Bioconductor ## BiocGenerics * 0.40.0 2021-10-26 [2] Bioconductor ## BiocManager 1.30.21 2023-06-10 [2] CRAN (R 4.1.3) ## BiocParallel 1.28.3 2021-12-09 [2] Bioconductor ## biomformat 1.22.0 2021-10-26 [2] Bioconductor ## Biostrings 2.62.0 2021-10-26 [2] Bioconductor ## bit 4.0.5 2022-11-15 [2] CRAN (R 4.1.2) ## bit64 4.0.5 2020-08-30 [2] CRAN (R 4.1.0) ## bitops 1.0-7 2021-04-24 [2] CRAN (R 4.1.0) ## blob 1.2.4 2023-03-17 [2] CRAN (R 4.1.2) ## bookdown 0.34 2023-05-09 [2] CRAN (R 4.1.2) ## broom 1.0.5 2023-06-09 [2] CRAN (R 4.1.3) ## bslib 0.6.0 2023-11-21 [1] CRAN (R 4.1.3) ## cachem 1.0.8 2023-05-01 [2] CRAN (R 4.1.2) ## Cairo 1.6-0 2022-07-05 [2] CRAN (R 4.1.2) ## callr 3.7.3 2022-11-02 [2] CRAN (R 4.1.2) ## car 3.1-2 2023-03-30 [2] CRAN (R 4.1.2) ## carData 3.0-5 2022-01-06 [2] CRAN (R 4.1.2) ## caret 6.0-94 2023-03-21 [2] CRAN (R 4.1.2) ## caTools 1.18.2 2021-03-28 [2] CRAN (R 4.1.0) ## cellranger 1.1.0 2016-07-27 [2] CRAN (R 4.1.0) ## checkmate 2.2.0 2023-04-27 [2] CRAN (R 4.1.2) ## circlize 0.4.15 2022-05-10 [2] CRAN (R 4.1.2) ## class 7.3-22 2023-05-03 [2] CRAN (R 4.1.2) ## cli 3.6.1 2023-03-23 [2] CRAN (R 4.1.2) ## clue 0.3-64 2023-01-31 [2] CRAN (R 4.1.2) ## cluster * 2.1.4 2022-08-22 [2] CRAN (R 4.1.2) ## clusterProfiler * 4.2.2 2022-01-13 [2] Bioconductor ## codetools 0.2-19 2023-02-01 [2] CRAN (R 4.1.2) ## coin 1.4-2 2021-10-08 [2] CRAN (R 4.1.0) ## colorspace 2.1-0 2023-01-23 [2] CRAN (R 4.1.2) ## ComplexHeatmap 2.10.0 2021-10-26 [2] Bioconductor ## config 0.3.1 2020-12-17 [2] CRAN (R 4.1.0) ## corpcor 1.6.10 2021-09-16 [2] CRAN (R 4.1.0) ## cowplot 1.1.1 2020-12-30 [2] CRAN (R 4.1.0) ## crayon 1.5.2 2022-09-29 [2] CRAN (R 4.1.2) ## crmn 0.0.21 2020-02-10 [2] CRAN (R 4.1.0) ## curl 5.0.1 2023-06-07 [2] CRAN (R 4.1.3) ## data.table 1.14.8 2023-02-17 [2] CRAN (R 4.1.2) ## DBI 1.1.3 2022-06-18 [2] CRAN (R 4.1.2) ## DelayedArray 0.20.0 2021-10-26 [2] Bioconductor ## dendextend * 1.17.1 2023-03-25 [2] CRAN (R 4.1.2) ## DESeq2 1.34.0 2021-10-26 [2] Bioconductor ## devtools 2.4.5 2022-10-11 [2] CRAN (R 4.1.2) ## digest 0.6.33 2023-07-07 [1] CRAN (R 4.1.3) ## DO.db 2.9 2022-04-11 [2] Bioconductor ## doParallel 1.0.17 2022-02-07 [2] CRAN (R 4.1.2) ## doRNG 1.8.6 2023-01-16 [2] CRAN (R 4.1.2) ## DOSE 3.20.1 2021-11-18 [2] Bioconductor ## doSNOW 1.0.20 2022-02-04 [2] CRAN (R 4.1.2) ## downloader 0.4 2015-07-09 [2] CRAN (R 4.1.0) ## dplyr * 1.1.2 2023-04-20 [2] CRAN (R 4.1.2) ## DT 0.28 2023-05-18 [2] CRAN (R 4.1.3) ## dynamicTreeCut * 1.63-1 2016-03-11 [2] CRAN (R 4.1.0) ## e1071 1.7-13 2023-02-01 [2] CRAN (R 4.1.2) ## edgeR 3.36.0 2021-10-26 [2] Bioconductor ## ellipse 0.4.5 2023-04-05 [2] CRAN (R 4.1.2) ## ellipsis 0.3.2 2021-04-29 [2] CRAN (R 4.1.0) ## enrichplot 1.14.2 2022-02-24 [2] Bioconductor ## evaluate 0.21 2023-05-05 [2] CRAN (R 4.1.2) ## factoextra * 1.0.7 2020-04-01 [2] CRAN (R 4.1.0) ## fansi 1.0.4 2023-01-22 [2] CRAN (R 4.1.2) ## farver 2.1.1 2022-07-06 [2] CRAN (R 4.1.2) ## fastcluster * 1.2.3 2021-05-24 [2] CRAN (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] CRAN (R 4.1.2) ## fastmatch 1.1-3 2021-07-23 [2] CRAN (R 4.1.0) ## fdrtool 1.2.17 2021-11-13 [2] CRAN (R 4.1.0) ## fgsea 1.20.0 2021-10-26 [2] Bioconductor ## filematrix 1.3 2018-02-27 [2] CRAN (R 4.1.0) ## foreach 1.5.2 2022-02-02 [2] CRAN (R 4.1.2) ## foreign 0.8-84 2022-12-06 [2] CRAN (R 4.1.2) ## forestplot 3.1.1 2022-12-06 [2] CRAN (R 4.1.2) ## Formula 1.2-5 2023-02-24 [2] CRAN (R 4.1.2) ## fs 1.6.2 2023-04-25 [2] CRAN (R 4.1.2) ## furrr 0.3.1 2022-08-15 [2] CRAN (R 4.1.2) ## future 1.33.0 2023-07-01 [2] CRAN (R 4.1.3) ## future.apply 1.11.0 2023-05-21 [2] CRAN (R 4.1.3) ## genefilter 1.76.0 2021-10-26 [2] Bioconductor ## geneplotter 1.72.0 2021-10-26 [2] Bioconductor ## generics 0.1.3 2022-07-05 [2] CRAN (R 4.1.2) ## GenomeInfoDb * 1.30.1 2022-01-30 [2] Bioconductor ## GenomeInfoDbData 1.2.7 2022-03-09 [2] Bioconductor ## GenomicRanges * 1.46.1 2021-11-18 [2] Bioconductor ## GetoptLong 1.0.5 2020-12-15 [2] CRAN (R 4.1.0) ## ggforce 0.4.1 2022-10-04 [2] CRAN (R 4.1.2) ## ggfun 0.1.1 2023-06-24 [2] CRAN (R 4.1.3) ## ggplot2 * 3.4.2 2023-04-03 [2] CRAN (R 4.1.2) ## ggplotify 0.1.1 2023-06-27 [2] CRAN (R 4.1.3) ## ggpubr 0.6.0 2023-02-10 [2] CRAN (R 4.1.2) ## ggraph * 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71) ## ggrepel 0.9.3 2023-02-03 [2] CRAN (R 4.1.2) ## ggsignif 0.6.4 2022-10-13 [2] CRAN (R 4.1.2) ## ggtree 3.2.1 2021-11-16 [2] Bioconductor ## glasso 1.11 2019-10-01 [2] CRAN (R 4.1.0) ## glmnet * 4.1-7 2023-03-23 [2] CRAN (R 4.1.2) ## GlobalOptions 0.1.2 2020-06-10 [2] CRAN (R 4.1.0) ## globals 0.16.2 2022-11-21 [2] CRAN (R 4.1.2) ## globaltest 5.48.0 2021-10-26 [2] Bioconductor ## glue * 1.6.2 2022-02-24 [2] CRAN (R 4.1.2) ## Gmisc * 3.0.2 2023-03-13 [2] CRAN (R 4.1.2) ## gmm 1.8 2023-06-06 [2] CRAN (R 4.1.3) ## gmp 0.7-1 2023-02-07 [2] CRAN (R 4.1.2) ## GO.db 3.14.0 2022-04-11 [2] Bioconductor ## golem 0.4.1 2023-06-05 [2] CRAN (R 4.1.3) ## GOSemSim 2.20.0 2021-10-26 [2] Bioconductor ## gower 1.0.1 2022-12-22 [2] CRAN (R 4.1.2) ## gplots 3.1.3 2022-04-25 [2] CRAN (R 4.1.2) ## graphlayouts 1.0.0 2023-05-01 [2] CRAN (R 4.1.2) ## gridExtra 2.3 2017-09-09 [2] CRAN (R 4.1.0) ## gridGraphics 0.5-1 2020-12-13 [2] CRAN (R 4.1.0) ## gtable 0.3.3 2023-03-21 [2] CRAN (R 4.1.2) ## gtools 3.9.4 2022-11-27 [2] CRAN (R 4.1.2) ## hardhat 1.3.0 2023-03-30 [2] CRAN (R 4.1.2) ## highr 0.10 2022-12-22 [2] CRAN (R 4.1.2) ## Hmisc 5.1-0 2023-05-08 [2] CRAN (R 4.1.2) ## hms 1.1.3 2023-03-21 [2] CRAN (R 4.1.2) ## htmlTable * 2.4.1 2022-07-07 [2] CRAN (R 4.1.2) ## htmltools 0.5.7 2023-11-03 [1] CRAN (R 4.1.3) ## htmlwidgets 1.6.2 2023-03-17 [2] CRAN (R 4.1.2) ## httpuv 1.6.11 2023-05-11 [2] CRAN (R 4.1.3) ## httr * 1.4.6 2023-05-08 [2] CRAN (R 4.1.2) ## huge 1.3.5 2021-06-30 [2] CRAN (R 4.1.0) ## igraph * 1.5.0 2023-06-16 [1] CRAN (R 4.1.3) ## impute 1.68.0 2021-10-26 [2] Bioconductor ## imputeLCMD 2.1 2022-06-10 [2] CRAN (R 4.1.2) ## ipred 0.9-14 2023-03-09 [2] CRAN (R 4.1.2) ## IRanges * 2.28.0 2021-10-26 [2] Bioconductor ## irlba 2.3.5.1 2022-10-03 [2] CRAN (R 4.1.2) ## iterators 1.0.14 2022-02-05 [2] CRAN (R 4.1.2) ## itertools 0.1-3 2014-03-12 [2] CRAN (R 4.1.0) ## jpeg 0.1-10 2022-11-29 [2] CRAN (R 4.1.2) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.0) ## jsonlite 1.8.7 2023-06-29 [2] CRAN (R 4.1.3) ## KEGGREST 1.34.0 2021-10-26 [2] Bioconductor ## KernSmooth 2.23-22 2023-07-10 [2] CRAN (R 4.1.3) ## knitr 1.43 2023-05-25 [2] CRAN (R 4.1.3) ## labeling 0.4.2 2020-10-20 [2] CRAN (R 4.1.0) ## later 1.3.1 2023-05-02 [2] CRAN (R 4.1.2) ## lattice 0.21-8 2023-04-05 [2] CRAN (R 4.1.2) ## lava 1.7.2.1 2023-02-27 [2] CRAN (R 4.1.2) ## lavaan 0.6-15 2023-03-14 [2] CRAN (R 4.1.2) ## lazyeval 0.2.2 2019-03-15 [2] CRAN (R 4.1.0) ## libcoin 1.0-9 2021-09-27 [2] CRAN (R 4.1.0) ## lifecycle 1.0.3 2022-10-07 [2] CRAN (R 4.1.2) ## limma 3.50.3 2022-04-07 [2] Bioconductor ## listenv 0.9.0 2022-12-16 [2] CRAN (R 4.1.2) ## locfit 1.5-9.8 2023-06-11 [2] CRAN (R 4.1.3) ## lubridate 1.9.2 2023-02-10 [2] CRAN (R 4.1.2) ## magrittr * 2.0.3 2022-03-30 [2] CRAN (R 4.1.2) ## MALDIquant 1.22.1 2023-03-20 [2] CRAN (R 4.1.2) ## MASS 7.3-60 2023-05-04 [2] CRAN (R 4.1.2) ## massdatabase * 1.0.7 2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93) ## massdataset * 1.0.24 2023-05-30 [2] gitlab (jaspershen/massdataset@b397116) ## masstools * 1.0.10 2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc) ## Matrix * 1.6-0 2023-07-08 [2] CRAN (R 4.1.3) ## MatrixGenerics * 1.6.0 2021-10-26 [2] Bioconductor ## matrixStats * 1.0.0 2023-06-02 [2] CRAN (R 4.1.3) ## memoise 2.0.1 2021-11-26 [2] CRAN (R 4.1.0) ## MetaboAnalystR * 3.2.0 2022-06-28 [2] Github (xia-lab/MetaboAnalystR@892a31b) ## metagenomeSeq 1.36.0 2021-10-26 [2] Bioconductor ## metid * 1.2.26 2023-05-30 [2] gitlab (jaspershen/metid@6bde121) ## metpath * 1.0.5 2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f) ## mgcv 1.8-42 2023-03-02 [2] CRAN (R 4.1.2) ## MicrobiomeProfiler * 1.0.0 2021-10-26 [2] Bioconductor ## mime 0.12 2021-09-28 [2] CRAN (R 4.1.0) ## miniUI 0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0) ## missForest 1.5 2022-04-14 [2] CRAN (R 4.1.2) ## mixedCCA 1.6.2 2022-09-09 [2] CRAN (R 4.1.2) ## mixOmics 6.18.1 2021-11-18 [2] Bioconductor (R 4.1.2) ## mnormt 2.1.1 2022-09-26 [2] CRAN (R 4.1.2) ## ModelMetrics 1.2.2.2 2020-03-17 [2] CRAN (R 4.1.0) ## modeltools 0.2-23 2020-03-05 [2] CRAN (R 4.1.0) ## MsCoreUtils 1.6.2 2022-02-24 [2] Bioconductor ## MSnbase * 2.20.4 2022-01-16 [2] Bioconductor ## multcomp 1.4-25 2023-06-20 [2] CRAN (R 4.1.3) ## multtest 2.50.0 2021-10-26 [2] Bioconductor ## munsell 0.5.0 2018-06-12 [2] CRAN (R 4.1.0) ## mvtnorm 1.2-2 2023-06-08 [2] CRAN (R 4.1.3) ## mzID 1.32.0 2021-10-26 [2] Bioconductor ## mzR * 2.28.0 2021-10-27 [2] Bioconductor ## ncdf4 1.21 2023-01-07 [2] CRAN (R 4.1.2) ## NetCoMi * 1.0.3 2022-07-14 [2] Github (stefpeschel/NetCoMi@d4d80d3) ## nlme 3.1-162 2023-01-31 [2] CRAN (R 4.1.2) ## nnet 7.3-19 2023-05-03 [2] CRAN (R 4.1.2) ## norm 1.0-11.1 2023-06-18 [2] CRAN (R 4.1.3) ## openxlsx 4.2.5.2 2023-02-06 [2] CRAN (R 4.1.2) ## org.Mm.eg.db * 3.14.0 2022-11-23 [2] Bioconductor ## parallelly 1.36.0 2023-05-26 [2] CRAN (R 4.1.3) ## patchwork 1.1.2 2022-08-19 [2] CRAN (R 4.1.2) ## pbapply 1.7-2 2023-06-27 [2] CRAN (R 4.1.3) ## pbivnorm 0.6.0 2015-01-23 [2] CRAN (R 4.1.0) ## pcaMethods 1.86.0 2021-10-26 [2] Bioconductor ## pcaPP 2.0-3 2022-10-24 [2] CRAN (R 4.1.2) ## permute 0.9-7 2022-01-27 [2] CRAN (R 4.1.2) ## pheatmap 1.0.12 2019-01-04 [2] CRAN (R 4.1.0) ## phyloseq 1.38.0 2021-10-26 [2] Bioconductor ## pillar 1.9.0 2023-03-22 [2] CRAN (R 4.1.2) ## pkgbuild 1.4.2 2023-06-26 [2] CRAN (R 4.1.3) ## pkgconfig 2.0.3 2019-09-22 [2] CRAN (R 4.1.0) ## pkgload 1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3) ## plotly * 4.10.2 2023-06-03 [2] CRAN (R 4.1.3) ## plyr 1.8.8 2022-11-11 [2] CRAN (R 4.1.2) ## png 0.1-8 2022-11-29 [2] CRAN (R 4.1.2) ## polyclip 1.10-4 2022-10-20 [2] CRAN (R 4.1.2) ## POMA * 1.7.2 2022-07-26 [2] Github (pcastellanoescuder/POMA@bc8a972) ## preprocessCore 1.56.0 2021-10-26 [2] Bioconductor ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.1.0) ## pROC 1.18.4 2023-07-06 [2] CRAN (R 4.1.3) ## processx 3.8.2 2023-06-30 [2] CRAN (R 4.1.3) ## prodlim 2023.03.31 2023-04-02 [2] CRAN (R 4.1.2) ## profvis 0.3.8 2023-05-02 [2] CRAN (R 4.1.2) ## progress 1.2.2 2019-05-16 [2] CRAN (R 4.1.0) ## promises 1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0) ## ProtGenerics * 1.26.0 2021-10-26 [2] Bioconductor ## proxy 0.4-27 2022-06-09 [2] CRAN (R 4.1.2) ## ps 1.7.5 2023-04-18 [2] CRAN (R 4.1.2) ## psych 2.3.6 2023-06-21 [2] CRAN (R 4.1.3) ## pulsar 0.3.10 2023-01-26 [2] CRAN (R 4.1.2) ## purrr 1.0.1 2023-01-10 [2] CRAN (R 4.1.2) ## qgraph 1.9.5 2023-05-16 [2] CRAN (R 4.1.3) ## qs 0.25.5 2023-02-22 [2] CRAN (R 4.1.2) ## quadprog 1.5-8 2019-11-20 [2] CRAN (R 4.1.0) ## qvalue 2.26.0 2021-10-26 [2] Bioconductor ## R6 2.5.1 2021-08-19 [2] CRAN (R 4.1.0) ## ragg 1.2.5 2023-01-12 [2] CRAN (R 4.1.2) ## randomForest 4.7-1.1 2022-05-23 [2] CRAN (R 4.1.2) ## RankProd 3.20.0 2021-10-26 [2] Bioconductor ## RApiSerialize 0.1.2 2022-08-25 [2] CRAN (R 4.1.2) ## rARPACK 0.11-0 2016-03-10 [2] CRAN (R 4.1.0) ## rbibutils 2.2.13 2023-01-13 [2] CRAN (R 4.1.2) ## RColorBrewer 1.1-3 2022-04-03 [2] CRAN (R 4.1.2) ## Rcpp * 1.0.11 2023-07-06 [1] CRAN (R 4.1.3) ## RcppParallel 5.1.7 2023-02-27 [2] CRAN (R 4.1.2) ## RCurl 1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2) ## Rdisop 1.54.0 2021-10-26 [2] Bioconductor ## Rdpack 2.4 2022-07-20 [2] CRAN (R 4.1.2) ## readr 2.1.4 2023-02-10 [2] CRAN (R 4.1.2) ## readxl * 1.4.3 2023-07-06 [2] CRAN (R 4.1.3) ## recipes 1.0.6 2023-04-25 [2] CRAN (R 4.1.2) ## remotes 2.4.2 2021-11-30 [2] CRAN (R 4.1.0) ## reshape2 1.4.4 2020-04-09 [2] CRAN (R 4.1.0) ## rhdf5 2.38.1 2022-03-10 [2] Bioconductor ## rhdf5filters 1.6.0 2021-10-26 [2] Bioconductor ## Rhdf5lib 1.16.0 2021-10-26 [2] Bioconductor ## rjson 0.2.21 2022-01-09 [2] CRAN (R 4.1.2) ## rlang 1.1.1 2023-04-28 [1] CRAN (R 4.1.2) ## rmarkdown 2.23 2023-07-01 [2] CRAN (R 4.1.3) ## Rmpfr 0.9-2 2023-04-22 [2] CRAN (R 4.1.2) ## rngtools 1.5.2 2021-09-20 [2] CRAN (R 4.1.0) ## rootSolve 1.8.2.3 2021-09-29 [2] CRAN (R 4.1.0) ## ropls * 1.26.4 2022-01-11 [2] Bioconductor ## rpart 4.1.19 2022-10-21 [2] CRAN (R 4.1.2) ## Rserve * 1.8-11 2022-11-28 [2] CRAN (R 4.1.2) ## RSpectra 0.16-1 2022-04-24 [2] CRAN (R 4.1.2) ## RSQLite 2.3.1 2023-04-03 [2] CRAN (R 4.1.2) ## rstatix 0.7.2 2023-02-01 [2] CRAN (R 4.1.2) ## rstudioapi 0.15.0 2023-07-07 [2] CRAN (R 4.1.3) ## rvest 1.0.3 2022-08-19 [2] CRAN (R 4.1.2) ## S4Vectors * 0.32.4 2022-03-29 [2] Bioconductor ## sandwich 3.0-2 2022-06-15 [2] CRAN (R 4.1.2) ## sass 0.4.6 2023-05-03 [2] CRAN (R 4.1.2) ## scales 1.2.1 2022-08-20 [2] CRAN (R 4.1.2) ## scatterpie 0.2.1 2023-06-07 [2] CRAN (R 4.1.3) ## scrime 1.3.5 2018-12-01 [2] CRAN (R 4.1.0) ## sessioninfo 1.2.2 2021-12-06 [2] CRAN (R 4.1.0) ## shadowtext 0.1.2 2022-04-22 [2] CRAN (R 4.1.2) ## shape 1.4.6 2021-05-19 [2] CRAN (R 4.1.0) ## shiny 1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3) ## shinycustomloader 0.9.0 2018-03-27 [2] CRAN (R 4.1.0) ## shinyWidgets 0.7.6 2023-01-08 [2] CRAN (R 4.1.2) ## siggenes 1.68.0 2021-10-26 [2] Bioconductor ## snow 0.4-4 2021-10-27 [2] CRAN (R 4.1.0) ## SpiecEasi * 1.1.2 2022-07-14 [2] Github (zdk123/SpiecEasi@c463727) ## SPRING * 1.0.4 2022-08-03 [2] Github (GraceYoon/SPRING@3d641a4) ## stringdist 0.9.10 2022-11-07 [2] CRAN (R 4.1.2) ## stringfish 0.15.8 2023-05-30 [2] CRAN (R 4.1.3) ## stringi 1.7.12 2023-01-11 [2] CRAN (R 4.1.2) ## stringr 1.5.0 2022-12-02 [2] CRAN (R 4.1.2) ## SummarizedExperiment * 1.24.0 2021-10-26 [2] Bioconductor ## survival 3.5-5 2023-03-12 [2] CRAN (R 4.1.2) ## systemfonts 1.0.4 2022-02-11 [2] CRAN (R 4.1.2) ## textshaping 0.3.6 2021-10-13 [2] CRAN (R 4.1.0) ## TH.data 1.1-2 2023-04-17 [2] CRAN (R 4.1.2) ## tibble * 3.2.1 2023-03-20 [2] CRAN (R 4.1.2) ## tidygraph 1.2.3 2023-02-01 [2] CRAN (R 4.1.2) ## tidyr 1.3.0 2023-01-24 [2] CRAN (R 4.1.2) ## tidyselect 1.2.0 2022-10-10 [2] CRAN (R 4.1.2) ## tidytree 0.4.2 2022-12-18 [2] CRAN (R 4.1.2) ## timechange 0.2.0 2023-01-11 [2] CRAN (R 4.1.2) ## timeDate 4022.108 2023-01-07 [2] CRAN (R 4.1.2) ## tmvtnorm 1.5 2022-03-22 [2] CRAN (R 4.1.2) ## treeio 1.18.1 2021-11-14 [2] Bioconductor ## tweenr 2.0.2 2022-09-06 [2] CRAN (R 4.1.2) ## tzdb 0.4.0 2023-05-12 [2] CRAN (R 4.1.3) ## urlchecker 1.0.1 2021-11-30 [2] CRAN (R 4.1.0) ## usethis 2.2.2 2023-07-06 [2] CRAN (R 4.1.3) ## utf8 1.2.3 2023-01-31 [2] CRAN (R 4.1.2) ## vctrs 0.6.3 2023-06-14 [1] CRAN (R 4.1.3) ## vegan 2.6-4 2022-10-11 [2] CRAN (R 4.1.2) ## VGAM 1.1-8 2023-03-09 [2] CRAN (R 4.1.2) ## viridis 0.6.3 2023-05-03 [2] CRAN (R 4.1.2) ## viridisLite 0.4.2 2023-05-02 [2] CRAN (R 4.1.2) ## vsn 3.62.0 2021-10-26 [2] Bioconductor ## WGCNA * 1.72-1 2023-01-18 [2] CRAN (R 4.1.2) ## withr 2.5.0 2022-03-03 [2] CRAN (R 4.1.2) ## Wrench 1.12.0 2021-10-26 [2] Bioconductor ## xfun 0.40 2023-08-09 [1] CRAN (R 4.1.3) ## XMAS2 * 2.2.0 2023-10-27 [1] local ## XML 3.99-0.14 2023-03-19 [2] CRAN (R 4.1.2) ## xml2 1.3.5 2023-07-06 [2] CRAN (R 4.1.3) ## xtable 1.8-4 2019-04-21 [2] CRAN (R 4.1.0) ## XVector 0.34.0 2021-10-26 [2] Bioconductor ## yaml 2.3.7 2023-01-23 [2] CRAN (R 4.1.2) ## yulab.utils 0.0.6 2022-12-20 [2] CRAN (R 4.1.2) ## zip 2.3.0 2023-04-17 [2] CRAN (R 4.1.2) ## zlibbioc 1.40.0 2021-10-26 [2] Bioconductor ## zoo 1.8-12 2023-04-13 [2] CRAN (R 4.1.2) ## ## [1] /Users/zouhua/Library/R/x86_64/4.1/library ## [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library ## ## ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
